% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{JMLR:v18:16-456}
\BIBentryALTinterwordspacing
I.~Hubara, M.~Courbariaux, D.~Soudry, R.~El-Yaniv, and Y.~Bengio, ``Quantized
  neural networks: Training neural networks with low precision weights and
  activations,'' \emph{Journal of Machine Learning Research}, vol.~18, no. 187,
  pp. 1--30, 2018. [Online]. Available:
  \url{http://jmlr.org/papers/v18/16-456.html}
\BIBentrySTDinterwordspacing

\bibitem{SCHMIDHUBER201585}
\BIBentryALTinterwordspacing
J.~Schmidhuber, ``Deep learning in neural networks: An overview,'' \emph{Neural
  Networks}, vol.~61, pp. 85 -- 117, 2015. [Online]. Available:
  \url{http://www.sciencedirect.com/science/article/pii/S0893608014002135}
\BIBentrySTDinterwordspacing

\bibitem{vitis-ai}
\BIBentryALTinterwordspacing
Xilinx. (2020) Vitis ai. [Online]. Available:
  \url{https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html}
\BIBentrySTDinterwordspacing

\bibitem{altera-ai}
\BIBentryALTinterwordspacing
Intel. Fpgas for artificial intelligence (ai). [Online]. Available:
  \url{https://www.intel.com/content/www/us/en/artificial-intelligence/programmable/overview.html}
\BIBentrySTDinterwordspacing

\bibitem{electronics8060661}
\BIBentryALTinterwordspacing
T.~Simons and D.-J. Lee, ``A review of binarized neural networks,''
  \emph{Electronics}, vol.~8, no.~6, 2019. [Online]. Available:
  \url{https://www.mdpi.com/2079-9292/8/6/661}
\BIBentrySTDinterwordspacing

\bibitem{8425178}
Y.~Hu, J.~Zhai, D.~Li, Y.~Gong, Y.~Zhu, W.~Liu, L.~Su, and J.~Jin, ``Bitflow:
  Exploiting vector parallelism for binary neural networks on cpu,'' in
  \emph{2018 IEEE International Parallel and Distributed Processing Symposium
  (IPDPS)}, May 2018, pp. 244--253.

\bibitem{Tang2017HowTT}
W.~Tang, G.~Hua, and L.~Wang, ``How to train a compact binary neural network
  with high accuracy?'' in \emph{AAAI}, 2017.

\bibitem{8953134}
R.~{Valencia}, C.~{Sham}, and O.~{Sinnen}, ``Using neuroevolved binary neural
  networks to solve reinforcement learning environments,'' in \emph{2019 IEEE
  Asia Pacific Conference on Circuits and Systems (APCCAS)}, Nov 2019, pp.
  301--304.

\bibitem{NIPS2019_8736}
\BIBentryALTinterwordspacing
X.~Sun, J.~Choi, C.-Y. Chen, N.~Wang, S.~Venkataramani, V.~V. Srinivasan,
  X.~Cui, W.~Zhang, and K.~Gopalakrishnan, ``Hybrid 8-bit floating point (hfp8)
  training and inference for deep neural networks,'' in \emph{Advances in
  Neural Information Processing Systems 32}, H.~Wallach, H.~Larochelle,
  A.~Beygelzimer, F.~Alch\'{e}-Buc, E.~Fox, and R.~Garnett, Eds.\hskip 1em plus
  0.5em minus 0.4em\relax Curran Associates, Inc., 2019, pp. 4900--4909.
  [Online]. Available:
  \url{http://papers.nips.cc/paper/8736-hybrid-8-bit-floating-point-hfp8-training-and-inference-for-deep-neural-networks.pdf}
\BIBentrySTDinterwordspacing

\bibitem{8977877}
R.~{Valencia}, C.~W. {Sham}, and O.~{Sinnen}, ``Evolved binary neural networks
  through harnessing fpga capabilities,'' in \emph{2019 International
  Conference on Field-Programmable Technology (ICFPT)}, Dec 2019, pp. 395--398.

\bibitem{10.1145/3377929.3389933}
\BIBentryALTinterwordspacing
R.~H.~V. Tenorio, C.~W. Sham, and D.~V. Vargas, ``Preliminary study of applied
  binary neural networks for neural cryptography,'' in \emph{Proceedings of the
  2020 Genetic and Evolutionary Computation Conference Companion}, ser. GECCO
  '20.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association
  for Computing Machinery, 2020, pp. 291--292. [Online]. Available:
  \url{https://doi.org/10.1145/3377929.3389933}
\BIBentrySTDinterwordspacing

\bibitem{9087264}
M.~Y. {Ibrahim}, R.~{Sridhar}, T.~V. {Geetha}, and D.~S. {S}, ``Advances in
  neuroevolution through augmenting topologies -- a case study,'' in \emph{2019
  11th International Conference on Advanced Computing (ICoAC)}, Dec 2019, pp.
  111--116.

\bibitem{alveoU50}
\BIBentryALTinterwordspacing
Xilinx. (2020) Alveo u50. [Online]. Available:
  \url{https://www.xilinx.com/products/boards-and-kits/alveo/u50.html}
\BIBentrySTDinterwordspacing

\bibitem{Zhao:2016aa}
W.~Zhao, H.~Fu, W.~Luk, T.~Yu, S.~Wang, B.~Feng, Y.~Ma, and G.~Yang, ``F-cnn:
  An fpga-based framework for training convolutional neural networks,'' in
  \emph{2016 IEEE 27th International Conference on Application-specific
  Systems, Architectures and Processors (ASAP)}, 2016, pp. 107--114.

\bibitem{gpgpu-ai-dominance}
\BIBentryALTinterwordspacing
J.~Kobielus. (2019) Gpus continue to dominate the ai accelerator market for
  now. [Online]. Available:
  \url{https://www.informationweek.com/big-data/ai-machine-learning/gpus-continue-to-dominate-the-ai-accelerator-market-for-now/a/d-id/1336475}
\BIBentrySTDinterwordspacing

\bibitem{8594633}
A.~{Shawahna}, S.~M. {Sait}, and A.~{El-Maleh}, ``Fpga-based accelerators of
  deep learning networks for learning and classification: A review,''
  \emph{IEEE Access}, vol.~7, pp. 7823--7859, 2019.

\bibitem{2017arXiv170303864S}
T.~{Salimans}, J.~{Ho}, X.~{Chen}, S.~{Sidor}, and I.~{Sutskever}, ``{Evolution
  Strategies as a Scalable Alternative to Reinforcement Learning},''
  \emph{ArXiv e-prints}, Mar. 2017.

\bibitem{Grozea2010}
\BIBentryALTinterwordspacing
C.~Grozea, Z.~Bankovic, and P.~Laskov, \emph{FPGA vs. Multi-core CPUs vs. GPUs:
  Hands-On Experience with a Sorting Application}.\hskip 1em plus 0.5em minus
  0.4em\relax Berlin, Heidelberg: Springer Berlin Heidelberg, 2010, pp.
  105--117. [Online]. Available:
  \url{https://doi.org/10.1007/978-3-642-16233-6_12}
\BIBentrySTDinterwordspacing

\bibitem{Shackleford2001}
\BIBentryALTinterwordspacing
B.~Shackleford, G.~Snider, R.~J. Carter, E.~Okushi, M.~Yasuda, K.~Seo, and
  H.~Yasuura, ``A high-performance, pipelined, fpga-based genetic algorithm
  machine,'' \emph{Genetic Programming and Evolvable Machines}, vol.~2, no.~1,
  pp. 33--60, Mar 2001. [Online]. Available:
  \url{https://doi.org/10.1023/A:1010018632078}
\BIBentrySTDinterwordspacing

\bibitem{initializationIntervalXilinx}
\BIBentryALTinterwordspacing
Xilinx. (2020) Loop pipelining and loop unrolling. [Online]. Available:
  \url{https://www.xilinx.com/support/documentation/sw_manuals/xilinx2015_2/sdsoc_doc/topics/calling-coding-guidelines/concept_pipelining_loop_unrolling.html}
\BIBentrySTDinterwordspacing

\bibitem{BiSUNAGithub}
\BIBentryALTinterwordspacing
R.~Valencia. (2019, Sep) Binary spectrum-diverse unified neuroevolution
  architecture. [Online]. Available: \url{https://github.com/rval735/BiSUNA}
\BIBentrySTDinterwordspacing

\bibitem{Suda:2016:TOF:2847263.2847276}
\BIBentryALTinterwordspacing
N.~Suda, V.~Chandra, G.~Dasika, A.~Mohanty, Y.~Ma, S.~Vrudhula, J.-s. Seo, and
  Y.~Cao, ``Throughput-optimized opencl-based fpga accelerator for large-scale
  convolutional neural networks,'' in \emph{Proceedings of the 2016 ACM/SIGDA
  International Symposium on Field-Programmable Gate Arrays}, ser. FPGA
  '16.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: ACM, 2016, pp.
  16--25. [Online]. Available: \url{http://doi.acm.org/10.1145/2847263.2847276}
\BIBentrySTDinterwordspacing

\bibitem{Nurvitadhi:2017:FBG:3020078.3021740}
\BIBentryALTinterwordspacing
E.~Nurvitadhi, G.~Venkatesh, J.~Sim, D.~Marr, R.~Huang, J.~Ong Gee~Hock, Y.~T.
  Liew, K.~Srivatsan, D.~Moss, S.~Subhaschandra, and G.~Boudoukh, ``Can fpgas
  beat gpus in accelerating next-generation deep neural networks?'' in
  \emph{Proceedings of the 2017 ACM/SIGDA International Symposium on
  Field-Programmable Gate Arrays}, ser. FPGA '17.\hskip 1em plus 0.5em minus
  0.4em\relax New York, NY, USA: ACM, 2017, pp. 5--14. [Online]. Available:
  \url{http://doi.acm.org/10.1145/3020078.3021740}
\BIBentrySTDinterwordspacing

\bibitem{9070311}
J.~{Lant}, J.~{Navaridas}, A.~{Attwood}, M.~{Lujan}, and J.~{Goodacre},
  ``Enabling standalone fpga computing,'' in \emph{2019 IEEE Symposium on
  High-Performance Interconnects (HOTI)}, Aug 2019, pp. 23--26.

\bibitem{Moore-1991-13223}
A.~Moore, ``Efficient memory-based learning for robot control,'' Ph.D.
  dissertation, Carnegie Mellon University, Pittsburgh, PA, March 1991.

\bibitem{Dietterich:2000:HRL:1622262.1622268}
\BIBentryALTinterwordspacing
T.~G. Dietterich, ``Hierarchical reinforcement learning with the maxq value
  function decomposition,'' \emph{J. Artif. Int. Res.}, vol.~13, no.~1, pp.
  227--303, Nov. 2000. [Online]. Available:
  \url{http://dl.acm.org/citation.cfm?id=1622262.1622268}
\BIBentrySTDinterwordspacing

\end{thebibliography}
