% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{JMLR:v18:16-456}
\BIBentryALTinterwordspacing
I.~Hubara, M.~Courbariaux, D.~Soudry, R.~El-Yaniv, and Y.~Bengio, ``Quantized
  neural networks: Training neural networks with low precision weights and
  activations,'' \emph{Journal of Machine Learning Research}, vol.~18, no. 187,
  pp. 1--30, 2018. [Online]. Available:
  \url{http://jmlr.org/papers/v18/16-456.html}
\BIBentrySTDinterwordspacing

\bibitem{SCHMIDHUBER201585}
\BIBentryALTinterwordspacing
J.~Schmidhuber, ``Deep learning in neural networks: An overview,'' \emph{Neural
  Networks}, vol.~61, pp. 85 -- 117, 2015. [Online]. Available:
  \url{http://www.sciencedirect.com/science/article/pii/S0893608014002135}
\BIBentrySTDinterwordspacing

\bibitem{vitis-ai}
\BIBentryALTinterwordspacing
Xilinx. (2020) Vitis ai. [Online]. Available:
  \url{https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html}
\BIBentrySTDinterwordspacing

\bibitem{altera-ai}
\BIBentryALTinterwordspacing
Intel. Fpgas for artificial intelligence (ai). [Online]. Available:
  \url{https://www.intel.com/content/www/us/en/artificial-intelligence/programmable/overview.html}
\BIBentrySTDinterwordspacing

\bibitem{electronics8060661}
\BIBentryALTinterwordspacing
T.~Simons and D.-J. Lee, ``A review of binarized neural networks,''
  \emph{Electronics}, vol.~8, no.~6, 2019. [Online]. Available:
  \url{https://www.mdpi.com/2079-9292/8/6/661}
\BIBentrySTDinterwordspacing

\bibitem{8425178}
Y.~Hu, J.~Zhai, D.~Li, Y.~Gong, Y.~Zhu, W.~Liu, L.~Su, and J.~Jin, ``Bitflow:
  Exploiting vector parallelism for binary neural networks on cpu,'' in
  \emph{2018 IEEE International Parallel and Distributed Processing Symposium
  (IPDPS)}, May 2018, pp. 244--253.

\bibitem{Tang2017HowTT}
W.~Tang, G.~Hua, and L.~Wang, ``How to train a compact binary neural network
  with high accuracy?'' in \emph{AAAI}, 2017.

\bibitem{8953134}
R.~{Valencia}, C.~{Sham}, and O.~{Sinnen}, ``Using neuroevolved binary neural
  networks to solve reinforcement learning environments,'' in \emph{2019 IEEE
  Asia Pacific Conference on Circuits and Systems (APCCAS)}, Nov 2019, pp.
  301--304.

\bibitem{NIPS2019_8736}
\BIBentryALTinterwordspacing
X.~Sun, J.~Choi, C.-Y. Chen, N.~Wang, S.~Venkataramani, V.~V. Srinivasan,
  X.~Cui, W.~Zhang, and K.~Gopalakrishnan, ``Hybrid 8-bit floating point (hfp8)
  training and inference for deep neural networks,'' in \emph{Advances in
  Neural Information Processing Systems 32}, H.~Wallach, H.~Larochelle,
  A.~Beygelzimer, F.~Alch\'{e}-Buc, E.~Fox, and R.~Garnett, Eds.\hskip 1em plus
  0.5em minus 0.4em\relax Curran Associates, Inc., 2019, pp. 4900--4909.
  [Online]. Available:
  \url{http://papers.nips.cc/paper/8736-hybrid-8-bit-floating-point-hfp8-training-and-inference-for-deep-neural-networks.pdf}
\BIBentrySTDinterwordspacing

\bibitem{8977877}
R.~{Valencia}, C.~W. {Sham}, and O.~{Sinnen}, ``Evolved binary neural networks
  through harnessing fpga capabilities,'' in \emph{2019 International
  Conference on Field-Programmable Technology (ICFPT)}, Dec 2019, pp. 395--398.

\bibitem{10.1145/3377929.3389933}
\BIBentryALTinterwordspacing
R.~H.~V. Tenorio, C.~W. Sham, and D.~V. Vargas, ``Preliminary study of applied
  binary neural networks for neural cryptography,'' in \emph{Proceedings of the
  2020 Genetic and Evolutionary Computation Conference Companion}, ser. GECCO
  '20.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association
  for Computing Machinery, 2020, pp. 291--292. [Online]. Available:
  \url{https://doi.org/10.1145/3377929.3389933}
\BIBentrySTDinterwordspacing

\bibitem{9087264}
M.~Y. {Ibrahim}, R.~{Sridhar}, T.~V. {Geetha}, and D.~S. {S}, ``Advances in
  neuroevolution through augmenting topologies -- a case study,'' in \emph{2019
  11th International Conference on Advanced Computing (ICoAC)}, Dec 2019, pp.
  111--116.

\bibitem{alveoU50}
\BIBentryALTinterwordspacing
Xilinx. (2020) Alveo u50. [Online]. Available:
  \url{https://www.xilinx.com/products/boards-and-kits/alveo/u50.html}
\BIBentrySTDinterwordspacing

\bibitem{Zhao:2016aa}
W.~Zhao, H.~Fu, W.~Luk, T.~Yu, S.~Wang, B.~Feng, Y.~Ma, and G.~Yang, ``F-cnn:
  An fpga-based framework for training convolutional neural networks,'' in
  \emph{2016 IEEE 27th International Conference on Application-specific
  Systems, Architectures and Processors (ASAP)}, 2016, pp. 107--114.

\bibitem{gpgpu-ai-dominance}
\BIBentryALTinterwordspacing
J.~Kobielus. (2019) Gpus continue to dominate the ai accelerator market for
  now. [Online]. Available:
  \url{https://www.informationweek.com/big-data/ai-machine-learning/gpus-continue-to-dominate-the-ai-accelerator-market-for-now/a/d-id/1336475}
\BIBentrySTDinterwordspacing

\bibitem{8594633}
A.~{Shawahna}, S.~M. {Sait}, and A.~{El-Maleh}, ``Fpga-based accelerators of
  deep learning networks for learning and classification: A review,''
  \emph{IEEE Access}, vol.~7, pp. 7823--7859, 2019.

\bibitem{2017arXiv170303864S}
T.~{Salimans}, J.~{Ho}, X.~{Chen}, S.~{Sidor}, and I.~{Sutskever}, ``{Evolution
  Strategies as a Scalable Alternative to Reinforcement Learning},''
  \emph{ArXiv e-prints}, Mar. 2017.

\bibitem{BiSUNAGithub}
\BIBentryALTinterwordspacing
R.~Valencia. (2019, Sep) Binary spectrum-diverse unified neuroevolution
  architecture. [Online]. Available: \url{https://github.com/rval735/BiSUNA}
\BIBentrySTDinterwordspacing

\bibitem{Nurvitadhi:2017:FBG:3020078.3021740}
\BIBentryALTinterwordspacing
E.~Nurvitadhi, G.~Venkatesh, J.~Sim, D.~Marr, R.~Huang, J.~Ong Gee~Hock, Y.~T.
  Liew, K.~Srivatsan, D.~Moss, S.~Subhaschandra, and G.~Boudoukh, ``Can fpgas
  beat gpus in accelerating next-generation deep neural networks?'' in
  \emph{Proceedings of the 2017 ACM/SIGDA International Symposium on
  Field-Programmable Gate Arrays}, ser. FPGA '17.\hskip 1em plus 0.5em minus
  0.4em\relax New York, NY, USA: ACM, 2017, pp. 5--14. [Online]. Available:
  \url{http://doi.acm.org/10.1145/3020078.3021740}
\BIBentrySTDinterwordspacing

\bibitem{Umuroglu:2017:FFF:3020078.3021744}
\BIBentryALTinterwordspacing
Y.~Umuroglu, N.~J. Fraser, G.~Gambardella, M.~Blott, P.~Leong, M.~Jahre, and
  K.~Vissers, ``Finn: A framework for fast, scalable binarized neural network
  inference,'' in \emph{Proceedings of the 2017 ACM/SIGDA International
  Symposium on Field-Programmable Gate Arrays}, ser. FPGA '17.\hskip 1em plus
  0.5em minus 0.4em\relax New York, NY, USA: ACM, 2017, pp. 65--74. [Online].
  Available: \url{http://doi.acm.org/10.1145/3020078.3021744}
\BIBentrySTDinterwordspacing

\bibitem{NIPS2015_5647}
M.~Courbariaux, Y.~Bengio, and J.-P. David, ``Binaryconnect: Training deep
  neural networks with binary weights during propagations,'' in \emph{Advances
  in Neural Information Processing Systems 28}, C.~Cortes, N.~D. Lawrence,
  D.~D. Lee, M.~Sugiyama, and R.~Garnett, Eds.\hskip 1em plus 0.5em minus
  0.4em\relax Curran Associates, Inc., 2015, pp. 3123--3131.

\bibitem{2016arXiv160601540B}
G.~{Brockman}, V.~{Cheung}, L.~{Pettersson}, J.~{Schneider}, J.~{Schulman},
  J.~{Tang}, and W.~{Zaremba}, ``{OpenAI Gym},'' \emph{arXiv e-prints}, Jun.
  2016.

\end{thebibliography}
