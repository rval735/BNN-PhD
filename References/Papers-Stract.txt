Use Haskell-Clash to develop a CNN for HFT

------> Fin

Adjoints and automatic (algorithmic) differentiation in computational finance
- Use AD to reduce computation time, increase accuracy 
- Create an "adjoint" for reverse computations
- Applied to Monte Carlo Simulations for the Greeks

------> CNN

Applications of Convolutional Neural Networks
- Describe different known applications of CNN
- Computer vision and Natural language processing as their main applications
- Improvements over LSTM RNN, SVN

Recent Advances in Convolutional Neural Networks
- The CNN tree of components, optimizations and applications
- Link to other publications about types of CNN
- General applications in which CNN have been used
- General explanation of how CNN works

Wavelet pooling for convolutional neural networks
- Use wavelet pooling to reduce feature dimensions.
- Uses MatConvNet
- Executed on Intel i7-6800K, 64GB
- MIST, CIFAR, SHVN and KDEF as its applications

Automatic differentiation in machine learning- a survey
- Use automatic diff for gradient decent learning techniques
- Explains what AD is not: numerical diff, symbolic diff.
- Explains how to perform AD and its modes
- How AD and back propagation relate

Deep Convolutional Inverse Graphics Network
- Propose a new architecture for NN using (de)convolutions
- Outputs resistant to rotations, translations or light changes
- Training using "Stochastic Gradient Variational Bayes"
- Image input -> new images with different pose or light
- Applications as well for 3D rendering

Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
- Use convolution and LSTM to extract text information from images
- Flickr8k, Flickr30k and MS COCO datasets with BLEU and METEOR metrics
- MS COCO trained for 3 days using a Titan GPU
- It explains two stochastic attentions: soft and hard

Convolutional Neural Network on Neural Compute Stick for Voxelized Point-clouds Classification
- Used CNN for object recognition on volumetric data
- Proposed a 3D voxelized cloud points generation
- Voxel tree representation "VOLA" (Volumetric accelerator)
- Used Movidious Neural Compute USB stick to accelerate the training (~1.2W)

Eyeriss- An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks
- Eyeriss is a chip designed for CNN operations
- Caffe runs on Jetson TK1 <-> PCI-Express of Xilinx VC707 <-> Eyeriss
- Eyeriss is a 65nm, 200MHz, 168 PE, 16bit fixed point and adaptively-fixed CNN shapes
- Native support for Caffe
- Used AlexNet (227x227) and VGG-16 (224x224)

Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning
- Energy-aware pruning algorithm for CNNs 
- Uses the energy consumption to guide the pruning process
- Minimizes error in the output feature maps instead of weights filter
- Reduce energy consumption: AlexNet (3.7x) and GoogLeNet (1.6x)
- Accuracy after pruning, less than 1% loss

Genetic CNN
- Encoding method to represent each network structure in a fixed-length binary string
- Genetic algorithm is only used to modify structures like VGGNet, ResNet and DenseNet
- Tested on ILSVRC(50i, 76.58%), MNIST (50i, 99.62%a) and CIFAR (i= iteration, %a= average)
- Improves marginally on state of the art publications with genetically generated CNNs
- Training CNNs still happens using traditional BP
- Fitness function of each individual is determined by its recognition accuracy on a reference dataset

Designing architectures of convolutional neural networks to solve practical problems
- Propose mechanisms to estimate effective CNN configurations based on FNN
- False Nearest Neighbors, used in dynamical systems, helps to estimate CNN architectures
- FNN transforms images and builds high dimensional space vectors
- Datasets: CMU, MNISt, COIL, GTSRB
- This paper CNN compare in error rates at a lower complexity
- FNN method iteratively increases the dimension of the phase space, measuring, at each step, how much neighborhood relations change

Evolutionary convolutional neural networks: An application to handwriting recognition
- Automatic design of CNN topologies
- Common framework with novel solutions based on genetic algorithms (GA) and grammatical evolution (GE)
- MNIST data set tested
- GE provides a more flexible definition of the phenotype and simultaneously prevents some of the redundancies present in the GA encoding
- Neuroevolution is an interesting field to explore the automatic design of NN topologies,
- Requires a fraction of the time and no manual intervention

Non-local Neural Networks
-
-
-

Deep Residual Learning for Image Recognition
-
-
-

ImageNet Classification with deep convolutional neural networks
-
-
-

SqueezeNet- AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size
-
-
-

HyperNetworks
-
-
-

An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution
-
-
-

BING- Binarized Normed Gradients for Objectness Estimation at 300fps
- Experiments performed on PASCAL VOC 2007 dataset with 96.2% object detection rate
- BING uses atomic updates (BITWISE SHIFT and BITWISE OR) to avoid the loop computing
- Can process object windows at 300fps, while other methods require several seconds for one image

On Face Segmentation, Face Swapping, and Face Perception
- Paper on face swap, related to DeepFakes
- Full source code provided
- Uses a CNN to make fast and accurate segmentations, then swap faces
- Base their technique on generative models to make 3D face shape blend estimation

Very deep convolutional networks for large-scale image recognition
-
-
-

Densely Connected Convolutional Networks
-
-
-

Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning
- Pure Inception variant without residual connections with roughly the same recognition performance as Inception-ResNet-v2
- Introduction of residual connections leads to dramatically improved training speed for the Inception architecture
- ImageNet 20% error (4.9 top-5)

Visualizing and Understanding Recurrent Networks
- Proves an analysis of their representations, predictions and error types
- Reveal the existence of interpretable cells that keep track of long-range dependencies such as line lengths, quotes and brackets
- Penn Treebank, War and Piece, Linux Kernel and Hutter Price datasets

Convolutional Networks for Fast, Energy-Efficient Neuromorphic Computing
- Develops the "TrueNorth" chip, which consists of a network of neurosynaptic cores with programmable connectivity, synapses, and neuron parameters
- Uses a variant of an integrate-and-fire model with 23 configurable parameters 
- Tests with CIFAR. SVHN, GTSRB, FlickrLogos, VAD and TIMIT

Progressive Neural Architecture Search
- Search the space in a progressive order, simplest models first
- A learned predictor function is trained based on the measured performance of the cells we have visited so far, picking the K most promising ones
- Tested on CIFAR-10(96.59) and ImageNet (82.9)

Encrypted Traffic Classification with a Convolutional Long Short-Term Memory Neural Network
- This model extracts features in both the packet level and the flow level automatically
- Can improve the accuracy of traffic classification by 5% in comparison with the
state-of-art work, with VPN traffic dataset
- Chooses any three consecutive packets in a flow and even if basic flow information is removed, their model can still achieve excellent results

MSCryptoNet- Multi-Scheme privacy-preserving deep learning in cloud computing
- Collaborative privacy-preserved DNN architecture based on a fully homomorphic cryptosystem
- NNs are free from loss of accuracy and efficient while training on different encrypted datasets
- Communication overhead is reduced along with the amount of data needed to transfer

Privacy-Preserving All Convolutional Net Based on Homomorphic Encryption
- Rectified Linear can have a good low-degree polynomial approximation by combining the Taylor series of the ReLU function with the batch normalization
- Converting floating-point numbers with fixed precision to integers by proper scaling
- Make sure the correctness of the calculation, we must control the scale of the number and increase the modulus t to avoid modulo operation
- Applied over MNIST with prediction over encrypted data with accuracy of 98.97%

Fast Homomorphic Evaluation of Deep Discretized Neural Networks
- Complexity is strictly linear in the depth of the network and whose parameters can be set beforehand
- Rely heavily on the bootstrapping procedure that offer an improvement in efficiency at the cost of increasing the storage requirements
- It discretized an already-trained model
- MNIST dataset where all images were binarized with a threshold value equal to 128; with more than 96% accuracy in less than 1.7 s.

Hybridizing Evolutionary Computation and Deep Neural Networks- An Approach to Handwriting Recognition Using Committees and Transfer Learning
-
-
-

Secure Convolutional Neural Networks using FHE
-
-
- 

A Topological Study of Chaotic Iterations Application to Hash Functions
-
-
-

< CNN

------> CNN-Fin

Intraday prediction of Borsa Istanbul using convolutional neural networks and feature correlations
- Use of CNN to predict stock market price movement using random and naïve   series
- CNN better than Macro Average F-Measure for random and correlated features
- Istanbul stock exchange

Forecasting Stock Prices from the Limit Order Book using Convolutional Neural Networks 
- CNN better than RNN, RBM (Restricted Boltzmann Machine), SVM (Support Vector Machines)
- Taiwan stock exchange

Financial Time-series Data Analysis using Deep Convolutional Neural Networks 
- Transform data into an image
- Executed on a CPU using Matlab

Deep learning for event-driven stock prediction
- Use news as a feature in the CNN
- Comparison of different CNN for market prediction
- NN vs CNN
- Profitability of the CNN against other publications
- S&P stocks

Convolutional Neural Networks Applied to High-Frequency Market Microstructure Forecasting 
- Confirmation of CNN works "reasonably well" on forecasting price trend
- Explains the structure of their CNN for order book and event flow

Multi-Scale Convolutional Neural Networks for Time Series Classification
- Use Multi-Scale CNN for time series classification
- MCNN unifies classification, feature extraction and back propagation
- Comprehensive benchmarking against other TSC algorithms

Conditional Time Series Forecasting with Convolutional Neural Networks
- Use wave CNN to make TSF
- S&P,  Forex and CBOE interest rate as base data
- Comparison against Naïve, LSTM and VAR

Artificial Neural Networks architectures for stock price prediction comparisons and applications
- Implementation of MLP, CNN, LSTM
- Comparison of their performance
- CNN are better than other architectures
- An novel Wavelet-CNN was implemented.

Reading the Tea Leaves- A Neural Network Perspective on Technical Trading
- Use technical analysis for price prediction
- CNN, RNN and many other DNN models tested
- It concludes 'there is no evidence of predictive prowess'

Deep learning for stock market prediction from financial news articles
- Use RCNN compared against other type of CNN
- Use two sources: news and technical indicators
- Prefer sentence embedding rather than word embedding

Finance time series prediction using complex-valued flexible neural tree model
-
-
-

< CNN-Fin

------> NN-Fin

A Deep Neural-Network Based Stock Trading System Based on Evolutionary Optimized Technical Analysis Parameters 
- Use of NN un a trading system for 30 stocks of the Dow
- Next steps are going to make a CNN 
- Use SMA and RSI 

Adaptive Neuro Fuzzy Inference Systems for High Frequency Financial Trading and Forecasting
- Another Machine learning technique: Adaptive Neuro-Fuzzy Inference System
- Use Sharpe and Sortino ratio
- Comparison against buy and hold
- FOREX for EUR/USD

Using Recurrent Neural Networks To Forecasting of Forex
- Use NN for time series forecasting
- CHF, GBP, Euro and JPN
- Use this as a relation with Bitcoin exchange

Deep learning networks for stock market analysis and prediction - Methodology, data representations, and case studies
- Comprehensive review of current publications
- Use data from the Korean Stock market
- Uses a simple DNN with 3 layers

Adaptive Hybrid Higher Order Neural Networks for Prediction of Stock Market Behavior
- Use Pi-Sigma HONN to make market predictions
- Used for Index and stocks in the USA market
- Used a genetic algorithm and compared that with a gradient decent
- Improved case of GA over GD

Two-Step Disentanglement for Financial Data
- Compare their proposed method with CAPM, Black-Sholes and GAN
- Use their method with MNIST, Sprites NORB, YaleB databases
- Used Nasdaq, NYSE, and AMEX data from 1976-2009
- Beta, rho and mean as benchmarks.
- "our algorithm encodes it as two separate parts, one that keeps the information regarding the labels and the other that is agnostic to the labels"

New Neural Networks Based on Taylor Series and their Research
- Propose NNs based on: Taylor series, a radial basis neuron and Fourier component neuron
- Mentions financial datasets, but no consistent results are provided
- It also proposes the combination of different types: Fourier, gauss or taylor components

An Efficient Neural Network Model with Taylor Series-Based Data Pre-processing for Stock Price Forecast
- Use fundamental and technical EPS and MACD as input data
- Hand picked stock data of some Taiwan public companies
- Their model mentions a remarkable return and high accuracy strategies
- It applies the form of Taylor series to preprocess data

Functional data learning by Hilbert feedforward neural networks
- The "Hilbert parallel overrelaxation backpropagation (HPORBP) algorithm" is proposed
- Mentioned that HPORBP has better accuracy than the Hilbert backpropagation algorithm
- It has embedded considerations for parallel execution

Stock Transaction Prediction Modeling and Analysis Based on LSTM
-
-
-

Efficient Memory-based Learning for Robot Control
-
-
-

Designing Safe,  Profitable Automated Stock Trading Agents Using Evolutionary Algorithms
-
-
-

Working with OpenCL to Speed Up a Genetic Programming Financial Forecasting Algorithm- Initial Results
- EDDIE financial forecasting tool executed on GPUs
- Speed ups up to 21 times faster than the original EDDIE algorithm
- GPUs were slower in their implementation tahn CPU

EDDIE-Automation, a decision support tool for financial forecasting
- Evolutionary Dynamic Data Investment Evaluator (EDDIE) is a genetic programming (GP)-based decision support tool for financial forecasting
- Improve the productivity of experts in searching the space of decision trees
- EDDIE-Automation 1.0 enables the users to conduct large-scale learning to fill the good-rules bank, the more rule sets one generates, the more chance that one could spot in- vestment opportunities or combine recommendations 

Empirical Asset Pricing via Machine Learning
-
-
-

< NN-Fin

------> FPGA

Recent Trends in FPGA Architectures and Applications
- Current state for platforms and tools of FPGAs
- Where FPGA are being used: radio astronomy, chip multiprocessor emulation,
particle physics and derivate pricing


Accelerating Large-Scale HPC Applications Using FPGAs
- Use FPGA to accelerate High performance computing
- Comparison with x86
- Modeling wave propagation and credit derivates as its applications

A Pythonic Approach for Rapid Hardware Prototyping and Instrumentation
- Use python as HDL language
- Runs on a Xilinx PynQ Platform
- Also allows simulation within the board

Floating-point bitwidth analysis via automatic differentiation
- Use AD to analyze the circuit and specify floating point precision
- Applied to D-FFT and Finite Impulse Response filter
- C++ implementation

Combined Spatial and Temporal Blocking for High-Performance Stencil Computation on FPGAs Using OpenCL
- Compare GPU vs FPGA for 2D/3D stencil computations
- Implemented on OpenCL
- Better performance despite lower memory bandwidth
- Simpler FPGA code rather than GPU implementations

Reconfigurable computing for Monte Carlo simulations: results and prospects of the Janus project
-
-
-

Floating-Point DSP Block Architecture for FPGAs
- Proposes a new DSP that provides fixed and FP functions integrated into the FPGA fabric
- High density of over 1600 single precision FP DSP block (20nm) adn 1.6 TFLOP
- 700K LUT device will require 17% for the equivalent of 1600 DSP blocks

High-Performance Parallel Implementation of Genetic Algorithm on FPGA
- Optimization of the system’s processing time and area occupancy for various population sizes are analyzed
- Focus on high-performance and critical applications that require nanoseconds time constraints to be satisfied
- Population of 64. 6598 FF, 58 875 (16%) LUT at 34.56MHz, 161700 Gen/sec
- Tests with math functions, different populations and Virtex 7 FPGA

Design Paradigms of Intelligent Control Systems on a Chip
- Functionality verification of a parameterized fuzzy logic processor core followed by a
modified architecture for faster data processing
- Scalable genetic algorithm processor core is presented and evaluated using the Traveling Salesman Problem (TSP)
- TSP in hardware takes 1.7ms vs 18 783ms (11035x)

Parallel Genetic Algorithms on Multiple FPGAs
- Steady-state GA which can be configured using run-time parameters, removing the need for expensive recompilation
- 30x speedup achieved compared to a multi-core CPU-based implementation
- Applied to Function 11, the Locating problem and the Travelling Salesman Problem
- A system with more FPGAs takes fewer generations to obtain satisfactory fitness

Hardware implementation of genetic algorithm on FPGA
- parallel-pipelined hardware genetic algorithm (PPHGA) utilizing very high speed integrated circuit hardware
- Modules are autonomous in operation once the system starts; communication with each other uses a handshaking protocol
- Applied to Thermistor data processing, linear function interpolation and vehicle lateral acceleration

A High-Performance, Pipelined, FPGA-Based Genetic Algorithm Machine
- GA features: random parent selection (conserves circuitry); steady-state memory model (conserves chip area); survival of fitter (promotes evolution)
- Pipelining parent selection, crossover, mutation, and fitness evaluation functions
- 1Mhz FPGA is 2,200× faster than a 100 MHz workstation running the same algorithm in C
- 66 MHZ FPGA solves a 36-residue protein folding problem 320× faster than a 366 MHz Pentium II

FPGA-Based System for the Acceleration of Cloud Microservices
- Demonstrates how FPGAs share logic resources among several microservices
- Decomposed the FPGA into multiple acceleration slots that are shared among concurrent microservices that run on the server side
- Hardware can be changed at runtime thanks to the FPGA’s partial reconfiguration capabilities

Understanding Performance Differences of FPGAs and GPUs
-
-
-

Exploring Functional Acceleration of OpenCL on FPGAs and GPUs Through Platform-Independent Optimizations
-
-
-

< FPGA

------> FPGA-NN

ESE- Efficient Speech Recognition Engine with Sparse LSTM on FPGA
- Implement a LSTM on Xilinx XCKU060 
- 3x faster than GPU Pascal Titan
- 11.5x efficient GPU
- Used Sparse Matrix-vector Multiplication with 16bit wide elements (12quant + 4index)

Hardware-efficient on-line learning through pipelined truncated-error backpropagation in binary-state networks
- Trained with MNIST data
- Implemented on a Spartan 6 FPGA
- On-line learning technique for FF-NN based on pipelined backpropagation
- Removes the need for an explicit backward pass
- Used Binary State Networks instead of common spiked ones

Towards a Multi-array Architecture for Accelerating Large-scale Matrix Multiplication on FPGAs
- Novel implementation of Matrix multiplication
- Applied to CNN
- Computes floating point operations
- Dynamic creation of "PE" to compute matrix elements

Development and Implementation of Parameterized FPGA-Based General Purpose Neural Networks for Online Applications
- Show a "Generalized backpropagation multilayer perceptron" on FPGAs
- Tries to minimize cost, maximize accuracy, performance and parametrization
- Divide neurons into "Processing Elements"
- It considers online training of the NN

Artificial Neural Network Implementation on a single FPGA of a Pipelined On- Line Backpropagation
- Implements a systolic array for multilayer perceptron
- Used a Virtex XCV400
- Pipelined adaptation of the back-propagation algorithm
- Uses two degrees of parallelism: synapse-oriented and forward-backward parallelism

EIE- Efficient Inference Engine on Compressed Deep Neural Network
- ASIC for compressed NN which is more energy efficient
- Better performance than DaDianNao, TrueNorth, GPU or FPGA implementations
- It leverages sparcity of activations and weights
- Also considers quantization and weight sharing
- Smaller models also improve data transfer to local SRAM rather than DRAM
- Almost linear scale from 1 to 256 PE, fabricated on 28nm and 2.36W

Accelerating CNN inference on FPGAs- A Survey
- Survey of current techniques used for CNN accelerated by FPGAs
- Explain CNN elements, types of parallelism
- Different approaches: algorithmic, datapath, model optimizations and hardware generation 
- Reduce computations: weight pruning, rank approximation.

Fast inference of deep neural networks in FPGAs for particle physics
- Datasets from the LHC: classifier for jet substructure, aka, searches for dark sector particles
- Open source HLS Library called hls4ml to build machine learning models in FPGA
- FPGA implementations must account for data latency and throughput
- Efficient network design consider: parallelization, quantization and compression

F-CNN- An FPGA-based framework for training Convolutional Neural Networks
- Reconfiguring a streaming data path at runtime for training CNN
- Maxeler technology can achieve a performance of 62.06 GFLOPS for 32-bit floating point
- Training LeNet-5 is 4x faster than CPU and 7.5x more energy efficient than GPU

Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey and Future Directions
- Full survey on current development of FPGA frameworks to run CNN
- It talks generally about interface, hardware, portability.
- Hardware architecture is divided in streaming and single computation engines

Throughput-Optimized OpenCL-based FPGA Accelerator for Large-Scale Convolutional Neural Networks
- Implementation of a CNN into a FPGA using OpenCL
- AlexNet and VGG running on P395-D8 and DE5-Net FPGA boards
- ImageNet classification with peak performance of 136.5 GOPS for convolutions; 117.8 GOPS for the entire VGG network
- 8-bit convolution weights precision and 10-bit inner product weights precision

PipeCNN: An OpenCL-Based FPGA Accelerator for Large-Scale Convolution Neuron Networks
- FPGA accelerator with a new architecture of deeply pipelined OpenCL kernels
- AlexNet and VGG on Altera Stratix-V A7 FPGA
- 33.9 GOPS with a 34% resource reduction on DSP blocks compared to previous work
- Open source code located in https://github.com/doonny/PipeCNN

Can FPGAs Beat GPUs in Accelerating Next-Generation Deep Neural Networks
- Thorough comparison of execution advantages of FPGA over GPUs
- "FPGAs offer superior energy efficiency (Ops/Watt), but they do not offer the performance of today’s GPUs on DNNs"
- Evaluation of two FPGA generations (Aria/Stratix 10) vs GPU (Titan X)
- Full/Ternary RestNet NN implementation; BNN with 5.4 better performance (TOP/Sec) than Titan X (28nm) GPU

An OpenCL Deep Learning Accelerator on Arria 10
- Maximizes data reuse and minimizes external memory bandwidth
- Uses Winograd transform to significantly boost the performance of the FPGA
- Arria 10 achieves a performance of 1020img/s, or 23img/s/W when running the AlexNet CNN benchmark and ILSVRC dataset
- Uses half-precision (FP16) instead of single-precision (FP32) on PEs

Improving the Performance of OpenCL-based FPGA Accelerator for Convolutional Neural Network
- Quantitatively models the performance with respect to resource utilization for VGG model
- Memory performance limit on bandwidth (6x smaller) but PE 2D interconnection reduces that requirement
- 2D dispatcher with an optimized scheduling policy to minimize memory requirements and leverate CNN data locality
- Arria 10 achieves 1.79 TOP/s with 385MHz and 47.78 Gops/s/W energy efficiency
- CNN are bandwidth bounded, not latency bounded, of which streaming applications are as well affected

Going Deeper with Embedded FPGA Platform for Convolutional Neural Network
- 16 bit fixed point number on the Zynq706 board with 2 PE reaches 4.45 FPS (ImageNet)
- Limited bandwidth is one of the acceleration bottlenecks of CNN models in embedded systems
- CONV layers are computation centric and Fully connected memory centric
- Used VGG16-SVD with 86.66% top-5 accuracy (137 GOP/s) under 150Mhz

Reconfigurable FPGA implementation of neural networks
-
-
-

Throughput optimizations for FPGA-based deep neural network inference
-
-
-

A High-Performance Reconfigurable Accelerator for Convolutional Neural Networks
-
-
-

A survey of FPGA-based accelerators for convolutional neural networks
-
-
-

FPGA-based acceleration of neural network training
-
-
-

FPGA-based Accelerators of Deep Learning Networks for Learning and Classification: A Review
-
-
-

Neural Network Based Reinforcement Learning Acceleration on FPGA Platforms
-
-
-

< FPGA-NN
------> FPGA-Fin

Computing system and network architectures in high frequency trading financial applications
- Use Networked FPGAs to obtain sub-microsecond data transfer
- CUDA for HFT algorithm
- Comparison of different CUDA implementations
- x86 vs GPUs

A Hybrid Genetic-Programming Swarm-Optimisation Approach for Examining the Nature and Stability of High Frequency Trading Strategies
- Use genetic algorithms for HFT strategies
- FPGA performs the genetic calculations (15.62x over CPU)
- CPU - FPGA - CPU structure

A Low-Latency Library in FPGA Hardware for High-Frequency Trading (HFT)
- Sustain why low latency is important in HFT transactions
- Whole trading system in the FPGA
- Advantages and disadvantages of a whole system in a FPGA
- "Building and verifying new hardware is more time- consuming than writing new software due to the significantly lower abstraction level in the design flow"
- High throughput 6.1M FIX messages/sec
- FIX as protocol of communication

DSL programmable engine for high frequency trading acceleration
- FPGA vs x86 vs PowerPC
- FAST as protocol of communication
- Directly connected from network to FPGA
- Decreased latency, increased data rate
- DSL for programming via software

FPGA acceleration of quasi-Monte Carlo in finance
- Advantages of using  instead of x86
- Novel publication of quasi-Monte Carlo simulation

High-Performance Quasi-Monte Carlo Financial Simulation: FPGA vs. GPP vs. GPU
- Comparison of FPGA vs other computing architectures
- Financial derivates and QMC simulation
- Throughput and efficiency are compared
- Verilog for FPGA programming
- Speed Up of ~544X vs CPU; 50x vs GPU
- Consumption of 336x CPU, 16x GPU

Low latency book handling in FPGA for high frequency trading
- FPGA implementation of a order book
- Reduced lookup latency
- Large storage due to memory arrangements

Low-Latency FPGA Based Financial Data Feed Handler
- FPGA implementation for data feeds
- FPGA vs CPU
- Almost planar latency when feed rate is increased  on FPGA
- CPU varies linearly positive

Multiplierless Algorithm for Multivariate Gaussian Random Number Generation in FPGAs
- Comparison of FPGA vs CPU vs GPU
- Monte Carlo simulations
- 10x vs GPU, 100X vs CPU

Selection and implementation of high-performance platforms in finance
- The third report, talks about FPGA implementation of a Monte Carlo simulation
- It used Automatic Differentiation to improve on the system performance
- It gives an overall overview of the whole system design
- On the experiments, it shows an improvement of 200x over a Xeon CPU

Fast inference of deep neural networks in FPGAs for particle physics
-
-
-

< FPGA-Fin
------> CNN-FPGA

A General Neural Network Hardware Architecture on FPGA
- Description of a general NN running on a FPGA
- Base case for CNN, DNN, RNN
- Energy efficient and real time applications

A GPU-Outperforming FPGA Accelerator Architecture for Binary Convolutional Neural Networks
- Implementation of a binary CNN
- Comparison with GPU
- 75x more energy efficient
- 8.3x faster
- Applied to image classification

CirCNN - Accelerating and Compressing Deep Neural Networks Using Block-Circulant Weight Matrices
- Mentions ARM processors along with FPGA chips
- CirCNN implementation
- It is important to reduce CNN complexity to enhance scalability when the model size grows

F-CNN: An FPGA-based framework for training Convolutional Neural Networks
- F-CNN is FPGA-CNN
- Comparison vs CPU and GPU in efficiency and throughput
- Whole implementation, with special focus on training
- Applied for handwritten recognition
- Hybrid design: CPU controller, FPGA accelerator

Why TanH is a Hardware Friendly Activation Function for CNNs
- An alternative activation function for CNN
- Minimum number of circuits required to deploy a CNN
- Comparison of ReLU, Sigmoid and TanH

PipeCNN- An OpenCL-Based Open-Source FPGA Accelerator for Convolution Neural Networks
- Github code at: https://github.com/doonny/PipeCNN
- Full implementation of a CNN on a FPGA
- It uses OpenCL/C++ for code implementation
- It details improvements over other FPGA implementations (2015,2016)
- Implements AlexNet and VGG on a DE5-Net board (Stratix V GXA7)

Minitaur, an Event-Driven FPGA-Based Spiking Network Accelerator
- Used MNIST and 20 newsgroups classification data sets
- Development based on "Spiking" event-driven NN 
- Aims robotics as one of its applications
- Executed on a Xilinx Spartan 6 ZTEX board

FINN- A Framework for Fast, Scalable Binarized Neural Network Inference
- Used MNIST data for its tests
- Implemented on a FPGA Zynq UltraScale+ ZU19EG
- Used Binary NN: Binary input activations, binary synapse weights and binary output activations

Automated Systolic Array Architecture Synthesis for High Throughput CNN Inference on FPGAs
- Implements CNN on a FPGA using a systolic array architecture
- Used Intel OpenCL SDK
- A "Continuous Integration" scheme was used: from code to deployment
- AlexNet and VGG16 models were evaluated with 32bit floating points

NeuFlow- A Runtime Reconfigurable Dataflow Processor for Vision
- Uses Xilinx Virtex6 to  create a scalable dataflow architecture for GP vision algorithms
- Realtime detection, categorization and localization of objects in complex escenes
- 10Watts, 20 categories, 12 FPS with LuaFlow compiler
- Street scene parsing, a convolutional network was trained on the LabelMe spanish dataset
- 83ms vs 8s on a laptop

Quad-multiplier packing based on customized floating point for convolutional neural networks on FPGA
-
-
-

< CNN-FPGA

------> Haskell

Modeling of dynamic reconfigurable systems with Haskell
- Mathematical description of Run Time Reconfigurable systems
- Use high order functions to generalize rules of abstraction

Roll your own test bed for embedded real-time protocols: a Haskell experience
- Use QuickCheck to generate signals and statistical reliability analysis
- Emulate environments
- Test the physical layer networking

Haskell Ready to Dazzle the Real World
- Desired attributes of Haskell to use as a development language
- Bayesian networks with the Dazzle software program
- GUI interaction between Dazzle and wxHaskell

Financial Software on GPUs- Between Haskell and Fortran
- Haskell vs Fortran
- Describe a generic algorithm for pricing (monte carlo)
- Outline the benefits of FP for functional parallelization

Functional Differentiation of Computer Programs
- Presents an implementation of "Computational Differentiation" (AD synonimn)
- Uses haskell to make that implementation
- Brief introduction to Differential Algebra and its operators
- Applications: Hermite, Lambert functions, WKB expansions, etc

The simple essence of automatic differentiation
- Simplified abstractions about AD
- Use category theory to explain AD with simple terms
- Special emphasis in Forward and Reverse AD for backpropagation
- Theoretical proofs that RAD is more efficient and pararellizable

Compiling To Categories
- Use categorical abstractions to express functions
- With CCC, it is possible to link to Graphs, Circuits or Graphics
- Use Haskell tools to bridge to different platforms
- First approach to declare AD

Beautiful Differentiation
- It explains the details about Automatic Differentiation
- It gives a high level detail of how AD is implemented in haskell
- It generalizes for vector spaces

Autobahn- using genetic algorithms to infer strictness annotations
- Strictness annotations allow programmers to control the laziness of their programs
- AUTOBAHN is a tool that uses a genetic algorithm to automatically infer annotations
- improves runtime performance on NoFib benchmark programs an average of 8.5% and
up to 89%
- No case was found that degrades performance

A genetic algorithm framework using Haskell
- Haskell framework designed for the construction of GA
- Allows a fine control of the stochastic processes underlying the GA
- Functional programs enables logical reason about their properties.
- Traveling Salesman Problem (TSP) and inverted pendulum test benchmarks

Cartesian closed 2-categories and permutation equivalence in higher-order rewriting
-
-
-

< Haskell 

------> Haskell-FPGA

Haskell as a higher order structural hardware description language
- Published at the same time as "ClasH - From Haskell To Hardware"
- Defend hardware description as a mathematical function application

A mathematical approach towards hardware design 
- Defend that a functional design can be used for logic circuit deployments
- Use clash but also mentions bluespec
- Sustain how basic functions translate to circuits

A fine-grained parallel dataflow-inspired architecture for streaming applications
- Thesis where Haskell and Clash is used
- Description of logic circuits
- Dataflow and coarse-grained reconfigurable arrays used to defend the thesis

A transformation-based approach to hardware design using higher-order functions
- Thesis where Haskell and Clash is used
- Application particule filtering

A two step hardware design method using CλaSH
- A procedure to develop HDL programs with Haskell
- Particle filtering application
- Publication from (previous) thesis 

Comparing CλaSH and VHDL by implementing a dataflow processor
- in some cases, Clash can synthesize better than VHDL code
- Simpler to use a high level language for circuit design
- Application: Dataflow processor
- Less lines of code in clash vs VHDL
- Lower power consumption

ClasH - From Haskell To Hardware
- Master thesis outlining Clash
- Mentions other languages for HDL
- One case study: reduction circuit

Co-simulation between Clash and traditional HDLs
- Use cases for clash when using fpga simulators
- Use verilog procedural interface for the simulation

Specification of apertif polyphase filter bank in Clash
- One formal application of Clash: an apertif polyphase filter bank
- Improvements on performance and clock frequency

System-level modeling of dynamic reconfigurable designs using functional programming abstractions
- Use clash to assign a FPGA section as reconfigurable
- Run embedded linux on the platform

Hardware Synthesis from a Recursive Functional Language
- Haskell-to-hardware compilation framework based on a series of semantics-preserving transformations
- Operate on a common functional intermediate representation and support for recursion
- Stream-based dialect of this IR models synchronous digital hardware synthesizable to SystemVerilog

Hardware software co-design in Haskell
- Introduction of "Prog" as an extensible representation of imperative programs
- The library allows a single program description to be interpreted in many different ways: IO monad or hardware compilation
- Generates C and VHDL from the imperative software and hardware programs using an extensible compiler

The Reduceron- Widening the von Neumann Bottleneck for Graph Reduction using an FPGA
- Reduceron could actually be described by pure (non-monadic) Lava functions
- The combination of wide, parallel memory units and vectorised processing logic
gives a factor of six speed-up on average across a range of benchmark programs
- 91.5MHz on a Xilinx Virtex-II FPGA performs better than interpreted bytecode running on a 2.8GHz Pentium-4 PC

A Functional Approach to Hardware Software Co-Design
- Functional approach to heterogeneous system development, with a staged hardware software co-design language embedded in Haskell
- Build applications from reusable components and skeletons, while retaining control over much of the generated source code
- The co-design language is based on a monadic representation of imperative programs
- Uses AXI4-lite for ARM-FPGA communication
- Physical address of a hardware component has to be manually incorporated into a software program and memory-mapped

Hardware in Haskell- Implementing Memories in a Stream-Based World
- Proposes a sequence of abstractions lowering transformations that exposes recursive haskell program
- Using recursive Stream data type inspired by the Lustre language 
- Each "stream operator" becomes a hardware register
- Does not allow streams of streams
- Simple, syntax-directed translation to SystemVerilog

------> DNN

Deep Learning in Neural Networks - An Overview
- A whole survey on how DL has developed until 2014
- Explain origins of DL before 1940
- Special topics in DL: SL, RL, UL.
- References to CNN and its improvements

Deep reinforcement learning - an overview
- "Book" like publication explaining from ground up DNN and RL
- Outline several applications: games, robotics, NLP, Computer Vision, etc
- Provide a plethora of related resources

Wasserstein Learning of Deep Generative Point Process Models
- Use NYSE to train a NN for High frequency transactions
- Several databases with realtime data: MIMIC, Meme, MAS
- Compares its performance against other MLE procedures (¿Maximum Likelihood Estimate?)
- Uses "Temporal point processes" as its main differentiator
- Key words: Wasserstein distance training of RNN point process models

Towards a Deeper Understanding of Training Quantized Neural Networks
Training Quantized Nets- A Deeper Understanding
- Paper interested in explaining why some quantized NN behave in some applications
- Stochastic rounding lacks annealing properties required for non-convex optimization
- Used Quantized Optimization routines: deterministic, stochastic rounding and binary connect
- Binary Connect algorithm has the ability to concentrate on minimizers
- Stochastic Rounding is unable to exploit greedy local search

Opening the Black Box of Deep Neural Networks via Information
- Demonstrate the effectiveness of the Information-Plane visualization of DNNs
- The training time is dramatically reduced when adding more hidden layers
- Extend the theory around Information Theory of Deep Learning
- Information Bottleneck: framework for finding approximate minimal sufficient statistics, or the optimal tradeoff between compression of X and prediction of Y

Expectation Backpropagation- Parameter-Free Training of Multilayer Neural Networks with Continuous or Discrete Weights
-
-
-

Trust Region Policy Optimization
-
-
-

Differentiable plasticity- training plastic neural networks with backpropagation
- In an image reconstruction task, a network memorizes a set of natural images that it has never seen before, then the network reconstructs the missing half from memory
- Highly flexible, providing gradient descent with an elementary building block: plastic connection
- Offer a more efficient form of memory than recurrence alone 

On the Learning Capabilities of Recurrent Neural Networks- A Cryptographic Perspective
- Training RNN based models to learn various cryptographic tasks
- Quantify algorithm complexity properties by borrowing confusion and diffusion concepts
- Confusion: complexification between the ciphertext and clear text using a key
- Diffusion: dissipate the statistical structure of P which causes redundancy, into long range statistics

GAZELLE- a low latency framework for secure neural network inference
- Scalable and low-latency system for secure NN inference, using an intricate combination of homomorphic encryption and traditional two-party computation techniques
- GAZELLE is a homomorphic encryption library that uses SIMD addition, multiplication and ciphertext permutation
- GAZELLE also implements algebra kernels to map NN to optimized homomorphic matrix-vector multiplication and convolution routines
- Tested on MNIST and CIFAR-10
- reduction of 20-80× in the online bandwidth per inference

Unsupervised learning by competing hidden units
- Network with one hidden layer that generate codes for input images trained in a unsupervised way, then the output is fed into another SGD NN
- No top–down propagation of information, the synaptic weights are learned using only bottom–up signals.
- Algorithm is agnostic about the task that the network will have to solve eventually in the top layer
- Tested with MNIST (98.54%) and CIFAR (50.75%) datasets 

< DNN
-------> NN

Backwards Differentiation in AD and Neural Nets- Past Links and New Opportunities
- Explains Backwards calculation of derivates or "backpropagation"
- Relates it to Automatic Derivation
- Its application to NN

Pixel Recurrent Neural Networks
- Detail RNN with pixel by pixel spatial dimensions
- Use MNIST, CIFAR, and ImageNet as sources
- Description of a better Diagonal-BiLSTM network.

Auto-Encoding Variational Bayes
- Join a probabilistic model "Variational Bayes" as a gradient learning method
- Deep explanation of the mathematics behind their reasoning
- Uses monte carlo gradient estimator.
- MNIST and Frey Face datasets
- Auto-Encoding VB (AEVB), that learns an approximate inference model using the SGVB estimator

Generative Adversarial Imitation Learning
- New general framework for directly extracting a policy from data
- Describe "Inverse reinforcement learning"
- Uses math to sustain their approach
- This algorithm is evaluated against physics-based control tasks

VIME: Variational Information Maximizing Exploration
- Use "Variational bayes" for Reinforcement Learning
- Backup their statements with mathematical models
- VIME helps training real physical models like: MountainCar, CartPoleSwingup or SwimmerGather
- "VIME is a curiosity-driven exploration strategy for continuous control tasks"

DRAW: A Recurrent Neural Network For Image Generation
- Applied to MNIST, CIFAR, SVHN
- According to authors it is able to generate highly realistic natural images
- "Loss function is a variational upper bound on the log-likelihood of the data"
- Uses two stages: decoding <-> encoding for image generation
- Authors showcase their findings in a youtube video: https://www.youtube.com/watch?v=Zt-7MI9eKEo

Improving Variational Inference with Inverse Autoregressive Flow
- Applied to MNIST, CIFAR
- IAF is a new type of normalizing flow
- Faster sampling in CIFAR thanks to log-likelihood results
- Used variational autoencoders with bidirectional inference 

Equilibrated adaptive learning rates for non-convex
optimization
- An alternative to stochastic gradient decent
- Used MNIST and CURVES datasets
- Experiments ran on a GPU
- It compares its results at par with RMSProp

Generating Sequences With Recurrent Neural Networks
- Use LSTM to generate realistic sequences containing long range structure
- According to authors: "system is able to generate highly realistic cursive
handwriting"
- Can work predicting characters or words
- Used for Penn Treebank and Hutter Prize Wikipedia datasets for text
- IAM Online Handwriting Database for real value data

Recurrent Models of Visual Attention
- Scale image processing considering regions of training
- RNN with back-propagation
- Internal RNN determines which sections should be considered from the whole input
- "Trained end-to-end using a policy gradient method"

Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets
- Learn how to grow the complexity of a model in a structured way
- Slight improvement using lists or stacks with RNN
- "Complex algorithmic patterns can be more easily learned by composing simpler algorithms"

Reinforcement Learning Neural Turing Machines - Revised
- Outline how a RL-NTM can interact with an input, memory and output "tapes"
- Gradual increments of the problem complexity, as "Curriculum learning"
- Their gradient checking procedure helped to debug any reinforce algorithm
- Used for simple tasks: copy, reverse, duplicate
- Possible future work to implement on a FPGA

Neural Machine Translation by Jointly Learning to Align and Translate
- Extend the classic Encoder - Decoder with a (soft)search-RNN
- It makes translations between english and french
- WMT parallel corpora as a dataset
- It compares its results quantitative and qualitatively

End-To-End Memory Networks
- RNN with (large) external memory
- Train a NN with explicit memory and recurrent attention, 
- A NN with "intuition" of information from a text
- Compared to baseline NN like: LSTM, MemNN and MemNN-WSH (weakly supervised heuristic)

Neural Turing Machines
- Extent the Von Neumann architecture to NN which differentiable end-to-end
- It is able to infer simple algorithms: copy, sort, associative recall.
- NTM interacts with its environment using input - output channels
- NTM uses a controller to read/write from a local memory module

GPU-Accelerated Adjoint Algorithmic Differentiation
- Implementation improvement over naïve AD code
- Feasible for multithreaded environments, specially GPUs
- CPU vs GPU implementations 
- Use vectorization to reduce tape size

Automatic Differentiation of Algorithms for Machine Learning
- Explains AD from basic calculus knowledge
- Links AD with ML algorithms
- Explains Forward and Reverse mode

Delving Deep into Rectifiers- Surpassing Human-Level Performance on ImageNet Classification
- Introduction of the PReLU function
- "improves model fitting and little overfitting risk"
- Better recognition levels for ImageNet 2012 classification dataset
- PReLu function is also trained using backpropagation
- Mention of a multi-GPU deployment

Adam- a method for stochastic optimization
- Algorithm for first-order gradient-based optimization, estimates of lower-order moments
- Computationally efficient, little memory requirements, invariant to rescaling
- Applies to multiple ML algorithms: DNN, Logistic Regression, Bias-correction term
- Aimed for ML problems with large datasets and/or high-dimensional parameter spaces

NetAdapt- Platform-Aware Neural Network Adaptation for Mobile Applications
- Algorithm that improves inference on mobile devices with trained models
- It includes direct metrics (empirical measurements) into its adaptation
- It tries to reduce resource consumption while keeping the same accuracy
- Tested for mobile CPU and GPUs

Hardware for Machine Learning- Challenges and Opportunities
- Abstract survey of hardware architectures: CPU, GPU, FPGA, ASIC
- General memory access SIMD models: Weight, output, row stationary or no local reuse
- Oportunities: reduced precision, sparcity, compression

Efficient Processing of Deep Neural Networks- A Tutorial and Survey
- Tutorial on past, present and future of DNN from a research perspective
- DNN Applications: image/video, speech/language, medical, game play, robotics
- DNN numerical precision survey according to the bitwidth 
- DNN models: LeNet, AlexNet, Overfeat, VGG, GoogLeNet, ResNet
- Techniques used on accelerators for SIMD operations
- Metrics for Hardware: power/energy, latency/throughput, cost

Understanding the Limitations of Existing Energy-Efficient Design Approaches for Deep Neural Networks
- "While specialized DNN hardware (ASIC, FPGA) provide improved energy-efficiency compared to GPUs, they often come at the cost of flexibility in terms layer types (CONV or FC) and network shapes that it can support; specifically they rely on certain DNN properties to achieve it"
- "On the other hand, innovative techniques have been used for efficient DNN algorithm design, adding diversification, which in turns, hardware needs to be flexible enough
to be efficient across all these possible combinations (dense/sparse, number of channels, batch size)".

Data-partitioning using the Hilbert space filling curves: Effect on the speed of convergence of Fuzzy ARTMAP for large database problems
- Use Hilbert space-filling curves to divide into subproblems for large databases
- Tested on one real-world database (Forest Covertype) and two artificial
- Ran on SCEROLA Beowulf cluster of workstations

Learning to See in the Dark
- CNN for low light images with raw sensor data
- Reduces image processing from traditional pipelines
- New dataset for the paper, 5094 raw exposures
- Trained from scratch using the L1 loss and the Adam optimizer
- Used smartphone images as well

Toward Deeper Understanding of Neural Networks- The Power of Initialization and a Dual View on Expressivity
- Proposed general duality between NN and compositional kernels
- Math background: reproducing kernel Hilbert space (RKHS) or kernel space 
- Extensive explanation of math: taylor series, 
- Using skeletons and compositional kernel spaces, it is possible to understand how functions learn
- State a conjecture that ReLU is more robust to initialization

On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation
- Make a pixel-wise decomposition of nonlinear classifiers
- It helps to visualize the contributions of single pixels to predictions
- Tested on PASCAL VOC 2009, MNIST and pre-trained ImageNet
- Example of Taylor-type and Bag of words decompositions
- An step forward to analytically justify NN results using heatmaps

Explaining NonLinear Classification Decisions with Deep Taylor Decomposition
- Another publication related to previous paper (On Pixel-wise explanations)
- "Deep Taylor Decomposition DNN"
- Use the network structure to back propagate explanations from the output
- MNIST and ILSVRC data sets
- Pixel-wise heatmap explaining why a NN classifier made a particular decision
- Examples of unconstrained (w^2 rule) and constrained (z rules) input spaces
- It is stable under different architectures and datasets, 
- It does not require hyperparameter tuning

Understanding Deep Learning requires rethinking generalization
- This paper tries to expose the idea of NN as just memorizing data sets
- Expose that NN do not distinguish between randomized and real labels
- CIFAR10 and Imagenet as classification benchmarks
- It is mentioned that a 2 layer NN with ReLU activations can represent functions of a certain sample size and dimension
- Exposed a simple experimental framework for defining and understanding a notion of effective capacity of ML models

Improving back-propagation by adding an adversarial gradient
- Adversarial gradient shows a regularizing effect (like dropout) in fully connected NN
- In MNIST, increases the resistance and boosts classification performance
- Requires an additional forward/backward pass to calculate
- Tested on MNIST and CIFAR10, with ReLU, TanH, Logistic and Maxout

Neuroscience-Inspired Artificial Intelligence
- Promote more collaboration between Neuroscience and AI
- Survey of the current research state in both fields: CS and Neuro Science
- "Insights often develop through a continual handing back and forth of ideas between fields"
- Future developments: Intuitive understanding, transfer learning, imagination, planning, virtual brain analytics

Overcoming catastrophic forgetting in neural networks
- Proposed method to remember old tasks by selectively slowing down learning
- MNIST classification with Atari 2600 games with
- Task-specific synaptic consolidation called "elastic weight consolidation (EWC)
- EWC can be used for supervised and reinforcement learning with several sequential tasks
- "EWC allows continual learning in a reinforcement learning context"
- "EWC parallels with neurobiological models of synaptic consolidation"
- Bayesian approach to learning, boosting rates for poorly constrained and slowing for crucial weights

Training and inference with integers in deep neural networks
- WAGE (Weights, Activations, Gradients and Errors) layers are shifted and linearly constrained to low-bitwidth integers
- Use low precision integers to train the NN, 2/8 bits
- MNIST, CIFAR, SVHN and ImageNet training sets
- WAGE empowers pure low-bitwidth integer dataflow for training and inference

Dorefa-net- training low bitwidth convolutional neural networks with low bitwidth gradients
- Weights and activations can be deterministically quantized
- Gradients need to be stochastically quantized
- SVHN and ImageNet datasets
- Gradients are quantized each time before they reach the selected convolution layers during the backward pass

Learning and Memory in Neural Networks
- Paper that mentions multilayer perceptron, Hopfield and associative networks
- Explains briefly how multilayer perceptrons can classify non linear input
- Hopfield networks can create CAM to retrieve patterns from partial information
- Associative networks are feedforward NN that learn an association between two input patterns

Explorations of the Mean Field Theory Learning Algorithm 
- MFT compared against Back Propagation (BP) in mirror simmetry and pattern classification
- A NxN (visible x hidden) units can store up to 4N patterns
- MFT can be implemented using VLSI circuitry
- MFT learns in a substantially smaller number of training epochs than BP
- [0,1] representation yields slower learning but better generalization than [-1,1]
- MFT is somewhat more biological than BP because the first depends only on neighboring neuron states
- MFT could perform feature recognition, CAM or optimization, the last with learning features "turned off"

A Survey on Deep Transfer Learning
-
-
-

Perceptrons- Expanded Edition
-
-
-

Taylor expansion of the accumulated rounding error
-
-
-

Transfer Learning for Visual Categorization- A Survey
-
-
-

Gradient-based learning applied to document recognition
-
-
-

Neural GPUs Learn Algorithms
- Proposes a scalable convolutional gated recurrent unit (CGRU) that assimilates GPU architectures
- Can perform operations like binary summation, multiplication, counting, copy, reverse or duplication
- Dropout helps this architecture compared to other recurrent neural networks
- Neural GPUs use the standard, heavily optimized convolution operation and are fast

FermiNets- Learning generative machines to generate efficient neural networks via generative synthesis
- Create a pair Generative - Inquisitor to train G to later create efficient NN
- Tested for image classification, semantic segmentation and object dectection
- >4x improvements in image inferences per joule consumed on a Nvidia Tegra X2 mobile processor

Training neural networks to identify coding regions in genomic DNA
- NN receives its inputs from statistical measures taken on a 99-base window
- Complete training set of 10652 non-coding vectors and 741 coding vectors
- CODEX attempts to predict the location of genomic coding regions by examining the output of the combination of 5 neural networks

Neural Network in Human Identification by DNA Sequences
- Analyzes the similarity/dissimilarity of DNA sequences
- Establishes the zigzag curve and calculate its curvature, then that forms the input of the NN
- LVQ network is the best for this set; since this network distinguishes between curvature vectors correctly.

Study of underlying repeats in genomic DNA sequences with neural networks
- Modeling quasi-random replacements using with multi-symbol extension of energy-minimizing neural networks
- Genomes datasets of PHIX174 and MIG4XX 
- The distance between two sequences of arbitrary length is determined as the number of non-coincident nucleotides in the same sites (Hamming distance)

Hybrid Neural Networks for Learning the Trend in Time Series
- Uses a hybrid CNN-LSTM to calculate time series trends
- Compared against other CNN, LSTM, SVR, Pattern-based Hidden Markov Model and naive NN implementations
- Tested on datasets of power consumption, gas sensor and stock transaction 

Measuring the time needed for training a neural network based on the number of training steps
-
-
-

An analysis of deep neural network models for practical applications
-
-
-

Large-scale Deep Unsupervised Learning using Graphics Processors
-
-
-

CryptoNets- Applying Neural Networks to Encrypted Data with High Throughput and Accuracy
- Method to convert learned neural networks to CryptoNets, NN that can be applied to encrypted data
- Send their data in an encrypted form to a cloud service that hosts the network (homomorphic encryption)
- CryptoNets on the MNIST optical character recognition tasks (99% accuracy) and makes 59000 predictions per hour
- The encryption scheme does not support floating-point numbers. Instead, it uses fixed precision real numbers by converting them to integers with proper scaling

CryptoDL- Deep Neural Networks over Encrypted Data
- CNN with the approximation polynomials instead of original activation functions and it
analyzes the performance of their models
- MNIST (99.52%) and 164000 predictions/hour. CIFAR-10 (91.5%) 
- In theory, it is possible to train neural networks over encrypted data: replacing activation functions with polynomials, BP can be computed

SecureNN- Efficient and Private Neural Network Training
- Provides a novel three-party and four-party secure computation protocols for various NN
- NN training and inference such that no single party learns any information about the data
- Overhead of executing secure training protocols is only between 17-33X of the cleartext implementation even for networks that achieve > 99% accuracy
- MNIST dataset with 99.15% accuracy in 42.51hours vs 2.11h in clear text

Generating and designing DNA with deep generative models
- Creates synthetic DNA sequences using a GANs
- DNA-based variant of the activation maximization ("deep dream") design method
- Applied to designing probes for protein binding microarrays
- Generative tools learn important structure from DNA sequences

An Asynchronous Encryption Arithmetic Based on Laguerre Chaotic Neural Networks
-
-
-

Cache Friendly Parallelization of Neural Encoder-Decoder Models Without Padding on Multi-core Architecture
-
-
-

Generalized synchronization theorems for a kind of Neural Network with application in data encryption
-
-
- 

A chaotic encryption system using PCA neural networks
-
-
-

QSGD- Communication-Efficient SGD via Gradient Quantization and Encoding
- Quantized SGD (QSGD): a family of compression schemes for gradient updates which provides convergence guarantees
- Smoothly trade off communication bandwidth and convergence time: nodes can adjust the number of bits sent per iteration, at the cost of possibly higher variance
- Significant reductions in end-to-end training time
- With 16GPUs, they can train the ResNet-152 network to full accuracy on ImageNet 1.8× faster than the full-precision variant

Neural Cryptography- From Symmetric Encryption to Adversarial Steganography
- Shows how NN are capable of performing symmetric encryption in an adversarial setting 
- NN capable of detecting insecure communications based on Ciphertext Indistinguishability
- Shows futher research on Neural Steganography in the context of developing neural end-to-end stegonographic algorithms

A Bayesian Framework for Reinforcement Learning
- Uses a posterior distribution over process parameters with a greedy behavior with respect to a sample of such posterior
- Each hypothesis is retained over a period of time, ensuring goal-directed exploratory behavior without the need to use approximate measures
- Obtain behavior which moves gradually from exploration to exploitation, without making heuristic design decisions
- Proposes the OpenAI Gym environment "NChain-v0", along with description for other Reinforcement problems like "Loop" and "Maze"

Learning simple algorithms from examples
- The bottleneck is in the capabilities of the controller rather than in the search incurred by Q-learning
- Environments: Copy, reverse, walk, addition, 3 number addition, single digit multiplication
- Q-learning: a standard reinforcement learning algorithm to learn a sequence of discrete
actions that solves a problem for the supervised case in this paper
- Not able to find a single controller that could solve all tasks

Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition
- Describes the theory of MaxQ algorithm where policies and value functions become context free
- MAXQ relies on programmers to design the hierarchy of termination conditions, pseudo-reward functions and state abstractions
- Applied to Taxi and HDG tasks􏰀

Interpretability Beyond Feature Attribution- Quantitative Testing with Concept Activation Vectors
- Shows importance of high level concepts for a prediction class
- TCAV gives an explanation that is generally true for a class of interest, beyond one image (global explanation)
- Tested a variety of concepts: color, gender, race, textures and many others

DeepZip- Lossless Data Compression using Recurrent Neural Networks
- Combine recurrent neural network predictors with an arithmetic coder and losslessly compress a variety of synthetic, text and genomic datasets
- Outperforms Gzip on the real datasets and achieves near-optimal compression for the synthetic datasets
- DeepZip has the three probability predictor blocks FC, biGRU and LSTM-multi
- Tested on Real: Human Chr1 dataset, C Elegans, PhyX virus, text8; Synthetic:k-order Markov, Hidden Markov Model

Public Key Cryptography using Neural Networks and Genetic Algorithms
-
-
-

Survey Report on Cryptography Based on Neural Network
-
-
-

Elliptic Curve Diffie-Hellman Random Keys Using Artificial Neural Network and Genetic Algorithm for Secure Data over Private Cloud
-
-
-

The Lottery Ticket Hypothesis- Finding Sparse, Trainable Neural Networks
- Llottery ticket hypothesis: dense, randomly-initialized, feed-forward
networks contain subnetworks (winning tickets) that—when trained in isolation—
reach test accuracy comparable to the original network in a similar number of
iterations
- An algorithm to identify winning tickets and a series of experiments
that support the lottery ticket hypothesis and the importance of these fortuitous
initializations
- Winning tickets that are less than 10-20% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10

Towards resource-frugal deep convolutional neural networks for hyperspectral image segmentation
-
-
-

Neural network based multi-objective evolutionary algorithm for dynamic workflow scheduling in cloud computing
-
-
-

< NN

-------> Decentralized

BitWorker, a Decentralized Distributed Computing System Based on BitTorrent
-
-
-

Distributed/Decentralized and Asynchronous Algorithms
-
-
-

Synthesis of Distributed Control through Knowledge Accumulation
-
-
-

A Heuristic Algorithm for Workflow-Based Job Scheduling in Decentralized Distributed Systems with Heterogeneous Resources
-
-
-

Advanced air traffic automation- A case study in distributed decentralized control
-
-
-

Comingle- Distributed Logic Programming for Decentralized Mobile Ensembles
-
-
-

Parallel and Distributed Particle Collision Simulation with Decentralized Control
-
-
-

< Decentralized

-------> DCGAN

Generative Adversarial Networks
- First paper about GAN: generator (G) and discriminator (D)
- G tries to fool D improving in the generated output
- Use MNIST, Toronto face database and CIFAR

Improved Techniques for Training GANs
- MNIST, CIFAR-10, ImageNet and SVHN data sets
- Focused on semi-supervised learning, and the generation of images
- The discriminator uses a "minibatch discrimination"
- Improvements on evaluation metrics and unstable training

InfoGAN- Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets
- "InfoGAN learns interpretable representations"
- Tested on MNIST, CelebA, SVHN datasets
- "Completely unsupervised and learns interpretable and disentangled representations on
challenging datasets"

Population Based Training of Neural Networks
- A different approach to tune hyperparameters
- "Improvements in accuracy, training time and stability"
- GAN image generation improves using PBT

Gang of GANs- Generative Adversarial Networks with Maximum Margin Ranking
- Improvements over Wasserstein GAN
- Uses multiple GAN alleviating gradient vanishing, instability and mode collapse
- Tested on visual datasets: CelebA, LSUN Bedroom, CIFAR-10 and 50K-SSFF
- Theoretical background for multiple GAN

DOOM Level Generation using Generative Adversarial Networks
- Use Wasserstein GAN with gradient penalty to create levels in Doom (video game)
- Possible alternative to Procedural Content Generation
- Replaced tanh with sigmoid to suit grey scale colors
- Used Adam optimizer and optimized the discriminator network five times at each update

Wasserstein GAN
- Focused on unsupervised learning defining Earth Mover (EM) distance
- Use WGAN to minimize and approximate EM, which "cures" training problems with GAN
- WGAN train the discriminator to optimality by continuously estimate EM
- According to them, WGAN can improve stability/debugging and remove mode collapse

Autoencoding beyond pixels using a learned similarity metric
- Combination of a variational autoencoder with a generative adversarial network
- GANs avoid element wise similarity measures by construction
- Trained with RMSProp using a learning rate of 0.0003 and a batch size of 64
- Used to reconstruct dataset samples with visual attribute vectors added to their latent representations

Evolving Mario Levels in the Latent Space of a Deep Convolutional Generative Adversarial Network
-
-
-

Learning to Protect Communications with Adversarial Neural Cryptography
- Alice, Bob, and Eve networks that take N-bit random plaintext and key values, and produce N-entry floating-point ciphertexts
- Dynamics of this adversarial training appear somewhat more reminiscent of evolutionary processes
- Demonstrates that neural networks can learn to protect communications
- An extra on the paper shows an example of using public keys to encrypt communications

Metropolis-Hastings Generative Adversarial Networks
- MH-GAN combines aspects of Markov chain Monte Carlo and GAN
- Draws samples from the distribution implicitly defined by a GAN’s discriminator generator pair
- Tested on CIFAR-10 and CelebA against using DCGAN and WGAN
- Their method is based on the premise that D is better at density ratio estimation than G is at sampling data

Strategic Object Oriented Reinforcement Learning
- SOORL learns simple dynamics model through automatic model selection
- It performs efficient planning with strategic exploration
- Tested with Atari's Pitfall, which achieves significantly improved exploration and performance over prior methods

Exploration by Random Network Distillation
- Exploration bonus for deep reinforcement learning method with minimal overhead to the computation performed
- Bonus is the NN error predicting features of the observations given by a fixed randomly initialized NN
- Tested with Montezuma's Revenge with better than average human performance

A Style-Based Generator Architecture for Generative Adversarial Networks
- Automatically learned, unsupervised separation of high-level attributes and stochastic variation in the generated images
- Introduces a new, highly varied and high-quality dataset of human faces
- Used FlickrFaces-HQ (FFHQ), consisting of 70,000 high-quality images at 1024 resolution

Progressive Growing of GANs for Improved Quality, Stability, and Variation
- Grow both the generator and discriminator progressively: add new layers that model increasingly fine details as training progresses
- Increase the variation in generated images, achieving a record inception score of 8.80 in unsupervised CIFAR10
- Dataset, implementation in github, along with shared trained networks, datasets and results in their webpage

Binary Generative Adversarial Networks for Image Retrieval
- BGAN can simultaneously learn a binary representation per image, and generate an image plausibly similar to the original one
- BGAN significantly outperforms existing hashing methods by up to 107%
- Back-propagation (BP) for learning and stochastic gradient descent (SGD) to minimize loss
- Datasets: CIFAR-10, NUS-Wide, Flickr, hamming ranking as evaluation metrice

Learning Perfectly Secure Cryptography to Protect Communications with Adversarial Neural Cryptography
- ANC agents can learn the unbreakable One-Time Pad (OTP) algorithm
- Communicate securely through an insecure communication channel without human knowledge
- Propose an improvement to the ANC methodology using the concept of the Chosen-Plaintext Attack (CPA)
- ANC is an unsupervised learning technique
- This work presents the first Artificial Neural Network able to learn an unbreakable cryptographic technique, namely OTP

Generative Adversarial Nets
-
-
-

Everybody’s Talkin’: Let Me Talk as You Want
-
-
-

< DCGAN

--------> Languages

A Comparative Study of Programming Languages in Rosetta Code
- Haskell as top 2 for functional language usage in Rosetta.
- Functional and Scripting provide concise code
- Python executables are smaller than Haskell due to static links.
- Haskell smaller run time/memory/error prone than python

Comparative Studies of 10 Programming Languages within 10 Diverse Criteria -- a Team 7 COMP6411-S10 Term Report
- Haskell allows robust, concise, correct software
- Compares Haskell with Java
- 10 criteria for language analysis, among Web apps, secure practices or UI prototyping

Experience Report: Haskell as a Reagent
- Implementation of some Haskell modules into a large scale Python project
- Haskell implementations of an automated computation cluster algorithm
- "Each language has certain characteristics that make it easier and more natural to program in a certain way"
- Functionalize Python later developments after Haskell implementation.
- Compares Haskell partial function application with Python library implementation

An Open-Source Sandbox for Increasing the Accessibility of Functional Programming to the Bioinformatics and Scientific Communities
- Paper backing up the use of functional programming for bioinformatics
- Functional programming languages are better to express math descriptions
- GHCi for interactive environment
- "Haskell code is inherently testable"
- Implementation of a Clojure Amono Acid Predictor

Haskell vs FSharp vs scala- a high-level language features and parallelism support comparison
- Tests performed for Windows and Linux
- The first tests haskell made the best performance in portability
- In parallel performance, haskell demonstrates the best speedups when using more cores
- Laziness as a double edge sword: difficult for HPC but allows infinite structures.

Haskell vs Ada vs Cpp vs Awk vs
- 1994 Research sponsored by DARPA for Naval Surface Warfare Center
- Haskell code took less time to develop and it was more concise/easier to understand
- Haskell lines of code were its minimal, with second in lines of documentation
- Haskell development time was second best (after Relational-Lisp)
- Subjective code evaluation gave an "A" to the haskell prototype

An embedded modeling language approach to interactive 3D and multimedia animation
- 1999 report on how a DSL on top of haskell was used for 3D animations
- First introduction to "Functional Reactive Animations"
- How Haskell enhances: composability, high order functions, strong static typing

------> BNN

How to Train a Compact Binary Neural Network with High Accuracy
- Propose how to train BNN with their own procedures
- Compared with AlexNex, XOR-NN and previous BNN
- Used "PReLU" function for activation
- Used L2 regularization to force weight bipolarization
- High compression rates compared to other BNN implementations

Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations
- Trained with  MNIST, CIFAR-10, SVHN and ImageNet datasets
- MNIST QNN 7 times faster than with an unoptimized GPU kernel
- Replaces MAC operations with XNOR and population count
- Same accuracies as typical NN with 4-bit weights and activation Recurrent-QNN
- Implemented NN structures: AlexNet, GoogleNet and ConvNet

Binarized Neural Networks- Training Neural Networks with Weights and Activations Constrained to +1 or −1
- Similar to quantized NN, previous publication
- Extensive explanation of the algorithms used
- Implemented in Theano and Torch (Git repositories)

Embedded Binarized Neural Networks
- Focus BNN for small memory devices (~ KB sizes) like Intel Curie
- Uses just a single floating-point temporary
- Use of "Fused Binary Convolution-Pool Blocks"
- MNIST and CIFAR10 were considered for testing

ReBNet- Residual Binarized Neural Network
- Explains the hardware implementation of a BNN
- Uses "Xnor-Popcount" as a binary dot product
- "Re" stands for reconfigurable
- Explains all phases of a BNN and its advances in parallelization
- Results compared with CIFAR10, SVHN, MNIST, and ILSVRC-2012 (Imagenet)
- ReBNet: scalable bin-CNN that embeds reconfigurability

Recursive Binary Neural Network Learning Model with 2.28b-Weight Storage Requirement
- RBNN that recycle synaptic data during training
- Improvement over BNN for MNIST data set
- This model requires 4x less storage than other binary models
- Storage requirements around 2.28b/synapse

Deep Learning Binary Neural Network on an FPGA
- Explains how to implement a BNN on a FPGA
- It uses only on-chip memory and an efficient batch normalization
- Evaluated using CIFAR-10 with 332,158 img/sec and 86.06% accurracy
- Used Zync ZC706 and Virtex 7 980T

Transfer Learning with Binary Neural Networks
- Have BNN fixed and dynamic sections that are updated later
- Train with Imagenet then perform other tasks or "transfer learning"
- Hybrid HW-SW approach: ship only domain specific NN layers

Build a Compact Binary Neural Network through Bit-level Sensitivity and Data Pruning
- Explores redundant work of BNN to build compact BNN
- Considers sensitivity analysis and bit-level data pruning
- Network size reduced with low accuracy loss, along with less runtime
- Tested on CIFAR-10, SNVH, Chars74K and GTSRB

Fully Parallel RRAM Synaptic Array for Implementing Binary Neural Network
- Considers an parallel array architecture that results in "P-BNN"
- Reduced energy consumption, ~20x improvement over BNN
- Tested for MNIST and ran over TSMC 65nm PDK
- Describes how a "Current Mode Sense Amplifier" can be used
- Uses less circuit area, latency is reduced along with energy consumption

Local Binary Convolutional Neural Networks
- Inspired by Local Binary Patterns, it translates the idea to convolutions
- It shows its mathematical background, with a AlexNet structure
- Tested on MNIST, SVHN, CIFAR-10, and ILSVRC2012 ImageNet

XNOR-Net- ImageNet Classification Using Binary Convolutional Neural Networks
- Two approaches to data quantization
- XNOR-Nets reach 58x convolutional operations that enables CPUs to train the NN
- Tested with ImageNet and ILSVRC2012 using an AlexNet structure
- Reduced network size by around 32X

Bitwise Neural Networks
- Proposed BNN for all elements in the NN
- Tested for MNIST
- Training was done with real values and bitwise 
- Hyperbolic tangent was used for both weight compression and activation

Accelerating Binarized Convolutional Neural Networks with Software-Programmable FPGAs
- BNN on FPGAs with convolutions (Xilinx Zynq-7000 SoC)
- Tested on CIFAR-10
- Implemented in C++
- 35.8 img/sec/watt

Accelerating Binarized Neural Networks- Comparison of FPGA, CPU, GPU, and ASIC
- Test comprehensively between architectures
- FPGA and ASIC have a tight battle
- Network structures: AlexNet, VGG and Neural Talk with CIFAR-10 dataset

FINN- A Framework for Fast, Scalable Binarized Neural Network Inference
- 12.3 million/sec, 0.31 microsec latency and 95.8% accuracy MNIST
- Comprehensive explanation of its FPGA implementation with 90% LUT utilization
- Xilinx Zynq-7000, SoC ZC706

Neural networks with few multiplications
- Test data set: MNIST, CIFAR10, SVHN
- Mayor contribution: Quantized Back Propagation
- Forward pass: binary connect or ternary connect
- Their description tries to eliminate multiplications from all NN stages
- "Ternary connects" is splitting binarization between [-1,0) [0,1]

Towards Accurate Binary Convolutional Neural Network
- Apply convolutions to BNN without prediction degradation, it is called ABC-Net
- This work approximates full-precision weights with linear combination of
multiple binary weight bases
- Employing multiple binary activations to alleviate information loss
- Uses ResNet topology in the ImageNet dataset with close results to full precision nets

Bitwise Neural Networks for Efficient Single-Channel Source Separation
- Use BNN to perform denoising signal operations
- BNNs learn the input Boolean mapping signals and their target Ideal Binary Masks
- Their binarization technique "Quantization-and-Dispersion" encodes magnitude spectra
- A two-stage training strategy was used to prepare a set of compressed weights
- They used their own data set of signals (121080 + 18020 for tests)

Training binary multilayer neural networks for image classification using expectation backpropagation
- Proposed the expected backpropagation based on Bayesian framework
- Tested for the MNIST data set
- Performance is ok but not comparable to other DNN with real values
- Dropout techniques significantly improve BNN with EBP

Back Propagation Learning With Trinary Quantization of Weight Updates
- Three value states: increment, decrement or same magnitude (zero) for weights
- Aims for parallel implementations wuth 3 - 10x less iterations than standard BP
- Sigmoid activation function (unbounded and not asymptotic)
- The algorithm performs a descent on sum-square error surfaces

GXNOR-Net- Training deep neural networks with ternary weights and activations without full-precision memory under a unified discretization framework
- Gradient decent with 3 elements, using derivates of pulses-like functions
- Multi-step neuronal activation discretization method and derivates approximations
- "Gates" connected to neurons, it is "deactivated", which reduces consumption
- Tested for MNIST, CIFAR and SVHN, reaching better results on them all
- Three special parameters: m (quantizer), a (derivate width) and r (excitability control)

FP-BNN- Binarized neural network on FPGA
- Proposed BNN to cut down hardware consumption while maintaining acceptable accuracy
- Resource-Aware Model Analysis (RAMA) method to 
- 64-channel accelerator architecture for CNN and FC-NN
- Stratix-V 5SGSD8 FPGA, 26.2W, 150MHz
- MNIST, CIFAR and AlexNet

Training deep neural networks with discrete state transition
- Discrete State Transition (DST) introduces a probabilistic projection operator
- DST constrains the weight matrices in a discrete weight space (DWS)
- MNIST (1.07%), CIFAR10 (11.84%) and SVHN (2.45%) datasets
- Could be designed for online training and computational cost reduced
- Values could range within multi-level states in a discrete weight space

Ternary Weight Networks
- Discrete weight space with {-1, 0, 1} range
- Up to 16× or 32× model compression
- MNIST, CIFAR-10, and ImageNet datasets
- Forward/backward pass used with ternary values, but not during parameter updates

Attacking Binarized Neural Networks
- BNN improve robustness against some adversarial attacks
- White box attack: Carlini-wagner attack with MNIST dataset
- Black box: CleverHans for both MNIST and CIFAR-10 datasets
- In BNN, difficulty in training leads to difficulty when attacking

Binary backpropagation in content addressable memory
- Use CAM + Binary BP to learn patterns in data
- Activation function uses XOR, as it does for distance to the target
- Because of discrete size corrections, minimal size is chosen, at most 1 bit in any connection row
- When all the synapse functions are identical, selection is arbitrary
- Patterns with a small number of discrete levels can be learned through a simple extension of the synapse function
- Asymmetric two variable boolean functions must be learnt locally by the NN 

Hardware efficient learning on a 3-D optoelectronic neural system
- Mentions an special type of processor called Dual-Scale Topology Optoelectronic Processor (D-STOP)
- States that BackProp and CAN (Content-Addressable networks) can be mapped to D-STOP
- Explains the CAN algorithm, and how a NN can be initialized with CAN then move to BP
- Because CAN uses boolean operations, cumulative errors are eliminated

Content addressable networks for initialization of backpropagation with zero error solutions
- CAN networks learn BP-like associations with an exact, error-free solutions
- It is possible to initialize BP quickly from a CAN solution
- CAN is a system that allows simple, efficient, discrete computational units to learn generalized mappings
- Advantages: rapid convergence, natural hardware efficiency, quickly produce exact solutions with zero error

A high-storage capacity content-addressable memory and its learning algorithm
- Considers VLSI as a target implementation
- It bases its theory in Hopfield networks with CAM properties
- Connection weights are restricted to the [-1, 0, 1] domain
- The paper presents SPICE simulations of the circuit proposed
- It can be programmed to do CAM or optimization problems
- The learning algorithm allows matrices to be asymmetric, where each neuron outputs (-1,1)

Optical matrix–vector implementation of the content-addressable network
- Explains how CAN works
- CAN is a learning algorithm that provides heteroassociative classification abilities
- CAN can learn arbitrary binary patterns in parallel hardware implementations
- Implementation of the CAN to optical systems
- Used optical matrix-vector multiplication for weight computation of recall
- Electronics were used for threshold, learning and control
- CAN can learn and operate with tolerance to non ideal environments

Neural networks for high-storage content-addressable memory- VLSI circuit and learning algorithm
- Proposed fully interconnected neural network with only two binary memory points per synapse
- Proposed algorithm for programming a Hopfield neural network as a high-storage content-addressable memory
- -1, 0, 1 as possible synaptic weights values
- Could be used in: optimization, pattern recognition and image processing.


Associative content-addressable networks with exponentially many robust stable states
- Construction of ACAM (Associative Content-Addressable neural Memory) with robust error correction
- ACAM possesses expander graph connectivity on a restricted Boltzmann machine
- Constraint nodes correct corrupted input patterns to the nearest (in Hamming distance) permitted pattern
- A network with initially specified connectivity but unspecified weights can self-organize to have exponentially many well-separated minima
- ACAM can be used to to generate robust labels for arbitrary input patterns in a high 
dimensional space

A highly scalable 3D chip for binary neural network classification applications
- Binary neural networks require only TLUs and are very suitable for a VLSI implementation
- The threshold function is indeed easy to implement in digital and this results in significant silicon area saving as compared to sigmoidal or radial basis functions used in multilayer perceptrons or RBF networks and implemented through area consuming look-up tables. 

A Survey on Methods and Theories of Quantized Neural Networks
-
-
-

Adaptive Learning with Binary Neurons
-
-
-

Binary Ensemble Neural Network- More Bits per Network or More Networks per Bit
-
-
-

Binary neural network with 16 Mb RRAM macro chip for classification and online training
-
-
-

Espresso- Efficient Forward Propagation for BCNNs
-
-
-

Hashing with Binary Matrix Pursuit
-
-
-

Learning in Memristive Neural Network Architectures using Analog Backpropagation Circuits
-
-
-

Learning to Train a Binary Neural Network
-
-
-

On the State Space of the Binary Neural Network
-
-
-

Quantum Inspired Binary Neural Network Algorithm
-
-
-

Training Binary Multilayer Neural Networks for Image Classification using Expectation Backpropagation
-
-
-

Training Compact Neural Networks with Binary Weights and Low Precision Activations
-
-
-

Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference
- Quantization scheme that allows inference to be carried out using integer-only arithmetic
- Co-designs a training procedure to preserve end-to-end model accuracy post quantization
- Tested on ImageNet and COCO with CPU
- Weights are quantized before they are convolved with the input
- Activations are quantized at points where they would be during inference


Universal Perceptron and DNA-Like Learning Algorithm for Binary Neural Networks- Non-LSBF Implementation
- Use genetic algorithm ideas to train BNN
- Focused on two problems: n-bit parity function and circular region approximation
- Uses only boolean operations for the whole algorithm

Xcel-RAM- Accelerating Binary Neural Networks in High-Throughput SRAM Compute Arrays
-
-
-

XNOR Neural Engine- a Hardware Accelerator IP for 21.6 fJ-op Binary Neural Network Inference
-
-
-

Accelerator Design with Effective Resource Utilization for Binary Convolutional Neural Networks on an FPGA
-
-
-

Stochastic weights binary neural networks on FPGA
-
-
-

BRein Memory- A Single-Chip Binary-Ternary Reconfigurable in-Memory Deep Neural Network Accelerator Achieving 1.4 TOPS at 0.6 W
-
-
-

BitFlow- Exploiting Vector Parallelism for Binary Neural Networks on CPU
-
-
-

An Energy-Efficient Architecture for Binary Weight Convolutional Neural Networks
-
-
-

XNORBIN- A 95 TOp-s-W hardware accelerator for binary convolutional neural networks
-
-
-

True Gradient-Based Training of Deep Binary Activated Neural Networks Via Continuous Binarization
- Train binary activated neural networks using true gradient-based learning, exploiting similarities between clipping and binary activation functions
- Datasets: MNIST, CIFAR-10 and SVHN
- Achieves an accuracy within 1.5% of the floating-point baseline

Self-binarizing networks
- Refloat the idea on paper: True Gradient-Based Training of Deep Binary Activated Neural Networks Via Continuous Binarization (https://openreview.net/forum?id=HJxKajC5t7)
- Binarization task by training on a unique representation involving a smooth activation function
- During training, a set of constrained floating-point weight is used
- CIFAR10 with Binaryconnect, BNN, Binary Weight Networks and XNORNet models

Fully parallel RRAM synaptic array for implementing binary neural network with (+1, −1) weights and (+1, 0) neurons
-
-
-

Hyperdrive- A Systolically Scalable Binary-Weight CNN Inference Engine for mW IoT End-Nodes
-
-
-

BinaryConnect- Training Deep Neural Networks with binary weights during propagations
-
-
-

YodaNN- An Architecture for Ultra-Low Power Binary-Weight CNN Acceleration
-
-
-

BMXNet- An Open-Source Binary Neural Network Implementation Based on MXNet
-
-
-

Hybrid Binary Networks- Optimizing for Accuracy, Efficiency and Memory
-
-
-

Towards Fast and Energy-Efficient Binarized Neural Network Inference on FPGA
-
-
-

No Multiplication, No Floating Point, No Problem, Training Networks for Efficient Inference
-
-
-

Probabilistic Binary Neural Networks
-
-
-

A Fully Onchip Binarized Convolutional Neural Network FPGA Impelmentation with Accurate Inference
-
-
-

FBNA- A Fully Binarized Neural Network Accelerator
-
-
-

A Lightweight YOLOv2: A Binarized CNN with A Parallel Support Vector Regression for an FPGA
-
-
-

FxpNet- Training deep convolutional neural network in fixed-point representation
-
-
-

Application of binary neural networks for classification
- Based on geometric technique, called Expand and Truncate Learning (ETL)
- Construct a three-layer NN to get multiple outputs using an improved ETL algorithm
- Classification examples: 3bit Input - 2 output; 7 in - 2 Out.

Design of two architectures of asynchronous binary neural networks using linear programming
- Proposes a new design technique for asynchronous binary neural networks with two architectures
- First, a fully connected network that reads a N-digit cue and classifies it into a category represented by a N-digit pattern
- Second, a two-layer network that reads an M-digit cue and associates it with a L-digit pattern

Pattern classification by geometrical learning of binary neural networks
- Use ETL algorithm to classify the breast cancer database
- Weights and thresholds are determined based on geometrical analysis hyperplanes
- ETL learning has 15 hidden units, using 10.6 seconds of processor time

A GA-based flexible learning algorithm with error tolerance for digital binary neural networks
- GA are used with flexible fitness that tolerates error; suitable to reduce the number of hidden neurons, tolerate noise and outliers
- It applies the algorithm to design of Cellular Automata
- Chromosomes are candidates of binary weights and integer thresholds

Rule extraction from binary neural networks
- Defines a new constructive learning algorithm, called Hamming clustering (HC)
- HC has a polynomial computational cost and memory required is polynomial asymptotic
- Tested with the Wisconsin Breast Cancer database

Hamming Clustering- A New Approach to Rule Extraction
- Almost same as paper "Rule extraction from binary neural networks" with minor improvements
- The algorithm directly infer the explicit rules in if-then form
- The goal of HS is to generate consistent set of rules synthesizing the knowledge embedded in the underlying Boolean function f

NullaNet- Training Deep Neural Networks for Reduced-Memory-Access Inference
- Treat MLP weights and thresholds as binary inputs/outputs
- Optimize for the same circuit paths that result in a similar operation
- Tested for the MNIST dataset

Design and implementation of binary neural network learning with fuzzy clustering
- Based on the concept of binary neural network and geometrical expansion
- ETL with Fuzzy C-Means algorithm used to train a three-layer BNN for a semisupervised classifier.
- Applies two algorithms to the dataset ETL and FCM
- Tested with Iris, Balance scale, BUPA and Wine datasets

A super parallel sorter using a binary neural network with AND-OR synaptic connections
- Their algorithm implementation does not need any adders
- The sorting operation is performed in two clock cycles
- Tested with data sizes from 100 - 1000 with same 2 cycles

Quantum Based Learning with Binary Neural Network
- NN architecture and weights are decided by quantum superposition
- Quantum computing optimizes the NN structure and the performance: # neurons and classification accuracy
- Accepts binary form of inputs and generate binary form of outputs
- Tested on PIMA Indian diabetes dataset compared with MTiling-real networks

High Speed Image Segmentation Using a Binary Neural Network
- Uses a BNN to process "Remote Sensing" data for regions of interest based on texture
- Advanced Distributed Associative Memory (ADAM) NN with only boolean operations
- Considers that N tuple network, with reasonable recognition performance
- Small data set of infra-red scanning sensor taken from an aircraft flying at 3000ft

Application of the Dynamic Binary Neural Network to Switching Circuits
- GA-based learning can store Binary Periodic Orbits into BNN with simple structure
- Application to various switching circuits; also for analysis/synthesis of various digital dynamical systems
- Matrix converter that converts a three-phase ac input into some three-phase ac output via nine switches
- The learning algorithm tries to separate the true vertices of the teacher signal by the separating hyper planes

Analysis for Characteristics of GA-Based Learning Method of Binary Neural Networks
- Learning can be obtained in the less number of generations by properly setting selection methods and parameters in a GA
- Learning characteristics of GAETL for the three-layer BNN
- Elitism and inverse-elitism can reduce the number of hidden layer neurons

Sensitivity-Based Adaptive Learning Rules for Binary Feedforward Neural Networks
-
-
-

Towards Effective Low-bitwidth Convolutional Neural Networks
- Proposes a two-stage optimization strategy to progressively find good local minima.
- First optimize with quantized weights and then quantized activations
- Secondly progressively decrease bit-width from high to low precision during training
- Finally use a novel learning scheme to jointly train a full-precision model alongside the low-precision one
- Experiments on CIFAR-100 and ImageNet that a 4-bit precision network has no performance decrease vs AlexNet and ResNet-50

Two-Step Quantization for Low-bit Neural Networks
- The TSQ framework decomposes the network quantization problem into two steps: code learning and transformation function learning based on learned codes
- 1st step: sparse quantization method for code learning
- 2nd step: non-linear least square regression problem with low-bit constraints, solved iteratively
- Experiments on CIFAR-10 and ILSVRC-12 
- 2-bit activation and ternary weight quantization (AlexNet), TSQ accuracy drops by ~0.5 points

Explicit Loss-Error-Aware Quantization for Low-Bit Deep Neural Networks
- ELQ bridges perturbation loss from weight quantization explicitly regularizing it
- Tested on ImageNet with AlexNet and ResNet-18
- Error decrease is minimal compared to other BNN

SYQ- Learning Symmetric Quantization For Efficient Deep Neural Networks
- Reduce BNN loss by learning a symmetric codebook for particular weight subgroups
- Open source code: github.com/julianfaraone/SYQ
- This method improves accuracy for 1-2 bit weights and 2-8 bit activations
- AlexNet, ResNet and VGG models and compared to QNN, Dorefa or TTQ
- Considers DSP/LUT utilization in Xilinx ZU3 FPGA 

A Ternary Weight Binary Input Convolutional Neural Network: Realization on the Embedded Processor
- Trains CNNs using the AdaDelta optimizer
- Proposes a 2D convolutional operation suitable for ARM processors (RPi 3)
- Better recognition accuracy and faster (8.13x) than binary weight CNN

VLSI implementation of a binary neural network-two case studies
- VLSI digital design for Correlation Matrix Memory networks
- Drawback is the demand for a high number of adders when dealing with large inputs
- Memory size is only limited by the maximum chip size

High Performance Binary Neural Networks on the Xeon-FPGA Platform
-
-
-

Training and Inference with Integers in Deep Neural Networks
- Weights (W), activations (A), gradients (G) and errors (E) among layers are shifted and linearly constrained to low-bitwidth integers
- MNIST, CIFAR and ImageNet datasets
- Where there is a MAC operation, there are quantization operators: k-bit linear mapping, distribution shifting and stochastic rounding

Learning discrete weights using the local reparameterization trick
-
-
-

The practical application of binary neural networks
- Advanced Distributed Associative Memory (ADAM) to the recognition of features in images
- Hierarchical organization of BNN can be used to quickly locate specific points in infrared images
- Images used to recognize road and intersection in satellite scans

Learning Recurrent Binary/Ternary Weights
- Proposes the use of batch normalization during the quantization process
- LSTMs trained with binary/ternary can only perform the inference computations with binary/ternary weights
- Binary/ternary-precision models in TSMC 65-nm CMOS technology 9× lower power and 10.6× lower silicon area at 400Mhz
- Tested on Penn Treebank (PTB), Text8, War and Peace, Linux and sequencial MNIST datasets reaching comparable perplexity and memory size

A complete mean-field theory for dynamics of binary recurrent neural networks
- It derives a novel MFT that captures the dynamic behavior of recurrent networks with binary units
- Guarantees the convergence of the average population activity to a deterministic limit
- Studied a simplified model that captures the essential nonequilibrium aspects of cortical asynchronous state

Hardware-efficient on-line learning through pipelined truncated-error backpropagation in binary-state networks
- Hardware-efficient on-line learning technique for feedforward (FF) multi-layer ANNs that is based on pipelined backpropagation
- Learning is performed in parallel with inference in the forward pass, removing the need for an explicit backward pass and requiring no extra weight lookup
- Binary state variables in the FF network and ternary errors in truncated-error backpropagation
- No need for multiplications in the forward and backward passes and memory requirements for the pipelining are drastically reduced
- Learning of MNIST handwritten digit classification on a Spartan 6 FPGA interfacing with an external 1Gb DDR2 DRAM
- Network history can be compactly represented in binary state networks (BSN)

FINN-R- An End-to-End Deep-Learning Framework for Fast Exploration of Quantized Neural Networks
-
-
-

Accelerating low bit-width convolutional neural networks with embedded FPGA
-
-
-

Training Generative Adversarial Networks with Binary Neurons by End-to-end Backpropagation
- Binary neurons (deterministic or stochastic) at the output layer (i.e., the final layer) of the generator
- Employ the sigmoid-adjusted straight-through estimators to estimate the gradients for binary neurons and train the whole network by end-to-end backpropagation.
- Use the binarized version of the MNIST handwritten digit database (i >=0 ~ 1)

LQ-Nets- Learned Quantization for HighlyAccurate and Compact Deep Neural Networks
- LQ-Nets use floating-point network weights which are quantized before convolution and optimized with error back-propagation (BP) and gradient descent. After training, they can be discarded and their binary codes and quantizer bases are kept.
- Variable size of weights and activations (1 - 32) with a quantizer that adaptively learns during network training
- Tested on Imagenet and CIFAR-10 with network structures like AlexNet, VGG-Net, GoogLeNet, ResNet, and DenseNet.

Deep Learning with Low Precision by Half-wave Gaussian Quantization
- Design of two approximators for the ReLUnon-linearity
- Half-wave Gaussian quantizer in the feed-forward computations
- A piece-wise continuous function in the backpropagation step
- Network models: AlexNet, ResNet, VGGNet, GooLenet
- GoogLeNet Top1, Full precision: 90.5; HWGQ: 84.90

BitSplit-Net- Multi-bit Deep Neural Network with Bitwise Activation Function
- Improving accuracy by using multi-bit precision using binary activation functions only
- Each bit of multi-bit activations propagates independently throughout the network before being merged at the end of the network
- LeNet-5, VGG-9, AlexNet,and ResNet-18 with lower computational cost
- MNIST (99.32), CIFAR-10 (Top-1 54.8) and ImageNet (T1 - 67.9) datasets

Training Competitive Binary Neural Networks from Scratch
- Version 2 of BMXNet: increase performance without prior knowledge and a much simpler training strategy
- Increasing the number of shortcut connections improves classification accuracy
- MNIST (99% - 202KB), CIFAR10 (90.3% - 1.39MB) and ImageNet (54.3%) datasets

BNN+- Improved Binary Network Training
- Train BNN with two novel regularization functions along with learnable scaling factors parameters
- Proposed SignSwish activation to replace Straight Trough Estimator (STE) loss and to remain differentiable at range -1 +1
- CIFAR-10 (87.4%); AlexNet (83.9%) withDoReFa network

Accuracy to Throughput Trade-Offs for Reduced Precision Neural Networks on Reconfigurable Logic
- Propose quantitative estimation models to show how parameter precision affects hardware cost
- MNIST (99%), CIFAR10 with AlexNet
- Xilinx Kintex UltraScale 115 as the target FPGA device
- INT2 and INT4 generally provide better trade-offs in small image classification tasks

MOBIUS- Model-Oblivious Binarized Neural Networks
- Enables scalable encrypted prediction and encryption of a trained model using BNN and secure computation based on secret sharing
- Composed of protocols we call secure full connection, secure batch normalization, and secure activation
- 2 EC2 c4.8xlarge with MNIST (95.9% and 0.76sec)

Efficient Object Detection Using Embedded Binarized Neural Networks
- Identifies human subjects in infrared images by using BNN
- 98% without any noise and over 96% even with noise in IR images
- BNN system has much less processing elements, the energy efficiency improves by three orders of magnitude
- Implementation onto an FPGA with 4x speedup compared to a GPU

Back to Simplicity- How to Train Accurate BNNs from Scratch
-
-
-

Matrix and tensor decompositions for training binary neural networks
-
-
-

A Review of Binarized Neural Networks
-
-
-

Efficient Super Resolution Using Binarized Neural Network
-
-
-

Training Binarized Neural Networks using MIP and CP
-
-
-

Using Neuroevolved Binary Neural Networks to solve reinforcement learning environments
-
-
-

< BNN

------> Crypto

Fast Homomorphic Evaluation of Deep Discretized Neural Networks
- FHE–DiNN complexity is strictly linear in the depth of the network and whose parameters can be set beforehand
- Modified BNN to do Homomorphic encryptions, based on the library tfhe (both open source)
- Test over MNIST >97% in 1.7s
- Bootstrapping technique that offer an improvement in efficiency at the cost of increasing the storage requirements

The AlexNet Moment for Homomorphic Encryption- HCNN, the First Homomorphic CNN on Encrypted Data with GPUs
- Runs a pre-learned model on encrypted data from the MNIST dataset
- Achieved high security level (> 80 bit) and reasonable classification accuracy (99%) and (77.55%) for MNIST and CIFAR-10
- Execute FHE on GPUs and classifies the entire testing datasets in 6.46 seconds (resp. 3044 seconds), with per-image amortized time (0.788 milliseconds) (resp. 371 milliseconds) for MNIST and CIFAR-10.

CHET- Compiler and Runtime for Homomorphic Evaluation of Tensor Programs
-
-
-

TAPAS- Tricks to Accelerate (encrypted) Prediction As a Service
-
-
-

XONN- XNOR-based Oblivious Deep Neural Network Inference
- XONN requires a constant round of interactions for any number of layers in the model, N inference with a constant round complexity that does not need expensive matrix multiplications
- Novel conditional addition protocol based on Oblivious Transfer
- The datasets include breast cancer, diabetes, liver disease, and Malaria

Chimera- a unified framework for B/FV, TFHE and HEAAN fully homomorphic encryption and predictions for deep learning
- It's modeled the noise generated during the homomorphic operations and the loss of precision by adding a Gaussian error
to the output of each non-linear function
- Only 4 bits of precision (instead of 20 to 40 bits usually) are needed on all fixed point operations throughout the network
- NN of small (LeNet-5), medium (cat-and-dog-9) and large (ResNet-34) size with large relative errors of at least 10%

Bounded Fully Homomorphic Encryption from Monoid Algebras
- Patented
-
-

TFHE: Fast Fully Homomorphic Encryption over the Torus
- Shows that FHEW  can be expressed only in terms of external product between a GSW and
a LWE ciphertext
- Running time of their bootstrapping from 690ms to 13ms single core, using 16MB bootstrapping key instead of 1GB, and preserving the security parameter
- New homomorphic counter called TBSR, that supports all the elementary operations that
occur in a multiplication

FPGA-based High-Performance Parallel Architecture for Homomorphic Computing on Encrypted Data
- Heterogeneous Arm+FPGA platform to accelerate homomorphic computing on encrypted data
- Fan-Vercauteren (FV) homomorphic encryption scheme on the FPGA
- Apply circuit-level and block-level pipeline strategies to boost the clock frequency and increase the throughput respectively
- Xilinx Zynq UltraScale+ MPSoC ZCU102 200MHz 13x speedup over Inter i5 1.8GHz

HEPCloud- An FPGA-based Multicore Processor for FV Somewhat Homomorphic Function
- FPGA-based hardware accelerator for homomorphic evaluations of medium depth functions, which supports the FV SHE scheme
- Based on the SHE accelerator architecture for the YASHE scheme
- Xilinx Virtex-6 ML605 at 100MHz with DDR at 200MHz. 16 cores performing polynomial arithmetic and 2 for lifting operations
- Obstacles, with the speed of the memory interface; despite that, FPGA-based is
a feasible solutions for reducing the large overhead in cloud computing environments

Designing an FPGA-Accelerated Homomorphic Encryption Co-Processor
- Focus on accelerating the Chinese Remainder Transform (CRT) and inverse Chinese Remainder Transform (iCRT) for power-of-2 cyclotomic rings
- Xilinx Virtex-7 FPGA experimental performance analysis on the NTRU-based LTV Homomorphic Encryption scheme
- FPGA-accelerated implementation is more than two orders of magnitude faster than the other implementations

Accelerating Homomorphic Evaluation on Reconfigurable Hardware
- Implement YASHE somewhat homomorphic encryption scheme into an FPGA
- Efficient double-buffered memory access scheme
- Polynomial multiplier based on the number theoretic transform
- Perform a homomorphic addition in 0.94 ms and a homomorphic multiplication in 48.67 ms

HPC on the Intel Xeon Phi: Homomorphic Word Searching
- Executed on 4 Intel Xeon Phi Coprocessors which was 834x times faster
- Perform a search over a set of encrypted words and add the results to get the encrypted value of the number of matches
- Exploiting the fact that the considered cryptosystem relies on matrix multiplication over a specific ring, which is a burdensome operation with a large level of parallelism

FASE- FPGA Acceleration of Secure Function Evaluation
-
-
-

ReDCrypt- Real-Time Privacy-Preserving Deep Learning Inference in Clouds Using FPGAs
-
-
-

Logsum Using Garbled Circuits
-
-
-

Fully Homomorphic Encryption over the Integers with Shorter Public Keys
-
-
-

GELU-Net- A Globally Encrypted, Locally Unencrypted Deep Neural Network for Privacy-Preserved Learning
-
-
-

A Pragmatic Introduction to Secure Multi-Party Computation
-
-
-

A Neural Network Approach for Visual Cryptography
-
-
-

Use of Neural Networks in Cryptography- A Review
-
-
-

Cryptography Using Neural Network
-
-
-

High-speed hardware implementations of Elliptic Curve Cryptography- A survey
-
-
-

Neuro-Cryptanalysis of DES and Triple-DES
-
-
-

Analysis of Neural Cryptography
-
-
-

Cryptography based on delayed chaotic neural networks
-
-
-

Automatic generation of high-performance multiple-input XOR/XNOR circuits and its application in Advanced Encryption Standard (AES)
-
-
-

< Crypto

------> Other

Physics, Topology, Logic and Computation- A Rosetta Stone
- Mentions Category theory from an applied perspective
- Related different branches of science to its application in Category Theory
- Explains concepts in CT like monoidal or CCC
- Mentions lambda calculus in the computation section
- Starts the conversation of how a braided monoidal category can be though of as a quantum process, a tangle or a simple computation.

BMOA- Binary Magnetic Optimization Algorithm
- Physics inspired optimization algorithm
- Uses tanh to calculate the probability that velocity for an agent approximates function minima
- It performs better for full connected topology than GA or Particle Swarm Optimization

Unikernels vs Containers- An In-Depth Benchmarking Study in the Context of Microservice Applications
- Unikernels versus Docker containers in the context of REST services and heavy processing workloads (Java, Go, Python)
- Unikernel does not require context switches from user space to kernel space and has simpler device drivers
- Unikernels are single process by design, so anything requiring multiple parallel processes must be broken up into separate unikernels
- Intel Core i5-2300, 4GB ram, all VM limited to 256MB 1 CPU. Unikernel OSv
-  Go 38% faster in unikernel. Java about 16%

A performance benchmarking analysis of Hypervisors Containers and Unikernels on ARMv8 and x86 CPUs
- CPU, memory and I/O compared for x86 and ARMv8
- KVM as hypervisor solution, Docker and rkt as container engines and finally Rumprun and OSv as unikernels
- Lack of stable support for ARMv8
- Unikernels combine the best of containers and VMs and this makes them lightweight and secure at the same time

The Dataset Nutrition Label- A Framework To Drive Higher Data Quality Standards
- Diagnostic framework that lowers the barrier to standardized data analysis
- Providing a distilled yet comprehensive overview of dataset "ingredients" before AI model development
- For those building and publishing datasets, the Label creates an expectation of explanation

Survey of Stochastic Computing
- Stochastic computing proposed in the 1960's with the advantage of low hardware cost and high error tolerance
- It has an effective replacement for conventional analog or hybrid controllers
- It's biggest drawback are: long computation time (grows with necessary precision); stochastic number generation.
- Can be used in LPDC decoding, AI, low precision environments.

OpenAI Gym
- Python environment for reinforcement learning algorithms
- Includes several topics like: algorithms, control systems, robotics 
- Open source and accessible here: https://github.com/openai/gym

Spike-Based Synaptic Plasticity in Silicon: Design, Implementation, Application, and Challenges
-
-
-

Addressing Neurological Disorders With Neuromodulation
-
-
-

Low power dual edge triggered flip-flop 
-
-
-

Benchmarking Deep Reinforcement Learning for Continuous Control
- Benchmark suite of continuous control tasks, systematic evaluation of a
range of implemented reinforcement learning algorithms
- Applied to basic tasks, locomotion tasks, partially observable tasks, and hierarchical tasks.
- Algorithms:  gradient-based policy search methods, as well as two gradient-free methods

Structured Control Nets for Deep Reinforcement Learning
- Proposed Structured Control Net (SCN) splits the generic MLP into two separate submodules: a nonlinear control module and a linear control module
- Improves training sampling efficiency, final episodic reward, and generalization of learned policy
- OpenAI MuJoCo, Roboschool, Atari, and a custom 2D urban driving environment
- Incorporates problem specific priors into the architecture

High-Performance Pseudorandom Number Generator Using Two-Dimensional Cellular Automata
-
-
-

< Other

------> SNN

Bistable Memory and Binary Counters in Spiking Neural Network
- Show how PNGs are capable of retaining triggering events (PNG - Polychronous Group)
- Bistable neural pools can perform tasks such as binary and stack-like counting
- PNGs have the capability of representing data and the power of controlling sequences of actions taking place within the network

Algorithm and Hardware Design of Discrete-Time Spiking Neural Networks Based on Back Propagation with Binary Activations
- Algorithm that uses binary activations with a straight-through gradient estimator
- Implemented on a energy-efficient neuromorphic hardware (28nm CMOS)
- Evaluated for the MNIST dataset (~98% accuracy)
- Cost of 48.4 nJ per classification

------> Evolutionary

Hardware/Software Partitioning for Heterogeneous Multicore SoC Using Genetic Algorithm
- Investigates genetic algorithm (GA) for hardware/software partitioning
- Processing engines(PE) as CPU, FPGA or ASIC; Communicating structure adopts NOC
- Uses a Task Graph (TG) to model the system; also called Directed Acyclic Graph (DAG) with weights
- GA helps to partition work between PE more efficiently

Evolving simple programs for playing Atari games
- Use Cartesian Genetic programming to evolve simple functions
- Play repeatedly Atari games in Arcade Learning Environment (ALE)
- Use pixel input and floating outputs, also all functions were constrained within [-1,1]
- Improvement of scores over humans or other DNN techniques
- Special mentions about KungFu Master, Centipede or Boxing for its win strategies

Evolution Strategies as a Scalable Alternative to Reinforcement Learning
- Scalable algorithm that linearly grows as the number of CPUs are open
- ES can be competitive with competing RL algorithms 
- Tested with MuJoCo and Atari game lab
- It avoids gradient decent and agent communication is low

Optimization of Deep Neural Networks Using SoCs with OpenCL
-
-
-

An Evolutionary Artificial Neural Network Approach for Breast Cancer Diagnosis
-
-
-

An evolutionary neural network algorithm for max cut problems
-
-
-

Comparison of Neural Network and Hybrid Genetic Algorithm-Neural Network in Forecasting of Philippine Peso-US Dollar Exchange Rate
-
-
-

Convolution by Evolution- Differentiable Pattern Producing Networks
-
-
-

Finance time series prediction using complex-valued flexible neural tree model
-
-
-

Universal Value Function Approximators
-
-
-

Emergent Complexity via Multi-Agent Competition
-
-
-

Simple random search provides a competitive approach to reinforcement learning
-
-
-

Deep Neuroevolution- Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning
- Evolves DNNs with a simple, traditional, population-based genetic algorithm
- The “Deep GA” successfully evolves networks with over four million free parameters
- Combines DNNs with Novelty Search, an exploration algorithm designed for tasks with deceptive or sparse reward functions
- Shows the Deep GA parallelizes better than, and is thus faster than, ES, A3C, and DQN

Towards Generalization and Simplicity in Continuous Control
-
-
-

Large-Scale Evolution of Image Classifiers
-
-
-

Deep Learning with Darwin- Evolutionary Synthesis of Deep Neural Networks
- Uses evolutionary algorithms to improve how the NN inferences more efficiently
- Uses probabilities to make selections between NN  
- Restricts resources available to descendant networks to encourage the evolution of highly-efficient deep neural networks
- Tests datasets: MSRA-B and HKU-IS with VGG-Net model

Evolution in Groups- A deeper look at synaptic cluster driven evolution of deep neural networks
- Focuses on parallelization of NN models via a genetic scheme
- Creates sparse groups via a probabilistic graphical modeling paradigm
- Genetic encoding scheme used to mimic heredity can have a significant impact on the architecture of the evolved offspring networks

DENSER- Deep Evolutionary Network Structured Representation
-
-
-

On the Relationship Between the OpenAI Evolution Strategy and Stochastic Gradient Descent
-
-
-

Simple Evolutionary Optimization Can Rival Stochastic Gradient Descent in Neural Networks
-
-
-

Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning
-
-
-

Parameter-exploring Policy Gradients
-
-
-

Evolution strategies- An alternative evolutionary algorithm
- Presents the (dis)advantages of GA vs ES
- Mentions that GA are more adequate for discrete whereas ES are more suitable for continuous spaces
- ES combines robust converge velocity and reliability compared to GA

Natural Evolution Strategies
- It uses the natural gradient to update a parameterized search distribution
in the direction of higher expected fitness
- In NES, the most important parameter to be adapted is the learning rate (eta)
- Several adaptations to the original idea: exponential NES, radial distributions, rotationally symmetric, separable NES
- NES is compared with CMA-ES

Evolving Neural Networks through Augmenting Topologies
- Outperforms the best fixed-topology method on reinforcement learning tasks
- Employs a principled method of crossover of different topologies
- Protects structural innovation using speciation
- Incrementally growing from minimal structure
- Increasingly sophisticated strategies are evolved by allowing networks to compete

A Genetic Algorithm-Based Solver for Very Large Jigsaw Puzzles
- Solve puzzles up to 22,000 pieces
- Detects, extracts and combine segments from parents to create improved children 
- Create and shares benchmark images for future testing

Information Collection Strategies In Memetic Cooperative Neuroevolution For Time Series Prediction 
- Cooperative coevolution has been combined as memetic cooperative neuroevolution with application to chaotic time series prediction
- Collection strategies that maintains and refines a pool of memes during global search
- Two collection strategies: sequential and concurrent
- Datasets: sunspot, TWI exchange, SantaFe Laser, Mackey Glass and Lorenz

Neuroevolution- Problems, algorithms, and experiments
- "Reinforcement learning is a compromise between research of unexplored areas and application of existing knowledge"
- TWEANNs was able to solve the trolley problem, also talking about research centers around neuroevolution
- In their proposal, TWEANN dismissed the crossover operator in favor of mutation
- Compares the trolley problem with NEAT

NeuroEvolution of Augmenting Topologies with Learning for Data Classification
- Proposes a hybrid training scheme Learning-NEAT (L-NEAT) for data classification
- Incorporating back propagation rule into NEAT
- "The lack of mechanism to guide the weight update slows down the discovery of a perfect solution"
- NEAT is good at global search, it is not efficient in fine-tuning local search

Neuroevolution in Games: State of the Art and Open Challenges
- NE is easily applicable and often high-performing, however the outstanding research question here is: when should one use NE?
- In many cases, TD-based algorithms learn faster but are more brittle and NE eventually reaches higher performance
- What is needed is some sort of general theory of what problem characteristics advantage and disadvantage NE
- Next step, start inventing hybrid algorithms that combine the strengths of both neuroevolution and its alternatives

Towards Hardware Acceleration of Neuroevolution for Multimedia Processing Applications on Mobile Devices
- Proposed digital hardware architecture capable of processing any evolved network topology
- Memory partitioning and data caching are used to minimise the effects of PE pipeline stalling
- XOR problem and the double pole balancing tests problem 
- Used Verilog with a 90nm TSMC ASIC library

A Public Key Compression Method for Fully Homomorphic Encryption using Genetic Algorithms
- Optimizes public keys compression techniques using Genetic Algorithms
- Used a  variant runtime primitive cryptographic model of Coron
- From 18MB to 630KB vs 784MB previous work

Evolutionary Neuro-Fuzzy Systems and Applications
- Neural fuzzy system and an evolutionary fuzzy system hybridises the approximate reasoning mechanism of fuzzy systems
- Hybridise the neurocomputing approach with the solution-searching ability of evolutionary computing
- Attention to the combined use of evolutionary algorithms and neural networks in order to endow fuzzy systems with learning and adaptive capabilities

Dynamic High Frequency Trading- A Neuro-Evolutionary Approach
- NEAT evolve of dynamic trading agents for the German Bond Futures Market
- Four fitness functions are tested and their out of sample performance is presented
- Fail to yield positive returns when realistic transaction costs are included

Artificial evolution using neuroevolution of augmenting topologies (NEAT) for kinetics study in diverse viscous mediums
- Evolution of artificial creatures which moves in a 3D virtual environment
- Creatures with similar morphological traits are grouped into the same species to limit the complexity of the search space
- Crossover of the neural networks is conducted by the NEAT algorithm

Large-Scale Evolution of Image Classifiers
- Start with a population of 1000 very simple linear regression models, and then use tournament selection
- Each evolutionary step, a worker process (250 of them running in parallel) chooses two individuals at random and compares their fitness
- Using this strategy to search large spaces of complex image models requires considerable computation
- Authors developed a massively-parallel, lock-free infrastructure
- Children to inherit the parents’ weights whenever possible.

Regularized Evolution for Image Classifier Architecture Search
- Applying evolutionary algorithms to the search space like mutations that modify the cell by randomly reconnecting the inputs or randomly replacing the operations
- Evolution can indeed find state-of-the-art models that either match or outperform hand-designs
- Compares evolution with reinforcement learning and random search with ImageNet (82.8%)

Intelligent decision-making through a simulation of evolution
-
-
-

Adjusting Weights in Artificial Neural Networks using Evolutionary Algorithms
- Use GA, EDA, ES to estimate NN weights with/without BP
- Tested on KILN, ECOLI and breast cancer datasets
- It concludes that EA remain competitive given their simplicity

A symmetric key cryptography using genetic algorithm and error back propagation neural network
- Symmetric key algorithm based on genetic algorithm (GA) and error back propagation neural network (EBP-NN)
- Genetic algorithm has been used for encryption and neural network has been used for decryption process
- Does not use a key to scramble data
- The NN can only learn one pattern at the time

Neural Cryptography Based on the Topology Evolving Neural Networks
- Create neural cryptography scheme on a new topology evolving NN architecture called Spectrum-diverse unified neuroevolution architecture
- Achieve the neural symmetric cryptosystem by using adversarial training
- Creates several areas in each neuron and divided the whole network into 3 parts: connection nodes(CN), encryption nodes(EN) and decryption nodes

Spectrum-Diverse Neuroevolution With Unified Neural Models
- A new TWEANN that joins most of the NN features into one unified representation
- The proposed algorithm outperformed NEAT on most of the problems
- Spectrum diversity allows the chromosomes that are novel enough to be kept even when their fitness is abysmally poor
- Spectrum diversity scales better with the size of chromosome than speciation

EvoNN - A Customizable Evolutionary Neural Network with Heterogenous Activation Functions
- Focuses on simultaneous evolution of weights and the activation functions within hidden layers
- Additional run time cost with superior performance to traditional standard NN
- Iris, Breast cancer and wine datasets
- EvoNN does not use gradient directly it does not require for the activation functions, or the fitness function, to be differentiable

Recurrent Cartesian Genetic Programming of Artificial
- Extend CGP to support recurrent connections with applications on time series
- Tested with Laser, Sunsports, Mackey-Glass datasets  
- Compared with RWF, MEAN, ETS, aRIMA, MLP, CGP, RCGP, CGPANN
- RCGPANNs also outperformed all the other methods based on CGP with statistical significance

Foreign Currency Exchange Rates Prediction Using CGP and Recurrent Neural Network
- Uses RCGPANN to predict forex market 
- Efficient performance thanks to its ability to select the best possible feature, network architecture and connectivity pattern for prediction
- Historical data sets of 1000 days for Yen, NZ, CAN, Won and Rupiah with up to 98.5% accuracy.  

Novelty-organizing team of classifiers in noisy and dynamic environments
- NOTC compared with NEAT with better performance but more time to convergence
- It used the novelty map and populations to keep track of already visited states using novelty measurements
- Novelty maps do not depend on input frequency or cell's efficiency
- Tested with the mountain car with several changes (continuous, noisy and with weather)

Designing neural networks through neuroevolution
- Survey of the changes in the area of neuroevolution, since 1980's
- NEAT addressed the problem of crossing over variable topologies through historical marking 
- Evolving new content in real time while the game is played
- Evolutionary algorithms can be less sample efficient, but because they are extremely parallelizable, they can run far faster in real (wall clock) time (for example hours instead of days), albeit at the cost of requiring more computing resources
- A final critical opportunity for neuroevolution is to lead the effort to construct ‘open-ended’ algorithms

Evolutionary architecture search for deep multitask networks
- Multitask learning (MTL): a neural network is trained simultaneously to perform several different tasks at once
- CoDeepNEAT begins by initializing two populations, one of modules and one of blueprints, with minimal complexity
- Tested with Omniglot Character Recognition, with 87.82 test accuracy
- When evolution is run multiple times, similar topologies for the same alphabet result

Limited Evaluation Evolutionary Optimization of Large Neural Networks
- Efficient batch fitness evaluation of a population of neural networks on GPUs
- Use low selective pressure as an alternative
- Uniform crossover works best among different mutation strength adaptation schemes
- Train a network of 92k parameters on MNIST using an EA and reach an average test accuracy of 97.6%

Limited evaluation cooperative co-evolutionary differential evolution for large-scale neuroevolution
- Cooperation co-evolution: subcomponents are merged together to assign a global fitness score to a candidate solution
- LE and CC schemes to improve the accuracy and runtime of standard DE algorithm for large-scale NE with direct encoding
- MNIST dataset with 96.60, 93.84, and 93.38 on training
- LE scheme reduces the runtime of the algorithms, without affecting the performance

A comparison between cellular encoding and direct encoding for genetic neural networks
- Compares the efficiency of two encoding schemes: direct and cellular encoding
- RL problem of balancing one or more poles on a cart moving on a fixed track
- Solutions found by Cellular Encoding are smaller than those obtained using methods and architectures developed

Evolutionary reinforcement learning of artificial neural networks
- Structure of the networks is developed using mutation operators, starting from a minimal structure
- Parameters are optimised using CMA-ES, Covariance Matrix Adaptation Evolution Strategy
- Simulated visual servoing scenario with 1023 start poses

Efficient Evolution of Neural Networks through Complexification
- Starting minimally, NEAT is more likely to find efficient and robust solutions than neuroevolution methods that begin with large fixed or randomized topologies
- NEAT is used to successfully discover complex behavior in three challenging domains
- Game of Go, an automobile warning system, and a real-time interactive video game

An Implementation of Evolutionary Computation Operators in OpenCL
- Multiple evolutionary operators are tested: tournament, roulette wheel selection, uniform and Gaussian mutation, crossover, recombination
- Computing the inner loops of the evolutionary algorithms inside the kernel gives the best performance
- OpenCL executed on NVidia GeForce GTX 560Ti and AMD Radeon 6950

Intrinsic evolvable hardware for combinatorial synthesis based on soc+fpga and gpu platforms
- Genetic Programming was implemented in a GPU and High Performance Computers
- Pseudo random number generation, a Mersenne-Twister-based coprocessor was inserted 
- HPC (512 processors) and GPU (192 CUDA cores)

Implementation of Parallel Genetic Algorithm Based on CUDA
- PGA running on a GeForce 8
- Distribute subpopulation to each shared memory of thread block
- Each grid exchanges best individuals using stepping stone model

Accelerating floating-point fitness functions in evolutionary algorithms- a FPGA-CPU-GPU performance comparison
- Complexity and configurability of EAs allows for a rapid processing of the time consuming parts in hardware
- Applied to Radio Network Design Problem (RND), also XRAY and ECC
- Comparison of fitness times between FPGA and CPU, in RND is 12x faster
- Xilinx ISE 9.2i, ModelSim 6, VHDL and Handel-C
- Times power in CPU cluster is greater than FPGA cluster: 114x for RND

A Co-processor System with a Virtex FPGA for Evolutionary Computation
- Agents expressed as bit-strings can be stored in distributed select RAMs very efficiently
- FPGA's partial reconfiguration and readback functions make it possible to exploit more parallelism without thinking about circuits for data I/O
- Speed gain for functions on Virtex XCV1000 is about 200x times compared with Pentium-III 750MHz

Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents
-
-
-

Efficient evolution of neural network topologies
-
-
-

< Evolutionary
