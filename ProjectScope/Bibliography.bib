%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for RHVT at 2018-03-20 22:15:52 +1300 


%% Saved with string encoding Unicode (UTF-8) 



@article{6701396,
	Author = {D. Neil and S. C. Liu},
	Date-Added = {2018-03-20 09:15:46 +0000},
	Date-Modified = {2018-03-20 09:15:46 +0000},
	Doi = {10.1109/TVLSI.2013.2294916},
	Issn = {1063-8210},
	Journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
	Keywords = {field programmable gate arrays;neural nets;CPU;MNIST handwritten digit classification;Minitaur;event-driven FPGA;event-driven neural network accelerator;field-programmable gate array-based system;neural networks;newsgroups classification data;robotics;spiking deep network;spiking network accelerator;Biological neural networks;Clocks;Computer architecture;Field programmable gate arrays;Mathematical model;Neurons;Performance evaluation;Deep belief networks;field programmable arrays;machine learning;neural networks;restricted Boltzmann machines;spiking neural networks},
	Month = {Dec},
	Number = {12},
	Pages = {2621-2628},
	Title = {Minitaur, an Event-Driven FPGA-Based Spiking Network Accelerator},
	Volume = {22},
	Year = {2014},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVLSI.2013.2294916}}

@book{Make-Your-Own-Neural-Network,
	Adsurl = {https://www.amazon.co.uk/Make-Your-Own-Neural-Network/dp/1530826608},
	Author = {{Rashid}, Tariq},
	Date-Added = {2018-03-03 10:33:43 +0000},
	Date-Modified = {2018-03-03 10:33:43 +0000},
	Keywords = {Computer Science, Neural Network, Python},
	Month = March,
	Title = {{Make Your Own Neural Network}},
	Year = 2016}

@article{798320,
	Author = {C. Elliott},
	Date-Added = {2018-02-26 09:50:52 +0000},
	Date-Modified = {2018-02-26 09:50:52 +0000},
	Doi = {10.1109/32.798320},
	Issn = {0098-5589},
	Journal = {IEEE Transactions on Software Engineering},
	Keywords = {computer animation;multimedia computing;simulation languages;Fran;Haskell;declarative host language;embedded domain-specific vocabulary;embedded modeling language approach;growth;interactive 3D animation;interactive multimedia animation;modeled animation;motion;Animation;Automatic programming;Computer graphics;Computer languages;Domain specific languages;Functional programming;Programming profession;Shape;Vocabulary;Writing},
	Month = {May},
	Number = {3},
	Pages = {291-308},
	Title = {An embedded modeling language approach to interactive 3D and multimedia animation},
	Volume = {25},
	Year = {1999},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/32.798320}}

@techreport{Hudak94vs.ada,
	Author = {Paul Hudak and Mark P. Jones},
	Date-Added = {2018-02-26 09:38:35 +0000},
	Date-Modified = {2018-02-26 09:38:35 +0000},
	Keywords = {DARPA, haskell, Cpp, Awk},
	Title = {vs. Ada vs. C++ vs. Awk vs. ... An Experiment in Software Prototyping Productivity Available from http://www.haskell.org/papers/NSWC/jfp.ps},
	Year = {1994}}

@inproceedings{Totoo:2012:HVF:2364474.2364483,
	Acmid = {2364483},
	Address = {New York, NY, USA},
	Author = {Totoo, Prabhat and Deligiannis, Pantazis and Loidl, Hans-Wolfgang},
	Booktitle = {Proceedings of the 1st ACM SIGPLAN Workshop on Functional High-performance Computing},
	Date-Added = {2018-02-26 08:51:00 +0000},
	Date-Modified = {2018-02-26 08:51:00 +0000},
	Doi = {10.1145/2364474.2364483},
	Isbn = {978-1-4503-1577-7},
	Keywords = {barnes-hut, f\#, haskell, n-body, parallelism, scala},
	Location = {Copenhagen, Denmark},
	Numpages = {12},
	Pages = {49--60},
	Publisher = {ACM},
	Series = {FHPC '12},
	Title = {Haskell vs. F\# vs. Scala: A High-level Language Features and Parallelism Support Comparison},
	Url = {http://doi.acm.org/10.1145/2364474.2364483},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2364474.2364483},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/2364474.2364483}}

@inproceedings{6209130,
	Author = {M. Fenwick and C. Sesanker and M. R. Schiller and H. J. Ellis and M. L. Hinman and J. Vyas and M. R. Gryk},
	Booktitle = {2012 Ninth International Conference on Information Technology - New Generations},
	Date-Added = {2018-02-26 08:28:41 +0000},
	Date-Modified = {2018-02-26 08:28:41 +0000},
	Doi = {10.1109/ITNG.2012.21},
	Keywords = {Java;LISP;bioinformatics;functional programming;learning (artificial intelligence);public domain software;software engineering;Haskell;Java;LISP;Python;algorithm development;bioinformatics;complex data operations;complex mathematical notions;data processing;functional computing;functional languages;functional programming accessibility;functional programming techniques;learning curve;learning resources;machine learning;multilanguage source-code repository;open-source Sandbox;scientific communities;software integration;Bioinformatics;Data visualization;Functional programming;Nuclear magnetic resonance;Proteins;Schedules;Transient analysis;Clojure;Haskell;Java;LISP;NMR;bioinformatics;functional-programming},
	Month = {April},
	Pages = {89-94},
	Title = {An Open-Source Sandbox for Increasing the Accessibility of Functional Programming to the Bioinformatics and Scientific Communities},
	Year = {2012},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/ITNG.2012.21}}

@inproceedings{Pop:2010:ERH:1863543.1863595,
	Acmid = {1863595},
	Address = {New York, NY, USA},
	Author = {Pop, Iustin},
	Booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
	Date-Added = {2018-02-26 08:27:07 +0000},
	Date-Modified = {2018-02-26 08:27:07 +0000},
	Doi = {10.1145/1863543.1863595},
	Isbn = {978-1-60558-794-3},
	Keywords = {ganeti, haskell, python, system administration},
	Location = {Baltimore, Maryland, USA},
	Numpages = {6},
	Pages = {369--374},
	Publisher = {ACM},
	Series = {ICFP '10},
	Title = {Experience Report: Haskell As a Reagent: Results and Observations on the Use of Haskell in a Python Project},
	Url = {http://doi.acm.org/10.1145/1863543.1863595},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1863543.1863595},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/1863543.1863595}}

@inproceedings{Nanz:2015:CSP:2818754.2818848,
	Acmid = {2818848},
	Address = {Piscataway, NJ, USA},
	Author = {Nanz, Sebastian and Furia, Carlo A.},
	Booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
	Date-Added = {2018-02-26 07:03:13 +0000},
	Date-Modified = {2018-02-26 07:03:13 +0000},
	Isbn = {978-1-4799-1934-5},
	Location = {Florence, Italy},
	Numpages = {11},
	Pages = {778--788},
	Publisher = {IEEE Press},
	Series = {ICSE '15},
	Title = {A Comparative Study of Programming Languages in Rosetta Code},
	Url = {http://dl.acm.org/citation.cfm?id=2818754.2818848},
	Year = {2015},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2818754.2818848}}

@article{2010arXiv1009.0305R,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2010arXiv1009.0305R},
	Archiveprefix = {arXiv},
	Author = {{Rabah}, S. and {Li}, J. and {Liu}, M. and {Lai}, Y.},
	Date-Added = {2018-02-22 23:19:52 +0000},
	Date-Modified = {2018-02-22 23:19:52 +0000},
	Eprint = {1009.0305},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Programming Languages, D.3},
	Month = sep,
	Primaryclass = {cs.PL},
	Title = {{Comparative Studies of 10 Programming Languages within 10 Diverse Criteria -- a Team 7 COMP6411-S10 Term Report}},
	Year = 2010}

@article{2017arXiv171109846J,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171109846J},
	Archiveprefix = {arXiv},
	Author = {{Jaderberg}, M. and {Dalibard}, V. and {Osindero}, S. and {Czarnecki}, W.~M. and {Donahue}, J. and {Razavi}, A. and {Vinyals}, O. and {Green}, T. and {Dunning}, I. and {Simonyan}, K. and {Fernando}, C. and {Kavukcuoglu}, K.},
	Date-Added = {2018-02-21 06:49:04 +0000},
	Date-Modified = {2018-02-21 06:49:04 +0000},
	Eprint = {1711.09846},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	Month = nov,
	Primaryclass = {cs.LG},
	Title = {{Population Based Training of Neural Networks}},
	Year = 2017}

@article{2014arXiv1410.5401G,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1410.5401G},
	Archiveprefix = {arXiv},
	Author = {{Graves}, A. and {Wayne}, G. and {Danihelka}, I.},
	Date-Added = {2018-02-21 06:07:10 +0000},
	Date-Modified = {2018-02-21 06:07:10 +0000},
	Eprint = {1410.5401},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Neural and Evolutionary Computing},
	Month = oct,
	Title = {{Neural Turing Machines}},
	Year = 2014}

@article{2015arXiv150308895S,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150308895S},
	Archiveprefix = {arXiv},
	Author = {{Sukhbaatar}, S. and {Szlam}, A. and {Weston}, J. and {Fergus}, R.},
	Date-Added = {2018-02-21 05:45:01 +0000},
	Date-Modified = {2018-02-21 05:45:01 +0000},
	Eprint = {1503.08895},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
	Month = mar,
	Title = {{End-To-End Memory Networks}},
	Year = 2015}

@article{2014arXiv1409.0473B,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1409.0473B},
	Archiveprefix = {arXiv},
	Author = {{Bahdanau}, D. and {Cho}, K. and {Bengio}, Y.},
	Date-Added = {2018-02-21 05:29:04 +0000},
	Date-Modified = {2018-02-21 05:29:04 +0000},
	Eprint = {1409.0473},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Computation and Language, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	Month = sep,
	Primaryclass = {cs.CL},
	Title = {{Neural Machine Translation by Jointly Learning to Align and Translate}},
	Year = 2014}

@article{2015arXiv150203044X,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150203044X},
	Archiveprefix = {arXiv},
	Author = {{Xu}, K. and {Ba}, J. and {Kiros}, R. and {Cho}, K. and {Courville}, A. and {Salakhutdinov}, R. and {Zemel}, R. and {Bengio}, Y.},
	Date-Added = {2018-02-21 04:55:23 +0000},
	Date-Modified = {2018-02-21 04:55:23 +0000},
	Eprint = {1502.03044},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition},
	Month = feb,
	Primaryclass = {cs.LG},
	Title = {{Show, Attend and Tell: Neural Image Caption Generation with Visual Attention}},
	Year = 2015}

@article{2015arXiv150301007J,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150301007J},
	Archiveprefix = {arXiv},
	Author = {{Joulin}, A. and {Mikolov}, T.},
	Date-Added = {2018-02-21 04:03:18 +0000},
	Date-Modified = {2018-02-21 04:03:18 +0000},
	Eprint = {1503.01007},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Learning},
	Month = mar,
	Title = {{Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets}},
	Year = 2015}

@article{2014arXiv1406.6247M,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1406.6247M},
	Archiveprefix = {arXiv},
	Author = {{Mnih}, V. and {Heess}, N. and {Graves}, A. and {Kavukcuoglu}, K.},
	Date-Added = {2018-02-21 04:01:10 +0000},
	Date-Modified = {2018-02-21 04:01:10 +0000},
	Eprint = {1406.6247},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	Month = jun,
	Primaryclass = {cs.LG},
	Title = {{Recurrent Models of Visual Attention}},
	Year = 2014}

@article{2013arXiv1308.0850G,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1308.0850G},
	Archiveprefix = {arXiv},
	Author = {{Graves}, A.},
	Date-Added = {2018-02-21 03:44:05 +0000},
	Date-Modified = {2018-02-21 03:44:05 +0000},
	Eprint = {1308.0850},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
	Month = aug,
	Title = {{Generating Sequences With Recurrent Neural Networks}},
	Year = 2013}

@article{2015arXiv150204390D,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150204390D},
	Archiveprefix = {arXiv},
	Author = {{Dauphin}, Y.~N. and {de Vries}, H. and {Bengio}, Y.},
	Date-Added = {2018-02-21 02:45:02 +0000},
	Date-Modified = {2018-02-21 02:45:02 +0000},
	Eprint = {1502.04390},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Computer Science - Numerical Analysis},
	Month = feb,
	Primaryclass = {cs.LG},
	Title = {{Equilibrated adaptive learning rates for non-convex optimization}},
	Year = 2015}

@article{2016arXiv160604934K,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160604934K},
	Archiveprefix = {arXiv},
	Author = {{Kingma}, D.~P. and {Salimans}, T. and {Jozefowicz}, R. and {Chen}, X. and {Sutskever}, I. and {Welling}, M.},
	Date-Added = {2018-02-20 10:42:29 +0000},
	Date-Modified = {2018-02-20 10:42:29 +0000},
	Eprint = {1606.04934},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Statistics - Machine Learning},
	Month = jun,
	Primaryclass = {cs.LG},
	Title = {{Improving Variational Inference with Inverse Autoregressive Flow}},
	Year = 2016}

@article{2015arXiv150204623G,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150204623G},
	Archiveprefix = {arXiv},
	Author = {{Gregor}, K. and {Danihelka}, I. and {Graves}, A. and {Jimenez Rezende}, D. and {Wierstra}, D.},
	Date-Added = {2018-02-20 10:42:05 +0000},
	Date-Modified = {2018-02-20 10:42:05 +0000},
	Eprint = {1502.04623},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	Month = feb,
	Primaryclass = {cs.CV},
	Title = {{DRAW: A Recurrent Neural Network For Image Generation}},
	Year = 2015}

@article{2016arXiv160603657C,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160603657C},
	Archiveprefix = {arXiv},
	Author = {{Chen}, X. and {Duan}, Y. and {Houthooft}, R. and {Schulman}, J. and {Sutskever}, I. and {Abbeel}, P.},
	Date-Added = {2018-02-20 00:17:44 +0000},
	Date-Modified = {2018-02-20 00:17:44 +0000},
	Eprint = {1606.03657},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Statistics - Machine Learning},
	Month = jun,
	Primaryclass = {cs.LG},
	Title = {{InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets}},
	Year = 2016}

@article{2016arXiv160509674H,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160509674H},
	Archiveprefix = {arXiv},
	Author = {{Houthooft}, R. and {Chen}, X. and {Duan}, Y. and {Schulman}, J. and {De Turck}, F. and {Abbeel}, P.},
	Date-Added = {2018-02-19 23:51:31 +0000},
	Date-Modified = {2018-02-19 23:51:31 +0000},
	Eprint = {1605.09674},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics, Statistics - Machine Learning},
	Month = may,
	Primaryclass = {cs.LG},
	Title = {{VIME: Variational Information Maximizing Exploration}},
	Year = 2016}

@article{2016arXiv160603476H,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160603476H},
	Archiveprefix = {arXiv},
	Author = {{Ho}, J. and {Ermon}, S.},
	Date-Added = {2018-02-19 10:11:33 +0000},
	Date-Modified = {2018-02-19 10:11:33 +0000},
	Eprint = {1606.03476},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Computer Science - Artificial Intelligence},
	Month = jun,
	Primaryclass = {cs.LG},
	Title = {{Generative Adversarial Imitation Learning}},
	Year = 2016}

@article{DBLP:journals/corr/SalimansGZCRC16,
	Archiveprefix = {arXiv},
	Author = {Tim Salimans and Ian J. Goodfellow and Wojciech Zaremba and Vicki Cheung and Alec Radford and Xi Chen},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.org/rec/bib/journals/corr/SalimansGZCRC16},
	Date-Added = {2018-02-19 09:53:01 +0000},
	Date-Modified = {2018-02-19 10:06:38 +0000},
	Eprint = {1606.03498},
	Journal = {CoRR},
	Keywords = {DCGAN, MNIST, Semi-Supervised learning, minibatch},
	Timestamp = {Wed, 07 Jun 2017 14:40:52 +0200},
	Title = {Improved Techniques for Training GANs},
	Url = {http://arxiv.org/abs/1606.03498},
	Volume = {abs/1606.03498},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1606.03498}}

@article{2014arXiv1406.2661G,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1406.2661G},
	Archiveprefix = {arXiv},
	Author = {{Goodfellow}, I.~J. and {Pouget-Abadie}, J. and {Mirza}, M. and {Xu}, B. and {Warde-Farley}, D. and {Ozair}, S. and {Courville}, A. and {Bengio}, Y.},
	Date-Added = {2018-02-19 09:28:01 +0000},
	Date-Modified = {2018-02-19 09:28:01 +0000},
	Eprint = {1406.2661},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning, Computer Science - Learning},
	Month = jun,
	Primaryclass = {stat.ML},
	Title = {{Generative Adversarial Networks}},
	Year = 2014}

@article{2013arXiv1312.6114K,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1312.6114K},
	Archiveprefix = {arXiv},
	Author = {{Kingma}, D.~P and {Welling}, M.},
	Date-Added = {2018-02-19 09:25:50 +0000},
	Date-Modified = {2018-02-19 09:25:50 +0000},
	Eprint = {1312.6114},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning, Computer Science - Learning},
	Month = dec,
	Primaryclass = {stat.ML},
	Title = {{Auto-Encoding Variational Bayes}},
	Year = 2013}

@article{DBLP:journals/corr/OordKK16,
	Archiveprefix = {arXiv},
	Author = {A{\"{a}}ron van den Oord and Nal Kalchbrenner and Koray Kavukcuoglu},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.org/rec/bib/journals/corr/OordKK16},
	Date-Added = {2018-02-19 09:01:51 +0000},
	Date-Modified = {2018-02-19 09:05:45 +0000},
	Eprint = {1601.06759},
	Journal = {CoRR},
	Keywords = {RNN, PixelRNN, BiLSTM, MNIST},
	Timestamp = {Wed, 07 Jun 2017 14:40:22 +0200},
	Title = {Pixel Recurrent Neural Networks},
	Url = {http://arxiv.org/abs/1601.06759},
	Volume = {abs/1601.06759},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1601.06759}}

@article{DBLP:journals/corr/KulkarniWKT15,
	Archiveprefix = {arXiv},
	Author = {Tejas D. Kulkarni and Will Whitney and Pushmeet Kohli and Joshua B. Tenenbaum},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.org/rec/bib/journals/corr/KulkarniWKT15},
	Date-Added = {2018-02-19 04:44:04 +0000},
	Date-Modified = {2018-02-19 04:44:43 +0000},
	Eprint = {1503.03167},
	Journal = {CoRR},
	Keywords = {CNN, IGN, SGVB, DC-IGN},
	Timestamp = {Wed, 07 Jun 2017 14:40:29 +0200},
	Title = {Deep Convolutional Inverse Graphics Network},
	Url = {http://arxiv.org/abs/1503.03167},
	Volume = {abs/1503.03167},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1503.03167}}

@article{2017arXiv170100160G,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170100160G},
	Archiveprefix = {arXiv},
	Author = {{Goodfellow}, I.},
	Date-Added = {2018-02-16 06:51:27 +0000},
	Date-Modified = {2018-02-16 06:51:27 +0000},
	Eprint = {1701.00160},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning},
	Month = dec,
	Primaryclass = {cs.LG},
	Title = {{NIPS 2016 Tutorial: Generative Adversarial Networks}},
	Year = 2017}

@article{2017arXiv170900199H,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170900199H},
	Archiveprefix = {arXiv},
	Author = {{Hadad}, N. and {Wolf}, L. and {Shahar}, M.},
	Date-Added = {2018-02-07 01:32:29 +0000},
	Date-Modified = {2018-02-07 01:32:29 +0000},
	Eprint = {1709.00199},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Statistics - Machine Learning},
	Month = sep,
	Primaryclass = {cs.LG},
	Title = {{Two-Step Disentanglement for Financial Data}},
	Year = 2017}

@inproceedings{10.1007/3-540-28438-9_2,
	Abstract = {Backwards calculation of derivatives -- sometimes called the reverse mode, the full adjoint method, or backpropagation -- has been developed and applied in many fields. This paper reviews several strands of history, advanced capabilities and types of application -- particularly those which are crucial to the development of brain-like capabilities in intelligent control and artificial intelligence.},
	Address = {Berlin, Heidelberg},
	Author = {Werbos, Paul J.},
	Booktitle = {Automatic Differentiation: Applications, Theory, and Implementations},
	Date-Added = {2018-02-07 01:11:34 +0000},
	Date-Modified = {2018-02-07 01:11:34 +0000},
	Editor = {B{\"u}cker, Martin and Corliss, George and Naumann, Uwe and Hovland, Paul and Norris, Boyana},
	Isbn = {978-3-540-28438-3},
	Pages = {15--34},
	Publisher = {Springer Berlin Heidelberg},
	Title = {Backwards Differentiation in AD and Neural Nets: Past Links and New Opportunities},
	Year = {2006}}

@article{2014arXiv1404.7828S,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1404.7828S},
	Archiveprefix = {arXiv},
	Author = {{Schmidhuber}, J.},
	Date-Added = {2018-02-07 00:15:56 +0000},
	Date-Modified = {2018-02-07 00:15:56 +0000},
	Eprint = {1404.7828},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Learning},
	Month = apr,
	Title = {{Deep Learning in Neural Networks: An Overview}},
	Year = 2014}

@article{2017arXiv170107274L,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170107274L},
	Archiveprefix = {arXiv},
	Author = {{Li}, Y.},
	Date-Added = {2018-02-06 09:19:00 +0000},
	Date-Modified = {2018-02-06 09:19:00 +0000},
	Eprint = {1701.07274},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning},
	Month = jan,
	Primaryclass = {cs.LG},
	Title = {{Deep Reinforcement Learning: An Overview}},
	Year = 2017}

@incollection{NIPS2017_6917,
	Author = {XIAO, SHUAI and Farajtabar, Mehrdad and Ye, Xiaojing and Yan, Junchi and Yang, Xiaokang and Song, Le and Zha, Hongyuan},
	Booktitle = {Advances in Neural Information Processing Systems 30},
	Date-Added = {2018-02-06 09:12:15 +0000},
	Date-Modified = {2018-02-06 09:13:20 +0000},
	Editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	Keywords = {DNN, Generative Adversarial NN, Point processes},
	Pages = {3250--3259},
	Publisher = {Curran Associates, Inc.},
	Title = {Wasserstein Learning of Deep Generative Point Process Models},
	Url = {http://papers.nips.cc/paper/6917-wasserstein-learning-of-deep-generative-point-process-models.pdf},
	Year = {2017},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/6917-wasserstein-learning-of-deep-generative-point-process-models.pdf}}

@book{TheWayOfTheTurtle,
	Author = {Curtis M. Faith},
	Date-Added = {2018-02-06 08:38:52 +0000},
	Date-Modified = {2018-02-06 08:40:50 +0000},
	Keywords = {Finance, Economics Personal, Professional Development},
	Month = {March},
	Number = {9780071486644},
	Publisher = {McGraw-Hill Osborne Media},
	Title = {Way of the Turtle},
	Year = {2007}}

@article{2015arXiv150205767G,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150205767G},
	Archiveprefix = {arXiv},
	Author = {{Gunes Baydin}, A. and {Pearlmutter}, B.~A. and {Andreyevich Radul}, A. and {Siskind}, J.~M.},
	Date-Added = {2018-02-06 01:01:08 +0000},
	Date-Modified = {2018-02-06 01:01:08 +0000},
	Eprint = {1502.05767},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Symbolic Computation, Computer Science - Learning, 68W30, 65D25, 68T05, G.1.4, I.2.6},
	Month = feb,
	Primaryclass = {cs.SC},
	Title = {{Automatic differentiation in machine learning: a survey}},
	Year = 2015}

@misc{2015arXiv151106434R-sc,
	Author = {{Radford}, A. and {Metz}, L. and {Chintala}, S.},
	Date-Added = {2018-02-05 09:50:12 +0000},
	Date-Modified = {2018-02-23 00:38:59 +0000},
	Keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition},
	Month = nov,
	Title = {{Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}},
	Url = {https://github.com/Newmu/dcgan_code},
	Year = 2015,
	Bdsk-Url-1 = {https://github.com/Newmu/dcgan_code}}

@article{2015arXiv151106434R,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2015arXiv151106434R},
	Archiveprefix = {arXiv},
	Author = {{Radford}, A. and {Metz}, L. and {Chintala}, S.},
	Date-Added = {2018-02-05 09:50:12 +0000},
	Date-Modified = {2018-02-05 09:50:12 +0000},
	Eprint = {1511.06434},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition},
	Month = nov,
	Primaryclass = {cs.LG},
	Title = {{Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}},
	Year = 2015}

@misc{Grenade-Github-Code,
	Address = {San Francisco, CA, USA},
	Author = {Campbell, Huw},
	Date-Added = {2018-02-05 09:27:10 +0000},
	Date-Modified = {2018-02-23 00:39:26 +0000},
	Day = {24},
	Keywords = {functional programming, DNN, CNN, sourcecode},
	Month = {June},
	Publisher = {Github},
	Title = {Grenade},
	Url = {https://github.com/HuwCampbell/grenade},
	Year = {2016},
	Bdsk-Url-1 = {https://github.com/HuwCampbell/grenade}}

@inproceedings{Zhang:2015:OFA:2684746.2689060,
	Acmid = {2689060},
	Address = {New York, NY, USA},
	Author = {Zhang, Chen and Li, Peng and Sun, Guangyu and Guan, Yijin and Xiao, Bingjun and Cong, Jason},
	Booktitle = {Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
	Date-Added = {2018-02-05 09:06:58 +0000},
	Date-Modified = {2018-02-05 09:06:58 +0000},
	Doi = {10.1145/2684746.2689060},
	Isbn = {978-1-4503-3315-3},
	Keywords = {acceleration, convolutional neural network, fpga, roofline model},
	Location = {Monterey, California, USA},
	Numpages = {10},
	Pages = {161--170},
	Publisher = {ACM},
	Series = {FPGA '15},
	Title = {Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks},
	Url = {http://doi.acm.org/10.1145/2684746.2689060},
	Year = {2015},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2684746.2689060},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/2684746.2689060}}

@article{2016arXiv161102450W,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv161102450W},
	Archiveprefix = {arXiv},
	Author = {{Wang}, D. and {An}, J. and {Xu}, K.},
	Date-Added = {2018-02-05 09:06:58 +0000},
	Date-Modified = {2018-02-05 09:06:58 +0000},
	Eprint = {1611.02450},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Hardware Architecture},
	Month = nov,
	Title = {{PipeCNN: An OpenCL-Based FPGA Accelerator for Large-Scale Convolution Neuron Networks}},
	Year = 2016}

@article{anonymous2018wavelet,
	Author = {Anonymous},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Journal = {International Conference on Learning Representations},
	Keywords = {Wavelet, CNN, MIST, MathConvNet},
	Title = {Wavelet Pooling for Convolutional Neural Networks},
	Url = {https://openreview.net/forum?id=rkhlb8lCZ},
	Year = {2018},
	Bdsk-Url-1 = {https://openreview.net/forum?id=rkhlb8lCZ}}

@book{Nayak:2017aa,
	Author = {Nayak, Sarat and Bihari Misra, Bijan and Behera, Dr. H.},
	Date = {2017/01/01},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.4018/978-1-5225-0788-8.ch022},
	Journal = {Nature-Inspired Computing: Concepts, Methodologies, Tools, and Applications},
	Keywords = {HONN, Pi-Sigma, Genetic Algorithms},
	Month = {01},
	N2 = {This chapter presents two higher order neural networks (HONN) for efficient prediction of stock market behavior. The models include Pi-Sigma, and Sigma-Pi higher order neural network models. Along with the traditional gradient descent learning, how the evolutionary computation technique such as genetic algorithm (GA) can be used effectively for the learning process is also discussed here. The learning process is made adaptive to handle the noise and uncertainties associated with stock market data. Further, different prediction approaches are discussed here and application of HONN for time series forecasting is illustrated with real life data taken from a number of stock markets across the globe.},
	Title = {Adaptive Hybrid Higher Order Neural Networks for Prediction of Stock Market Behavior},
	Ty = {BOOK},
	Year = {2017},
	Bdsk-Url-1 = {https://dx.doi.org/10.4018/978-1-5225-0788-8.ch022}}

@article{CHONG2017187,
	Abstract = {We offer a systematic analysis of the use of deep learning networks for stock market analysis and prediction. Its ability to extract features from a large set of raw data without relying on prior knowledge of predictors makes deep learning potentially attractive for stock market prediction at high frequencies. Deep learning algorithms vary considerably in the choice of network structure, activation function, and other model parameters, and their performance is known to depend heavily on the method of data representation. Our study attempts to provides a comprehensive and objective assessment of both the advantages and drawbacks of deep learning algorithms for stock market analysis and prediction. Using high-frequency intraday stock returns as input data, we examine the effects of three unsupervised feature extraction methods---principal component analysis, autoencoder, and the restricted Boltzmann machine---on the network's overall ability to predict future market behavior. Empirical results suggest that deep neural networks can extract additional information from the residuals of the autoregressive model and improve prediction performance; the same cannot be said when the autoregressive model is applied to the residuals of the network. Covariance estimation is also noticeably improved when the predictive network is applied to covariance-based market structure analysis. Our study offers practical insights and potentially useful directions for further investigation into how deep learning networks can be effectively used for stock market analysis and prediction.},
	Author = {Eunsuk Chong and Chulwoo Han and Frank C. Park},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {https://doi.org/10.1016/j.eswa.2017.04.030},
	Issn = {0957-4174},
	Journal = {Expert Systems with Applications},
	Keywords = {Stock market prediction, Deep learning, Multilayer neural network, Covariance estimation},
	Pages = {187 - 205},
	Title = {Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies},
	Url = {http://www.sciencedirect.com/science/article/pii/S0957417417302750},
	Volume = {83},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0957417417302750},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.eswa.2017.04.030}}

@inproceedings{HuangY.2016Etmt,
	Author = {Huang, Y. and Huang, K. and Wang, Y. and Zhang, H. and Guan, J. and Zhou, S.},
	Copyright = {Copyright 2017 Elsevier B.V., All rights reserved.},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Isbn = {9783319422961},
	Issn = {03029743},
	Journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	Keywords = {Convolutional Neural Network ; Deep Neural Network ; Financial Trend Prediction ; Twitter Mood},
	Pages = {449--460},
	Publisher = {Springer Verlag},
	Title = {Exploiting twitter moods to boost financial trend prediction based on deep network models},
	Volume = {9773},
	Year = {2016}}

@article{diartificial,
	Author = {Di Persio, Luca and Honchar, Oleksandr},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Journal = {International Journal of Economics and Management Systems},
	Keywords = {CNN, RNN, LSTM},
	Month = {January},
	Pages = {5},
	Title = {Artificial neural networks approach to the forecast of stock market price movements},
	Volume = {1},
	Year = {2016}}

@techreport{ghoshal2017reading,
	Author = {Ghoshal, Sid and Roberts, Stephen},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Institution = {Technical report},
	Keywords = {CNN, RNN, Technical Analysis},
	Title = {Reading the Tea Leaves: A Neural Network Perspective on Technical Trading},
	Year = {2017}}

@article{aggarwal2017deep,
	Author = {Aggarwal, Saurabh and Aggarwal, Somya},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Journal = {International Journal of Computer Applications},
	Keywords = {DNN, Finance, Portfolio, LSTM},
	Number = {2},
	Publisher = {Foundation of Computer Science},
	Title = {Deep Investment in Financial Markets using Deep Learning Models},
	Volume = {162},
	Year = {2017}}

@article{di2016artificial,
	Author = {Di Persio, Luca and Honchar, Oleksandr},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Journal = {International Journal of Circuits, Systems and Signal Processing},
	Keywords = {CNN, MLP, LSTM, Wavelet},
	Pages = {403--413},
	Title = {Artificial Neural Networks architectures for stock price prediction: comparisons and applications},
	Volume = {10},
	Year = {2016}}

@article{dixon2016classification,
	Author = {Dixon, Matthew Francis and Klabjan, Diego and Bang, Jin Hoon},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Keywords = {DNN, Futures, Finance},
	Title = {Classification-based Financial Markets Prediction using Deep Neural Networks},
	Year = {2016}}

@misc{essay59381,
	Author = {M. {Kooijman}},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Keywords = {Haskell, functional programming},
	Month = {December},
	Title = {Haskell as a higher order structural hardware description language},
	Url = {http://essay.utwente.nl/59381/},
	Year = {2009},
	Bdsk-Url-1 = {http://essay.utwente.nl/59381/}}

@conference{L:08,
	Author = {Philip H.W. Leong},
	Booktitle = {Proc. 4th IEEE International Symposium on Electronic Design, Test and Applications},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Keywords = {FPGA, Trends},
	Location = {Hong Kong},
	Note = {\textbf{Invited}},
	Pages = {137--141},
	Title = {Recent Trends in {FPGA} Architectures and Applications},
	Url = {rtfpga_delta08.pdf},
	Year = {2008},
	Bdsk-Url-1 = {rtfpga_delta08.pdf}}

@inproceedings{Pike:2009:RYO:1596638.1596646,
	Acmid = {1596646},
	Address = {New York, NY, USA},
	Author = {Pike, Lee and Brown, Geoffrey and Goodloe, Alwyn},
	Booktitle = {Proceedings of the 2Nd ACM SIGPLAN Symposium on Haskell},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1145/1596638.1596646},
	Isbn = {978-1-60558-508-6},
	Keywords = {emulation, functional programming, physical-layer protocol testing},
	Location = {Edinburgh, Scotland},
	Numpages = {8},
	Pages = {61--68},
	Publisher = {ACM},
	Series = {Haskell '09},
	Title = {Roll Your Own Test Bed for Embedded Real-time Protocols: A Haskell Experience},
	Url = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/1596638.1596646},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOS4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL05OL0VuZC1Uby1FbmQgTWVtb3J5IE5ldHdvcmtzLmJpYtIXCxgZV05TLmRhdGFPEQGsAAAAAAGsAAIAAAlNYWNpbnRvc2gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8eRW5kLVRvLUVuZCBNZW1vcnkgTmV0d29ya3MuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAABAAQAAAogY3UAAAAAAAAAAAAAAAAAAk5OAAIATy86VXNlcnM6cmh2dDpEZXY6Q05OLVBoZDpSZWZlcmVuY2VzOkNpdGF0aW9uczpOTjpFbmQtVG8tRW5kIE1lbW9yeSBOZXR3b3Jrcy5iaWIAAA4APgAeAEUAbgBkAC0AVABvAC0ARQBuAGQAIABNAGUAbQBvAHIAeQAgAE4AZQB0AHcAbwByAGsAcwAuAGIAaQBiAA8AFAAJAE0AYQBjAGkAbgB0AG8AcwBoABIATVVzZXJzL3JodnQvRGV2L0NOTi1QaGQvUmVmZXJlbmNlcy9DaXRhdGlvbnMvTk4vRW5kLVRvLUVuZCBNZW1vcnkgTmV0d29ya3MuYmliAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMoAzwDXAocCiQKOApkCogKwArQCuwLEAskC1gLZAusC7gLzAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAvU=},
	Bdsk-Url-1 = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/1596638.1596646},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/1596638.1596646}}

@inproceedings{Schrage:2005:HRD:1088348.1088351,
	Acmid = {1088351},
	Address = {New York, NY, USA},
	Author = {Schrage, Martijn M. and van IJzendoorn, Arjan and van der Gaag, Linda C.},
	Booktitle = {Proceedings of the 2005 ACM SIGPLAN Workshop on Haskell},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1145/1088348.1088351},
	Isbn = {1-59593-071-X},
	Keywords = {application, bayesian networks, graphical user interface, haskell, wxHaskell},
	Location = {Tallinn, Estonia},
	Numpages = {10},
	Pages = {17--26},
	Publisher = {ACM},
	Series = {Haskell '05},
	Title = {Haskell Ready to Dazzle the Real World},
	Url = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/1088348.1088351},
	Year = {2005},
	Bdsk-Url-1 = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/1088348.1088351},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/1088348.1088351}}

@article{Sezer:2017aa,
	Author = {Sezer, Omer Berat and Ozbayoglu, Murat and Dogdu, Erdogan},
	Booktitle = {Complex Adaptive Systems Conference with Theme: Engineering Cyber Physical Systems, CAS October 30 --November 1, 2017, Chicago, Illinois, USA},
	Da = {2017/01/01/},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {https://doi.org/10.1016/j.procs.2017.09.031},
	Isbn = {1877-0509},
	Journal = {Procedia Computer Science},
	Keywords = {Stock Trading; Stock Market; Deep Neural-Network; Evolutionary Algorithms; Technical Analysis},
	Number = {Supplement C},
	Pages = {473--480},
	Title = {A Deep Neural-Network Based Stock Trading System Based on Evolutionary Optimized Technical Analysis Parameters},
	Ty = {JOUR},
	Url = {http://www.sciencedirect.com/science/article/pii/S1877050917318252},
	Volume = {114},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1877050917318252},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.procs.2017.09.031}}

@inproceedings{Kablan:2009aa,
	Author = {A. Kablan},
	Booktitle = {2009 Third International Conference on Advanced Engineering Computing and Applications in Sciences},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/ADVCOMP.2009.23},
	Journal = {2009 Third International Conference on Advanced Engineering Computing and Applications in Sciences},
	Journal1 = {2009 Third International Conference on Advanced Engineering Computing and Applications in Sciences},
	Keywords = {decision making; expert systems; financial data processing; fuzzy reasoning; neural nets; pattern recognition; stock markets; adaptive neuro fuzzy inference systems; automated trading strategy; decision making; efficient market hypothesis; expert system; financial forecasting; financial markets; financial time series; fuzzy reasoning; high frequency financial trading; neural networks; pattern recognition; Adaptive systems; Economic forecasting; Expert systems; Finance; Frequency; Fuzzy reasoning; Fuzzy systems; Humans; Neural networks; Pattern recognition; efficient market hypothesis; financial prediction; high frequency trading; neuro-fuzzy inference system},
	Pages = {105--110},
	Title = {Adaptive Neuro Fuzzy Inference Systems for High Frequency Financial Trading and Forecasting},
	Ty = {CONF},
	Year = {2009},
	Year1 = {11-16 Oct. 2009},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/ADVCOMP.2009.23}}

@article{2003cond.mat..4469K,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2003cond.mat..4469K},
	Author = {{Kondratenko}, V.~V. and {Kuperin}, Y.~A},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Eprint = {cond-mat/0304469},
	Journal = {eprint arXiv:cond-mat/0304469},
	Keywords = {Condensed Matter - Disordered Systems and Neural Networks, Quantitative Finance - Statistical Finance},
	Month = apr,
	Title = {{Using Recurrent Neural Networks To Forecasting of Forex}},
	Year = 2003}

@article{2015arXiv151207108G,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2015arXiv151207108G},
	Archiveprefix = {arXiv},
	Author = {{Gu}, J. and {Wang}, Z. and {Kuen}, J. and {Ma}, L. and {Shahroudy}, A. and {Shuai}, B. and {Liu}, T. and {Wang}, X. and {Wang}, L. and {Wang}, G. and {Cai}, J. and {Chen}, T.},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Eprint = {1512.07108},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	Month = dec,
	Primaryclass = {cs.CV},
	Title = {{Recent Advances in Convolutional Neural Networks}},
	Year = 2015}

@article{Niedermeier:2014aa,
	Abstract = {Data driven streaming applications are quite common in modern multimedia and wireless applications, like for example video and audio processing. The main components of these applications are Digital Signal Processing (DSP) algorithms. These algorithms are not extremely complex in terms of their structure and the operations that make up the algorithms are fairly simple (usually binary mathematical operations like addition and multiplication). What makes it challenging to implement and execute these algorithms efficiently is their large degree of fine-grained parallelism and the required throughput. DSP algorithms can usually be described as dataflow graphs with nodes corresponding to operations and edges between the nodes expressing data dependencies. A node fires, i.e. executes, as soon as all required input data has arrived at its input edge(s). To execute DSP algorithms efficiently while maintaining flexibility, coarse-grained reconfigurable arrays (CGRAs) can be used. CGRAs are composed of a set of small, reconfigurable cores, interconnected in e.g. a two dimensional array. Each core by itself is not very powerful, yet the complete array of cores forms an efficient architecture with a high throughput due to its ability to efficiently execute operations in parallel. In this thesis, we present a CGRA targeted at data driven streaming DSP applications that contain a large degree of fine grained parallelism, such as matrix manipulations or filter algorithms. Along with the architecture, also a programming language is presented that can directly describe DSP applications as dataflow graphs which are then automatically mapped and executed on the architecture. In contrast to previously published work on CGRAs, the guiding principle and inspiration for the presented CGRA and its corresponding programming paradigm is the dataflow principle. The result of this work is a completely integrated framework targeted at streaming DSP algorithms, consisting of a CGRA, a programming language and a compiler. The complete system is based on dataflow principles. We conclude that by using an architecture that is based on dataflow principles and a corresponding programming paradigm that can directly express dataflow graphs, DSP algorithms can be implemented in a very intuitive and straightforward manner.},
	Author = {Niedermeier,A.},
	Date = {2014/8/29},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.3990/1.9789036537322},
	Isbn = {978-90-365-3732-2},
	Keywords = {IR-91607; EWI-25011; METIS-304761},
	M3 = {PhD Thesis - Research UT, graduation UT},
	Month = {8},
	N2 = {Data driven streaming applications are quite common in modern multimedia and wireless applications, like for example video and audio processing. The main components of these applications are Digital Signal Processing (DSP) algorithms. These algorithms are not extremely complex in terms of their structure and the operations that make up the algorithms are fairly simple (usually binary mathematical operations like addition and multiplication). What makes it challenging to implement and execute these algorithms efficiently is their large degree of fine-grained parallelism and the required throughput. DSP algorithms can usually be described as dataflow graphs with nodes corresponding to operations and edges between the nodes expressing data dependencies. A node fires, i.e. executes, as soon as all required input data has arrived at its input edge(s). To execute DSP algorithms efficiently while maintaining flexibility, coarse-grained reconfigurable arrays (CGRAs) can be used. CGRAs are composed of a set of small, reconfigurable cores, interconnected in e.g. a two dimensional array. Each core by itself is not very powerful, yet the complete array of cores forms an efficient architecture with a high throughput due to its ability to efficiently execute operations in parallel. In this thesis, we present a CGRA targeted at data driven streaming DSP applications that contain a large degree of fine grained parallelism, such as matrix manipulations or filter algorithms. Along with the architecture, also a programming language is presented that can directly describe DSP applications as dataflow graphs which are then automatically mapped and executed on the architecture. In contrast to previously published work on CGRAs, the guiding principle and inspiration for the presented CGRA and its corresponding programming paradigm is the dataflow principle. The result of this work is a completely integrated framework targeted at streaming DSP algorithms, consisting of a CGRA, a programming language and a compiler. The complete system is based on dataflow principles. We conclude that by using an architecture that is based on dataflow principles and a corresponding programming paradigm that can directly express dataflow graphs, DSP algorithms can be implemented in a very intuitive and straightforward manner.},
	Title = {A fine-grained parallel dataflow-inspired architecture for streaming applications},
	Ty = {THES},
	U2 = {10.3990/1.9789036537322},
	Year = {2014},
	Year1 = {2014/8/29},
	Bdsk-Url-1 = {https://dx.doi.org/10.3990/1.9789036537322}}

@inbook{Smit:2010aa,
	Abstract = {Today the hardware for embedded systems is often specified in VHDL. However, VHDL describes the system at a rather low level, which is cumbersome and may lead to design faults in large real life applications. There is a need of higher level abstraction mechanisms. In the embedded systems group of the University of Twente we are working on systematic and transformational methods to design hardware architectures, both multi core and single core. The main line in this approach is to start with a straightforward (often mathematical) specification of the problem. The next step is to find some adequate transformations on this specification, in particular to find specific optimizations, to be able to distribute the application over different cores. The result of these transformations is then translated into the functional programming language Haskell since Haskell is close to mathematics and such a translation often is straightforward. Besides, the Haskell code is executable, so one immediately has a simulation of the intended system. Next, the resulting Haskell specification is given to a compiler, called C{\"e}aSH (for CAES LAnguage for Synchronous Hardware) which translates the specification into VHDL. The resulting VHDL is synthesizable, so from there on standard VHDL-tooling can be used for synthesis. In this work we primarily focus on streaming applications: i.e. applications that can be modeled as data-flow graphs. At the moment the C{\"e}aSH system is ready in prototype form and in the presentation we will give several examples of how it can be used. In these examples it will be shown that the specification code is clear and concise. Furthermore, it is possible to use powerful abstraction mechanisms, such as polymorphism, higher order functions, pattern matching, lambda abstraction, partial application. These features allow a designer to describe circuits in a more natural and concise way than possible with the language elements found in the traditional hardware description languages. In addition we will give some examples of transformations that are possible in a mathematical specification, and which do not suffer from the problems encountered in, e.g., automatic parallelization of nested for-loops in C-programs.},
	Annote = {eemcs-eprint-19169},
	Author = {Smit,Gerardus Johannes Maria and Kuper,Jan and Baaij,C. P. R.},
	Booktitle = {Dagstuhl Seminar on Dynamically Reconfigurable Architectures},
	Date = {2010/12/14},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.4230/OASIcs.WCET.2010.136},
	Keywords = {IR-75334; METIS-275806; Hardware design; EC Grant Agreement nr.: FP7/248465; Streaming Applications; EWI-19169; mathematical specification},
	M3 = {Conference contribution},
	Month = {12},
	N2 = {Today the hardware for embedded systems is often specified in VHDL. However, VHDL describes the system at a rather low level, which is cumbersome and may lead to design faults in large real life applications. There is a need of higher level abstraction mechanisms. In the embedded systems group of the University of Twente we are working on systematic and transformational methods to design hardware architectures, both multi core and single core. The main line in this approach is to start with a straightforward (often mathematical) specification of the problem. The next step is to find some adequate transformations on this specification, in particular to find specific optimizations, to be able to distribute the application over different cores. The result of these transformations is then translated into the functional programming language Haskell since Haskell is close to mathematics and such a translation often is straightforward. Besides, the Haskell code is executable, so one immediately has a simulation of the intended system. Next, the resulting Haskell specification is given to a compiler, called C{\"e}aSH (for CAES LAnguage for Synchronous Hardware) which translates the specification into VHDL. The resulting VHDL is synthesizable, so from there on standard VHDL-tooling can be used for synthesis. In this work we primarily focus on streaming applications: i.e. applications that can be modeled as data-flow graphs. At the moment the C{\"e}aSH system is ready in prototype form and in the presentation we will give several examples of how it can be used. In these examples it will be shown that the specification code is clear and concise. Furthermore, it is possible to use powerful abstraction mechanisms, such as polymorphism, higher order functions, pattern matching, lambda abstraction, partial application. These features allow a designer to describe circuits in a more natural and concise way than possible with the language elements found in the traditional hardware description languages. In addition we will give some examples of transformations that are possible in a mathematical specification, and which do not suffer from the problems encountered in, e.g., automatic parallelization of nested for-loops in C-programs.},
	Pages = {11},
	Publisher = {Internationales Begegnungs- und Forschungszentrum fur Informatik (IBFI)},
	Title = {A mathematical approach towards hardware design},
	Title1 = {Dagstuhl Seminar Proceedings},
	Ty = {CHAP},
	U2 = {10.4230/OASIcs.WCET.2010.136},
	Year = {2010},
	Year1 = {2010/12/14},
	Bdsk-Url-1 = {https://dx.doi.org/10.4230/OASIcs.WCET.2010.136}}

@article{Wester:2015aa,
	Abstract = {The amount of resources available on reconfigurable logic devices like FPGAs has seen a tremendous growth over the last thirty years. During this period, the amount of programmable resources (CLBs and RAMs) has increased by more than three orders of magnitude. Programming these reconfigurable architectures has been dominated by the hardware description languages VHDL and Verilog. However, it has become generally accepted that these languages do not provide adequate abstraction mechanisms to deliver the design productivity for designing more and more complex applications. To raise the abstraction level, techniques to translate high-level languages to hardware have been developed based on imperative languages like C. Parallelism is achieved by parallelization of for-loops. Whether parallelization of loops is possible, is determined using dependency analysis which is a very hard problem. To mitigate this problem, other abstractions are needed to express parallelism. In this thesis, parallelism is expressed using higher-order functions, an abstraction commonly used in functional programming languages. The main contribution of this thesis is a design methodology based on exploiting regularity of higher-order functions. A mathematical formula, e.g., a DSP algorithm, is first formulated using higher-order functions. Then, transformation rules are applied to these higher-order functions to distribute computations over space and time. Using these transformations, an optimal trade-off can be made between space and time. Finally, hardware is generated using the CLaSH compiler by translating the result of the transformation to VHDL. In this thesis, we derive transformation rules for several higher-order functions and prove that the transformations are meaning-preserving. After transformation, a mathematically equivalent description is derived in which the computations are distributed over space and time. The designer can control the amount of parallelism using a parameter that is introduced by the transformation. Transformation rules for both one-dimensional higher-order functions and two-dimensional higher- order functions have been derived and applied to several case studies: a dot product, a particle filter and stencil computations.},
	Author = {Wester,Rinse},
	Date = {2015/7/3},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.3990/1.9789036538879},
	Isbn = {978-90-365-3887-9},
	Keywords = {Higher-order functions; EWI-26125; IR-96278; METIS-310874; transformations; Hardware design},
	M3 = {PhD Thesis - Research UT, graduation UT},
	Month = {7},
	N2 = {The amount of resources available on reconfigurable logic devices like FPGAs has seen a tremendous growth over the last thirty years. During this period, the amount of programmable resources (CLBs and RAMs) has increased by more than three orders of magnitude. Programming these reconfigurable architectures has been dominated by the hardware description languages VHDL and Verilog. However, it has become generally accepted that these languages do not provide adequate abstraction mechanisms to deliver the design productivity for designing more and more complex applications. To raise the abstraction level, techniques to translate high-level languages to hardware have been developed based on imperative languages like C. Parallelism is achieved by parallelization of for-loops. Whether parallelization of loops is possible, is determined using dependency analysis which is a very hard problem. To mitigate this problem, other abstractions are needed to express parallelism. In this thesis, parallelism is expressed using higher-order functions, an abstraction commonly used in functional programming languages. The main contribution of this thesis is a design methodology based on exploiting regularity of higher-order functions. A mathematical formula, e.g., a DSP algorithm, is first formulated using higher-order functions. Then, transformation rules are applied to these higher-order functions to distribute computations over space and time. Using these transformations, an optimal trade-off can be made between space and time. Finally, hardware is generated using the CLaSH compiler by translating the result of the transformation to VHDL. In this thesis, we derive transformation rules for several higher-order functions and prove that the transformations are meaning-preserving. After transformation, a mathematically equivalent description is derived in which the computations are distributed over space and time. The designer can control the amount of parallelism using a parameter that is introduced by the transformation. Transformation rules for both one-dimensional higher-order functions and two-dimensional higher- order functions have been derived and applied to several case studies: a dot product, a particle filter and stencil computations.},
	Publisher = {Universiteit Twente},
	Title = {A transformation-based approach to hardware design using higher-order functions},
	Ty = {THES},
	U2 = {10.3990/1.9789036538879},
	Year = {2015},
	Year1 = {2015/7/3},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QkS4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL05OLUZpbi9BIERlZXAgTmV1cmFsLU5ldHdvcmsgQmFzZWQgU3RvY2sgVHJhZGluZyBTeXN0ZW0gQmFzZWQgb24gRXZvbHV0aW9uYXJ5IE9wdGltaXplZCBUZWNobmljYWwgQW5hbHlzaXMgUGFyYW1ldGVycy5yaXPSFwsYGVdOUy5kYXRhTxEDCAAAAAADCAACAAAJTWFjaW50b3NoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////H0EgRGVlcCBOZXVyYWwtTmV0dyNGRkZGRkZGRi5yaXMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAAAQAEAAAKIGN1AAAAAAAAAAAAAAAAAAZOTi1GaW4AAgCnLzpVc2VyczpyaHZ0OkRldjpDTk4tUGhkOlJlZmVyZW5jZXM6Q2l0YXRpb25zOk5OLUZpbjpBIERlZXAgTmV1cmFsLU5ldHdvcmsgQmFzZWQgU3RvY2sgVHJhZGluZyBTeXN0ZW0gQmFzZWQgb24gRXZvbHV0aW9uYXJ5IE9wdGltaXplZCBUZWNobmljYWwgQW5hbHlzaXMgUGFyYW1ldGVycy5yaXMAAA4A5gByAEEAIABEAGUAZQBwACAATgBlAHUAcgBhAGwALQBOAGUAdAB3AG8AcgBrACAAQgBhAHMAZQBkACAAUwB0AG8AYwBrACAAVAByAGEAZABpAG4AZwAgAFMAeQBzAHQAZQBtACAAQgBhAHMAZQBkACAAbwBuACAARQB2AG8AbAB1AHQAaQBvAG4AYQByAHkAIABPAHAAdABpAG0AaQB6AGUAZAAgAFQAZQBjAGgAbgBpAGMAYQBsACAAQQBuAGEAbAB5AHMAaQBzACAAUABhAHIAYQBtAGUAdABlAHIAcwAuAHIAaQBzAA8AFAAJAE0AYQBjAGkAbgB0AG8AcwBoABIApVVzZXJzL3JodnQvRGV2L0NOTi1QaGQvUmVmZXJlbmNlcy9DaXRhdGlvbnMvTk4tRmluL0EgRGVlcCBOZXVyYWwtTmV0d29yayBCYXNlZCBTdG9jayBUcmFkaW5nIFN5c3RlbSBCYXNlZCBvbiBFdm9sdXRpb25hcnkgT3B0aW1pemVkIFRlY2huaWNhbCBBbmFseXNpcyBQYXJhbWV0ZXJzLnJpcwAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgEiAScBLwQ7BD0EQgRNBFYEZARoBG8EeAR9BIoEjQSfBKIEpwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAASp},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8Qfi4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL05OLUZpbi9BZGFwdGl2ZSBOZXVybyBGdXp6eSBJbmZlcmVuY2UgU3lzdGVtcyBmb3IgSGlnaCBGcmVxdWVuY3kgRmluYW5jaWFsIFRyYWRpbmcgYW5kIEZvcmVjYXN0aW5nLnJpc9IXCxgZV05TLmRhdGFPEQK6AAAAAAK6AAIAAAlNYWNpbnRvc2gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8fQWRhcHRpdmUgTmV1cm8gRnV6I0ZGRkZGRkZGLnJpcwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAABAAQAAAogY3UAAAAAAAAAAAAAAAAABk5OLUZpbgACAJQvOlVzZXJzOnJodnQ6RGV2OkNOTi1QaGQ6UmVmZXJlbmNlczpDaXRhdGlvbnM6Tk4tRmluOkFkYXB0aXZlIE5ldXJvIEZ1enp5IEluZmVyZW5jZSBTeXN0ZW1zIGZvciBIaWdoIEZyZXF1ZW5jeSBGaW5hbmNpYWwgVHJhZGluZyBhbmQgRm9yZWNhc3RpbmcucmlzAA4AwABfAEEAZABhAHAAdABpAHYAZQAgAE4AZQB1AHIAbwAgAEYAdQB6AHoAeQAgAEkAbgBmAGUAcgBlAG4AYwBlACAAUwB5AHMAdABlAG0AcwAgAGYAbwByACAASABpAGcAaAAgAEYAcgBlAHEAdQBlAG4AYwB5ACAARgBpAG4AYQBuAGMAaQBhAGwAIABUAHIAYQBkAGkAbgBnACAAYQBuAGQAIABGAG8AcgBlAGMAYQBzAHQAaQBuAGcALgByAGkAcwAPABQACQBNAGEAYwBpAG4AdABvAHMAaAASAJJVc2Vycy9yaHZ0L0Rldi9DTk4tUGhkL1JlZmVyZW5jZXMvQ2l0YXRpb25zL05OLUZpbi9BZGFwdGl2ZSBOZXVybyBGdXp6eSBJbmZlcmVuY2UgU3lzdGVtcyBmb3IgSGlnaCBGcmVxdWVuY3kgRmluYW5jaWFsIFRyYWRpbmcgYW5kIEZvcmVjYXN0aW5nLnJpcwATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAQ8BFAEcA9oD3APhA+wD9QQDBAcEDgQXBBwEKQQsBD4EQQRGAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAABEg=},
	Bdsk-File-3 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QWi4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL05OLUZpbi9Vc2luZyBSZWN1cnJlbnQgTmV1cmFsIE5ldHdvcmtzIFRvIEZvcmVjYXN0aW5nIG9mIEZvcmV4LmJpYtIXCxgZV05TLmRhdGFPEQIqAAAAAAIqAAIAAAlNYWNpbnRvc2gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8fVXNpbmcgUmVjdXJyZW50IE5lI0ZGRkZGRkZGLmJpYgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAABAAQAAAogY3UAAAAAAAAAAAAAAAAABk5OLUZpbgACAHAvOlVzZXJzOnJodnQ6RGV2OkNOTi1QaGQ6UmVmZXJlbmNlczpDaXRhdGlvbnM6Tk4tRmluOlVzaW5nIFJlY3VycmVudCBOZXVyYWwgTmV0d29ya3MgVG8gRm9yZWNhc3Rpbmcgb2YgRm9yZXguYmliAA4AeAA7AFUAcwBpAG4AZwAgAFIAZQBjAHUAcgByAGUAbgB0ACAATgBlAHUAcgBhAGwAIABOAGUAdAB3AG8AcgBrAHMAIABUAG8AIABGAG8AcgBlAGMAYQBzAHQAaQBuAGcAIABvAGYAIABGAG8AcgBlAHgALgBiAGkAYgAPABQACQBNAGEAYwBpAG4AdABvAHMAaAASAG5Vc2Vycy9yaHZ0L0Rldi9DTk4tUGhkL1JlZmVyZW5jZXMvQ2l0YXRpb25zL05OLUZpbi9Vc2luZyBSZWN1cnJlbnQgTmV1cmFsIE5ldHdvcmtzIFRvIEZvcmVjYXN0aW5nIG9mIEZvcmV4LmJpYgATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAOsA8AD4AyYDKAMtAzgDQQNPA1MDWgNjA2gDdQN4A4oDjQOSAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA5Q=},
	Bdsk-Url-1 = {https://dx.doi.org/10.3990/1.9789036538879}}

@inproceedings{Wester:2012aa,
	Author = {R. Wester and C. Baaij and J. Kuper},
	Booktitle = {22nd International Conference on Field Programmable Logic and Applications (FPL)},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/FPL.2012.6339258},
	Isbn = {1946-147X},
	Journal = {22nd International Conference on Field Programmable Logic and Applications (FPL)},
	Journal1 = {22nd International Conference on Field Programmable Logic and Applications (FPL)},
	Keywords = {field programmable gate arrays; functional languages; hardware description languages; logic design; mathematical analysis; particle filtering (numerical methods); program compilers; C\&{\#}x03BB;aSH HDL; DSP application; FPGA; Haskell; adequate abstraction mechanisms; functional hardware description language; higher level abstraction mechanism; higher-order function; mathematical definition; particle filtering; polymorphism; two step hardware design method; Atmospheric measurements; Design methodology; Equations; Hardware; Mathematical model; Particle measurements; Systematics},
	Pages = {181--188},
	Title = {A two step hardware design method using C\&{\#}x03BB;aSH},
	Ty = {CONF},
	Year = {2012},
	Year1 = {29-31 Aug. 2012},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/FPL.2012.6339258}}

@inbook{5ecc1e5c8c7644a9bf1ff0c60033d5faB,
	Abstract = {Functional hardware description languages are a class of hardware description languages that emphasize on the ability to express higher level structural properties, such a parameterization and regularity. Due to such features as higher-order functions and polymorphism, parameterization in functional hardware description languages is more natural than the parameterization support found in the more traditional hardware description languages, like VHDL and Verilog. We de- velop a new functional hardware description language, CasH, that borrows both the syntax and semantics from the general-purpose functional programming language Haskell.},
	Author = {C.P.R. Baaij},
	Booktitle = {ClasH - From Haskell To Hardware},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Keywords = {Haskell, CLaSH},
	Month = {12},
	Pages = {101},
	Publisher = {University of Twente},
	Title = {ClasH - From Haskell To Hardware},
	Year = {2009}}

@misc{essay70777,
	Abstract = {ClaSH is a functional hardware description language (HDL) developed at the CAES
group of the University of Twente. ClaSH borrows both the syntax and semantics from the general-purpose functional programming language Haskell, meaning that circuit designers can define their circuits with regular Haskell syntax.

In this thesis, research is done on the co-simulation of ClaSH and traditional HDLs. The Verilog Procedural Interface (VPI), as defined in the IEEE 1364 standard, is used to set-up the communication and to control a Verilog simulator. An implementation is made, as will be described in this thesis, to show the practical feasibility of co-simulation of ClaSH and Verilog.},
	Author = {J.G.J. {Verheij}},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Keywords = {CLaSH, Haskell, Simulation, HDL},
	Month = {August},
	Title = {Co-simulation between C$\lambda$aSH and traditional HDLs},
	Url = {http://essay.utwente.nl/70777/},
	Year = {2016},
	Bdsk-Url-1 = {http://essay.utwente.nl/70777/}}

@inbook{5ecc1e5c8c7644a9bf1ff0c60033d5fa,
	Abstract = {As embedded systems are becoming increasingly complex, the design process and verification have become very time-consuming. Additionally, specifying hardware manually in a low-level hardware description language like VHDL is usually an error-prone task. In our group, a tool (the ClaSH compiler) was developed to generate fully synthesisable VHDL code from a specification given in the functional programming language Haskell. In this paper, we present a comparison between two implementations of the same design by using ClaSH and hand-written VHDL. The design is a simple dataflow processor. As measures of interest area, performance, power consumption and source lines of code (SLOC) are used. The obtained results indicate that the ClaSH -generated VHDL code as well as the netlist after synthesis and place and route are functionally correct. The placed and routed hand-written VHDL code has also the correct behaviour. Furthermore, a similar performance is achieved. The power consumption is even lower for the ClaSH implementation. The SLOC for ClaSH is considerably smaller and it is possible to specify the design in a much higher level of abstraction compared to VHDL.},
	Author = {A. Niedermeier and Rinse Wester and Rinse Wester and C.P.R. Baaij and Jan Kuper and Smit, {Gerardus Johannes Maria}},
	Booktitle = {Proceedings of the Workshop on PROGram for Research on Embedded Systems and Software (PROGRESS 2010)},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Isbn = {978-90-73461-67-3},
	Keywords = {METIS-277454, IR-75095, EWI-18902},
	Month = {11},
	Pages = {216--221},
	Publisher = {Technology Foundation (STW)},
	Title = {Comparing CaSH and VHDL by implementing a dataflow processor},
	Year = {2010}}

@inproceedings{6339201,
	Author = {B. N. Uchevler and K. Svarstad},
	Booktitle = {22nd International Conference on Field Programmable Logic and Applications (FPL)},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/FPL.2012.6339201},
	Issn = {1946-147X},
	Keywords = {circuit complexity;functional languages;hardware description languages;high level synthesis;program compilers;program verification;reconfigurable architectures;CLaSH;RT level VHDL;digital circuit description;digital circuit verification;dynamic reconfigurable system modeling;electronic design complexity;formal verification;functional HDL;high-level Haskell description translation;higher-order functions;parametrization;partial evaluation technique;polymorphism;run-time reconfigurable systems;synthesis tool chain;Communications technology;Consumer electronics;Educational institutions;Field programmable gate arrays;Hardware;Mathematical model;Unified modeling language},
	Month = {Aug},
	Pages = {481-482},
	Title = {Modeling of dynamic reconfigurable systems with Haskell},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QZy4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL0ZQR0EvQSBQeXRob25pYyBBcHByb2FjaCBmb3IgUmFwaWQgSGFyZHdhcmUgUHJvdG90eXBpbmcgYW5kIEluc3RydW1lbnRhdGlvbi5iaWLSFwsYGVdOUy5kYXRhTxECYgAAAAACYgACAAAJTWFjaW50b3NoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////H0EgUHl0aG9uaWMgQXBwcm9hYyNGRkZGRkZGRi5iaWIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAAAQAEAAAKIGN1AAAAAAAAAAAAAAAAAARGUEdBAAIAfS86VXNlcnM6cmh2dDpEZXY6Q05OLVBoZDpSZWZlcmVuY2VzOkNpdGF0aW9uczpGUEdBOkEgUHl0aG9uaWMgQXBwcm9hY2ggZm9yIFJhcGlkIEhhcmR3YXJlIFByb3RvdHlwaW5nIGFuZCBJbnN0cnVtZW50YXRpb24uYmliAAAOAJYASgBBACAAUAB5AHQAaABvAG4AaQBjACAAQQBwAHAAcgBvAGEAYwBoACAAZgBvAHIAIABSAGEAcABpAGQAIABIAGEAcgBkAHcAYQByAGUAIABQAHIAbwB0AG8AdAB5AHAAaQBuAGcAIABhAG4AZAAgAEkAbgBzAHQAcgB1AG0AZQBuAHQAYQB0AGkAbwBuAC4AYgBpAGIADwAUAAkATQBhAGMAaQBuAHQAbwBzAGgAEgB7VXNlcnMvcmh2dC9EZXYvQ05OLVBoZC9SZWZlcmVuY2VzL0NpdGF0aW9ucy9GUEdBL0EgUHl0aG9uaWMgQXBwcm9hY2ggZm9yIFJhcGlkIEhhcmR3YXJlIFByb3RvdHlwaW5nIGFuZCBJbnN0cnVtZW50YXRpb24uYmliAAATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAPgA/QEFA2sDbQNyA30DhgOUA5gDnwOoA60DugO9A88D0gPXAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA9k=},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/FPL.2012.6339201}}

@inbook{fff28539e56047c4adca5cc3c9c29cec,
	Abstract = {CaSH, a functional hardware description language based on Haskell, has several abstraction mechanisms that allow a hardware designer to describe architectures in a short and concise way. In this paper we evaluate CaSH on a complex DSP application, a Polyphase Filter Bank as it is used in the ASTRON APERTIF project. The Polyphase Filter Bank is implemented in two steps: first in Haskell as being close to a standard mathematical specification, then in CaSH which is derived from the Haskell formulation by applying only minor changes. We show that the CaSH formulation can be directly mapped to hardware, thus exploiting the parallelism and concurrency that is present in the original mathematical specification.},
	Author = {Rinse Wester and Dimitrios Sarakiotis and Eric Kooistra and Jan Kuper},
	Booktitle = {Communicating Process Architectures 2012},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Isbn = {978-0-9565409-5-9},
	Keywords = {EWI-22586, EC Grant Agreement nr.: FP7/248465, Specification, METIS-289800, APERTIF Project, CaSH, IR-82307},
	Month = {8},
	Note = {eemcs-eprint-22586},
	Pages = {53--64},
	Publisher = {Open Channel Publishing},
	Title = {Specification of APERTIF Polyphase Filter Bank in CaSH},
	Year = {2012}}

@inproceedings{6523639,
	Author = {B. N. Uchevler and K. Svarstad and J. Kuper and C. Baaij},
	Booktitle = {International Symposium on Quality Electronic Design (ISQED)},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/ISQED.2013.6523639},
	Issn = {1948-3287},
	Keywords = {field programmable gate arrays;hardware description languages;logic design;CLaSH;FPGA design;RT level;Suzaku-sz410 board;digital circuit verification;dynamic reconfigurable designs;formal verification;functional HDL;functional programming abstractions;high-level Haskell descriptions;high-level descriptions;high-level structures;higher-order functions;partial evaluation implementation technique;run-time reconfigurable systems;synthesizable VHDL;system-level modelling;Consumer electronics;Digital signal processing;Field programmable gate arrays;Finite impulse response filters;Hardware;Software;Unified modeling language;Functional HDL;Partial Evaluation;Run-Time Reconfiguration;Self-Reconfiguration},
	Month = {March},
	Pages = {379-385},
	Title = {System-level modelling of dynamic reconfigurable designs using functional programming abstractions},
	Year = {2013},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/ISQED.2013.6523639}}

@inproceedings{Oancea:2012:FSG:2364474.2364484,
	Acmid = {2364484},
	Address = {New York, NY, USA},
	Author = {Oancea, Cosmin E. and Andreetta, Christian and Berthold, Jost and Frisch, Alain and Henglein, Fritz},
	Booktitle = {Proceedings of the 1st ACM SIGPLAN Workshop on Functional High-performance Computing},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1145/2364474.2364484},
	Isbn = {978-1-4503-1577-7},
	Keywords = {autoparallelization, functional language, memory coalescing, strength reduction, tiling},
	Location = {Copenhagen, Denmark},
	Numpages = {12},
	Pages = {61--72},
	Publisher = {ACM},
	Series = {FHPC '12},
	Title = {Financial Software on GPUs: Between Haskell and Fortran},
	Url = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/2364474.2364484},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/2364474.2364484},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/2364474.2364484}}

@inproceedings{Funie:2014aa,
	Author = {A. I. Funie and M. Salmon and W. Luk},
	Booktitle = {2014 13th International Conference on Machine Learning and Applications},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/ICMLA.2014.11},
	Journal = {2014 13th International Conference on Machine Learning and Applications},
	Journal1 = {2014 13th International Conference on Machine Learning and Applications},
	Keywords = {economics; field programmable gate arrays; foreign exchange trading; genetic algorithms; particle swarm optimisation; economic value; field programmable gate array technology; financial markets; foreign exchange market data; genetic programming; high frequency trading strategies; hybrid evolutionary algorithm; monitor market stability; particle swarm optimisation; Algorithm design and analysis; Genetics; Noise; Prediction algorithms; Sociology; Statistics; Testing},
	Pages = {29--34},
	Title = {A Hybrid Genetic-Programming Swarm-Optimisation Approach for Examining the Nature and Stability of High Frequency Trading Strategies},
	Ty = {CONF},
	Year = {2014},
	Year1 = {3-6 Dec. 2014},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/ICMLA.2014.11}}

@inproceedings{Lockwood:2012aa,
	Author = {J. W. Lockwood and A. Gupte and N. Mehta and M. Blott and T. English and K. Vissers},
	Booktitle = {2012 IEEE 20th Annual Symposium on High-Performance Interconnects},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/HOTI.2012.15},
	Isbn = {1550-4794},
	Journal = {2012 IEEE 20th Annual Symposium on High-Performance Interconnects},
	Journal1 = {2012 IEEE 20th Annual Symposium on High-Performance Interconnects},
	Keywords = {IP networks; electronic engineering computing; electronic trading; field programmable gate arrays; local area networks; memory protocols; microprocessor chips; network interfaces; Ethernet line rate; FPGA IP library; FPGA hardware; HFT platform; I-O interface; alternative hybrid architecture; bit rate 10 Gbit/s; computers software; custom 1U FPGA appliance; electronic trading; financial protocol parser; fixed end-to-end latency; hardware acceleration; high-frequency trading platform; high-performance network adapter; low-latency library; memory interface; pre-built infrastructure; software implementation; time 1 mus; Field programmable gate arrays; Hardware; IP networks; Libraries; Protocols; Registers; Software; Algorithmic; FPGA; HFT; latency; trading},
	Pages = {9--16},
	Title = {A Low-Latency Library in FPGA Hardware for High-Frequency Trading (HFT)},
	Ty = {CONF},
	Year = {2012},
	Year1 = {22-24 Aug. 2012},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/HOTI.2012.15}}

@inproceedings{Zoican:2016aa,
	Author = {S. Zoican and M. Vochin},
	Booktitle = {2016 International Conference on Communications (COMM)},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/ICComm.2016.7528289},
	Journal = {2016 International Conference on Communications (COMM)},
	Journal1 = {2016 International Conference on Communications (COMM)},
	Keywords = {financial data processing; computing system; financial market literature; high frequency trading applications; high frequency trading financial applications; high processing speed; high-frequency traders; low latency technology; low network latency; medium cost technology; network architectures; optimal trading speed; Bandwidth; Computer architecture; Computers; Graphics processing units; Instruction sets; Parallel processing; Servers; computer unified device architecture; high frequency trading algorithms; network latency},
	Pages = {139--144},
	Title = {Computing system and network architectures in high frequency trading financial applications},
	Ty = {CONF},
	Year = {2016},
	Year1 = {9-10 June 2016},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/ICComm.2016.7528289}}

@inproceedings{Litz:2011:DPE:2088256.2088268,
	Acmid = {2088268},
	Address = {New York, NY, USA},
	Author = {Litz, Heiner and Leber, Christian and Geib, Benjamin},
	Booktitle = {Proceedings of the Fourth Workshop on High Performance Computational Finance},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1145/2088256.2088268},
	Isbn = {978-1-4503-1108-3},
	Keywords = {DSL, FAST, FIX, FPGA, decoder, domain specific language, high throughput, low latency, stock, trading},
	Location = {Seattle, Washington, USA},
	Numpages = {8},
	Pages = {31--38},
	Publisher = {ACM},
	Series = {WHPCF '11},
	Title = {DSL Programmable Engine for High Frequency Trading Acceleration},
	Url = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/2088256.2088268},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/2088256.2088268},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/2088256.2088268}}

@inproceedings{Woods:2008aa,
	Author = {N. A. Woods and T. VanCourt},
	Booktitle = {2008 International Conference on Field Programmable Logic and Applications},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/FPL.2008.4629954},
	Isbn = {1946-147X},
	Journal = {2008 International Conference on Field Programmable Logic and Applications},
	Journal1 = {2008 International Conference on Field Programmable Logic and Applications},
	Keywords = {Monte Carlo methods; field programmable gate arrays; financial data processing; FPGA acceleration; finance; multicore processor; pricing simulations; quasiMonte Carlo methods; Acceleration; Computational modeling; Field programmable gate arrays; Finance; Monte Carlo methods; Multicore processing; Pricing; Runtime; Security; Yield estimation},
	Pages = {335--340},
	Title = {FPGA acceleration of quasi-Monte Carlo in finance},
	Ty = {CONF},
	Year = {2008},
	Year1 = {8-10 Sept. 2008},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/FPL.2008.4629954}}

@article{Tian:2010:HQC:1862648.1862656,
	Acmid = {1862656},
	Address = {New York, NY, USA},
	Articleno = {26},
	Author = {Tian, Xiang and Benkrid, Khaled},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1145/1862648.1862656},
	Issn = {1936-7406},
	Issue_Date = {November 2010},
	Journal = {ACM Trans. Reconfigurable Technol. Syst.},
	Keywords = {CPU, FPGA, GPU, Maxwell, Quasi-Monte Carlo simulations, option pricing},
	Month = nov,
	Number = {4},
	Numpages = {22},
	Pages = {26:1--26:22},
	Publisher = {ACM},
	Title = {High-Performance Quasi-Monte Carlo Financial Simulation: FPGA vs. GPP vs. GPU},
	Url = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/1862648.1862656},
	Volume = {3},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/1862648.1862656},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/1862648.1862656}}

@inproceedings{Dvorak:2014aa,
	Author = {M. Dvo{\v r}{\'a}k and J. Ko{\v r}enek},
	Booktitle = {17th International Symposium on Design and Diagnostics of Electronic Circuits \& Systems},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/DDECS.2014.6868785},
	Journal = {17th International Symposium on Design and Diagnostics of Electronic Circuits \& Systems},
	Journal1 = {17th International Symposium on Design and Diagnostics of Electronic Circuits \& Systems},
	Keywords = {electronic trading; field programmable gate arrays; logic design; FPGA; QDR SRAM; algorithmic trading; best bid price; best offer price; financial instrument; hardware architecture; hardware market state; high frequency trading; lookup latency-memory utilization trade-off; low latency book handling; low latency trading system; market data processing; storage capacity 144 Mbit; Algorithm design and analysis; Feeds; Field programmable gate arrays; Hardware; Instruments; Memory management},
	Pages = {175--178},
	Title = {Low latency book handling in FPGA for high frequency trading},
	Ty = {CONF},
	Year = {2014},
	Year1 = {23-25 April 2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QXy4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL05OL0VxdWlsaWJyYXRlZCBhZGFwdGl2ZSBsZWFybmluZyByYXRlcyBmb3Igbm9uLWNvbnZleCBvcHRpbWl6YXRpb24uYmli0hcLGBlXTlMuZGF0YU8RAkQAAAAAAkQAAgAACU1hY2ludG9zaAAAAAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x9FcXVpbGlicmF0ZWQgYWRhcHQjRkZGRkZGRkYuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEABAAACiBjdQAAAAAAAAAAAAAAAAACTk4AAgB1LzpVc2VyczpyaHZ0OkRldjpDTk4tUGhkOlJlZmVyZW5jZXM6Q2l0YXRpb25zOk5OOkVxdWlsaWJyYXRlZCBhZGFwdGl2ZSBsZWFybmluZyByYXRlcyBmb3Igbm9uLWNvbnZleCBvcHRpbWl6YXRpb24uYmliAAAOAIoARABFAHEAdQBpAGwAaQBiAHIAYQB0AGUAZAAgAGEAZABhAHAAdABpAHYAZQAgAGwAZQBhAHIAbgBpAG4AZwAgAHIAYQB0AGUAcwAgAGYAbwByACAAbgBvAG4ALQBjAG8AbgB2AGUAeAAgAG8AcAB0AGkAbQBpAHoAYQB0AGkAbwBuAC4AYgBpAGIADwAUAAkATQBhAGMAaQBuAHQAbwBzAGgAEgBzVXNlcnMvcmh2dC9EZXYvQ05OLVBoZC9SZWZlcmVuY2VzL0NpdGF0aW9ucy9OTi9FcXVpbGlicmF0ZWQgYWRhcHRpdmUgbGVhcm5pbmcgcmF0ZXMgZm9yIG5vbi1jb252ZXggb3B0aW1pemF0aW9uLmJpYgAAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDwAPUA/QNFA0cDTANXA2ADbgNyA3kDggOHA5QDlwOpA6wDsQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAOz},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/DDECS.2014.6868785}}

@article{Thomas:2013aa,
	Author = {D. B. Thomas and W. Luk},
	Booktitle = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/TVLSI.2012.2228017},
	Isbn = {1063-8210},
	Journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
	Journal1 = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
	Keywords = {Gaussian distribution; adders; field programmable gate arrays; graphics processing units; random number generation; shift registers; table lookup; Virtex-5 FPGA; adders; block-memory resources; field-programmable gate array; frequency 1.2 GHz; frequency 400 MHz; graphics processing unit; independent Gaussian samples; logic resources; lookup-tables; multiplierless algorithm; multivariate Gaussian distribution; multivariate Gaussian vectors; multivariate generator; numerical simulation; pair-wise correlations; random number generation; read-only memories; registers; scalar Gaussian generator; uniform distribution; Covariance matrix; Field programmable gate arrays; Generators; Matrix decomposition; Standards; Table lookup; Vectors; Field-programmable gate array (FPGA); Monte Carlo simulation; multivariate samples; random number generation},
	Number = {12},
	Pages = {2193--2205},
	Title = {Multiplierless Algorithm for Multivariate Gaussian Random Number Generation in FPGAs},
	Ty = {JOUR},
	Vo = {21},
	Volume = {21},
	Year = {2013},
	Year1 = {Dec. 2013},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVLSI.2012.2228017}}

@article{2017arXiv171105860H-2,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171105860H},
	Archiveprefix = {arXiv},
	Author = {{Hao}, Y.},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Eprint = {1711.05860},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Hardware Architecture, Computer Science - Neural and Evolutionary Computing},
	Month = nov,
	Primaryclass = {cs.CV},
	Title = {{A General Neural Network Hardware Architecture on FPGA}},
	Year = 2017}

@article{2017arXiv170206392L,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170206392L},
	Archiveprefix = {arXiv},
	Author = {{Li}, Y. and {Liu}, Z. and {Xu}, K. and {Yu}, H. and {Ren}, F.},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Eprint = {1702.06392},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Hardware Architecture, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, C.3},
	Month = feb,
	Primaryclass = {cs.DC},
	Title = {{A GPU-Outperforming FPGA Accelerator Architecture for Binary Convolutional Neural Networks}},
	Year = 2017}

@article{2017arXiv170808917D,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170808917D},
	Archiveprefix = {arXiv},
	Author = {{Ding}, C. and {Liao}, S. and {Wang}, Y. and {Li}, Z. and {Liu}, N. and {Zhuo}, Y. and {Wang}, C. and {Qian}, X. and {Bai}, Y. and {Yuan}, G. and {Ma}, X. and {Zhang}, Y. and {Tang}, J. and {Qiu}, Q. and {Lin}, X. and {Yuan}, B.},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Eprint = {1708.08917},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Computer Vision and Pattern Recognition, Artificial Intelligence, Computer Science - Learning, Statistics - Machine Learning},
	Month = aug,
	Primaryclass = {cs.CV},
	Title = {{CirCNN: Accelerating and Compressing Deep Neural Networks Using Block-CirculantWeight Matrices}},
	Year = 2017}

@inproceedings{Zhao:2016aa,
	Author = {Wenlai Zhao and Haohuan Fu and W. Luk and Teng Yu and Shaojun Wang and Bo Feng and Yuchun Ma and Guangwen Yang},
	Booktitle = {2016 IEEE 27th International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/ASAP.2016.7760779},
	Journal = {2016 IEEE 27th International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
	Journal1 = {2016 IEEE 27th International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
	Keywords = {field programmable gate arrays; floating point arithmetic; neural nets; 32-bit floating-point arithmetic; FPGA-based framework; bandwidth resources; convolutional neural networks; hardware resources; streaming datapath; Bandwidth; Computational modeling; Convolution; Field programmable gate arrays; Neural networks; Runtime; Training},
	Pages = {107--114},
	Title = {F-CNN: An FPGA-based framework for training Convolutional Neural Networks},
	Ty = {CONF},
	Year = {2016},
	Year1 = {6-8 July 2016},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QVi4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL0ZQR0EvQWNjZWxlcmF0aW5nIExhcmdlLVNjYWxlIEhQQyBBcHBsaWNhdGlvbnMgVXNpbmcgRlBHQXMucmlz0hcLGBlXTlMuZGF0YU8RAhwAAAAAAhwAAgAACU1hY2ludG9zaAAAAAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x9BY2NlbGVyYXRpbmcgTGFyZ2UjRkZGRkZGRkYucmlzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEABAAACiBjdQAAAAAAAAAAAAAAAAAERlBHQQACAGwvOlVzZXJzOnJodnQ6RGV2OkNOTi1QaGQ6UmVmZXJlbmNlczpDaXRhdGlvbnM6RlBHQTpBY2NlbGVyYXRpbmcgTGFyZ2UtU2NhbGUgSFBDIEFwcGxpY2F0aW9ucyBVc2luZyBGUEdBcy5yaXMADgB0ADkAQQBjAGMAZQBsAGUAcgBhAHQAaQBuAGcAIABMAGEAcgBnAGUALQBTAGMAYQBsAGUAIABIAFAAQwAgAEEAcABwAGwAaQBjAGEAdABpAG8AbgBzACAAVQBzAGkAbgBnACAARgBQAEcAQQBzAC4AcgBpAHMADwAUAAkATQBhAGMAaQBuAHQAbwBzAGgAEgBqVXNlcnMvcmh2dC9EZXYvQ05OLVBoZC9SZWZlcmVuY2VzL0NpdGF0aW9ucy9GUEdBL0FjY2VsZXJhdGluZyBMYXJnZS1TY2FsZSBIUEMgQXBwbGljYXRpb25zIFVzaW5nIEZQR0FzLnJpcwATAAEvAAAVAAIAC///AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAOcA7AD0AxQDFgMbAyYDLwM9A0EDSANRA1YDYwNmA3gDewOAAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA4I=},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/ASAP.2016.7760779}}

@inproceedings{Abdelouahab:2017:WTH:3131885.3131937,
	Acmid = {3131937},
	Address = {New York, NY, USA},
	Author = {Abdelouahab, Kamel and Pelcat, Maxime and Berry, Francois},
	Booktitle = {Proceedings of the 11th International Conference on Distributed Smart Cameras},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1145/3131885.3131937},
	Isbn = {978-1-4503-5487-5},
	Keywords = {FPGA, TanH, Harware, Acceleration},
	Location = {Stanford, CA, USA},
	Numpages = {3},
	Pages = {199--201},
	Publisher = {ACM},
	Series = {ICDSC 2017},
	Title = {Why TanH is a Hardware Friendly Activation Function for CNNs},
	Url = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/3131885.3131937},
	Year = {2017},
	Bdsk-Url-1 = {http://doi.acm.org.ezproxy.auckland.ac.nz/10.1145/3131885.3131937},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/3131885.3131937}}

@article{2017arXiv170304691B,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170304691B},
	Archiveprefix = {arXiv},
	Author = {{Borovykh}, A. and {Bohte}, S. and {Oosterlee}, C.~W.},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Eprint = {1703.04691},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning},
	Month = mar,
	Primaryclass = {stat.ML},
	Title = {{Conditional Time Series Forecasting with Convolutional Neural Networks}},
	Year = 2017,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QdC4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL0NOTi1GUEdBL09wdGltaXppbmcgRlBHQS1iYXNlZCBBY2NlbGVyYXRvciBEZXNpZ24gZm9yIERlZXAgQ29udm9sdXRpb25hbCBOZXVyYWwgTmV0d29ya3MuYmli0hcLGBlXTlMuZGF0YU8RApAAAAAAApAAAgAACU1hY2ludG9zaAAAAAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x9PcHRpbWl6aW5nIEZQR0EtYmEjRkZGRkZGRkYuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEABAAACiBjdQAAAAAAAAAAAAAAAAAIQ05OLUZQR0EAAgCKLzpVc2VyczpyaHZ0OkRldjpDTk4tUGhkOlJlZmVyZW5jZXM6Q2l0YXRpb25zOkNOTi1GUEdBOk9wdGltaXppbmcgRlBHQS1iYXNlZCBBY2NlbGVyYXRvciBEZXNpZ24gZm9yIERlZXAgQ29udm9sdXRpb25hbCBOZXVyYWwgTmV0d29ya3MuYmliAA4AqABTAE8AcAB0AGkAbQBpAHoAaQBuAGcAIABGAFAARwBBAC0AYgBhAHMAZQBkACAAQQBjAGMAZQBsAGUAcgBhAHQAbwByACAARABlAHMAaQBnAG4AIABmAG8AcgAgAEQAZQBlAHAAIABDAG8AbgB2AG8AbAB1AHQAaQBvAG4AYQBsACAATgBlAHUAcgBhAGwAIABOAGUAdAB3AG8AcgBrAHMALgBiAGkAYgAPABQACQBNAGEAYwBpAG4AdABvAHMAaAASAIhVc2Vycy9yaHZ0L0Rldi9DTk4tUGhkL1JlZmVyZW5jZXMvQ2l0YXRpb25zL0NOTi1GUEdBL09wdGltaXppbmcgRlBHQS1iYXNlZCBBY2NlbGVyYXRvciBEZXNpZ24gZm9yIERlZXAgQ29udm9sdXRpb25hbCBOZXVyYWwgTmV0d29ya3MuYmliABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4BBQEKARIDpgOoA60DuAPBA88D0wPaA+MD6AP1A/gECgQNBBIAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAEFA==},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8Qei4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL0NOTi1GUEdBL1BpcGVDTk4tIEFuIE9wZW5DTC1CYXNlZCBPcGVuLVNvdXJjZSBGUEdBIEFjY2VsZXJhdG9yIGZvciBDb252b2x1dGlvbiBOZXVyYWwgTmV0d29ya3MuYmli0hcLGBlXTlMuZGF0YU8RAqgAAAAAAqgAAgAACU1hY2ludG9zaAAAAAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x9QaXBlQ05OLSBBbiBPcGVuQ0wjRkZGRkZGRkYuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEABAAACiBjdQAAAAAAAAAAAAAAAAAIQ05OLUZQR0EAAgCQLzpVc2VyczpyaHZ0OkRldjpDTk4tUGhkOlJlZmVyZW5jZXM6Q2l0YXRpb25zOkNOTi1GUEdBOlBpcGVDTk4tIEFuIE9wZW5DTC1CYXNlZCBPcGVuLVNvdXJjZSBGUEdBIEFjY2VsZXJhdG9yIGZvciBDb252b2x1dGlvbiBOZXVyYWwgTmV0d29ya3MuYmliAA4AtABZAFAAaQBwAGUAQwBOAE4ALQAgAEEAbgAgAE8AcABlAG4AQwBMAC0AQgBhAHMAZQBkACAATwBwAGUAbgAtAFMAbwB1AHIAYwBlACAARgBQAEcAQQAgAEEAYwBjAGUAbABlAHIAYQB0AG8AcgAgAGYAbwByACAAQwBvAG4AdgBvAGwAdQB0AGkAbwBuACAATgBlAHUAcgBhAGwAIABOAGUAdAB3AG8AcgBrAHMALgBiAGkAYgAPABQACQBNAGEAYwBpAG4AdABvAHMAaAASAI5Vc2Vycy9yaHZ0L0Rldi9DTk4tUGhkL1JlZmVyZW5jZXMvQ2l0YXRpb25zL0NOTi1GUEdBL1BpcGVDTk4tIEFuIE9wZW5DTC1CYXNlZCBPcGVuLVNvdXJjZSBGUEdBIEFjY2VsZXJhdG9yIGZvciBDb252b2x1dGlvbiBOZXVyYWwgTmV0d29ya3MuYmliABMAAS8AABUAAgAL//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4BCwEQARgDxAPGA8sD1gPfA+0D8QP4BAEEBgQTBBYEKAQrBDAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAEMg==}}

@inproceedings{Ding:2015:DLE:2832415.2832572,
	Acmid = {2832572},
	Author = {Ding, Xiao and Zhang, Yue and Liu, Ting and Duan, Junwen},
	Booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Isbn = {978-1-57735-738-4},
	Keywords = {Deep learning, CNN, NN, S&P},
	Location = {Buenos Aires, Argentina},
	Numpages = {7},
	Pages = {2327--2333},
	Publisher = {AAAI Press},
	Series = {IJCAI'15},
	Title = {Deep Learning for Event-driven Stock Prediction},
	Url = {http://dl.acm.org/citation.cfm?id=2832415.2832572},
	Year = {2015},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2832415.2832572}}

@inproceedings{Chen:2016aa,
	Author = {J. F. Chen and W. L. Chen and C. P. Huang and S. H. Huang and A. P. Chen},
	Booktitle = {2016 7th International Conference on Cloud Computing and Big Data (CCBD)},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/CCBD.2016.027},
	Journal = {2016 7th International Conference on Cloud Computing and Big Data (CCBD)},
	Journal1 = {2016 7th International Conference on Cloud Computing and Big Data (CCBD)},
	Keywords = {decision support systems; feature extraction; feedforward neural nets; financial data processing; learning (artificial intelligence); stock markets; time series; FinTech; Taiwan Stock Index Futures; artificial intelligence; deep convolutional neural networks; deep learning; feature extraction; financial markets; financial time-series data analysis; historical datasets; intelligent trading decision support system; multimedia fields; next financial technology generation; numerical features; planar feature representation; time-series data prediction; time-series data processing; trading simulation application; Data models; Feature extraction; Machine learning; Market research; Neural networks; Time series analysis; Training; Deep learning; convolutional neural networks; data visualization; machine learning; trend prediction},
	Pages = {87--92},
	Title = {Financial Time-Series Data Analysis Using Deep Convolutional Neural Networks},
	Ty = {CONF},
	Year = {2016},
	Year1 = {16-18 Nov. 2016},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/CCBD.2016.027}}

@inproceedings{Tsantekidis:2017aa,
	Abstract = {In today's financial markets, where most trades are performed in their entirety by electronic means and the largest fraction of them is completely automated, an opportunity has risen from analyzing this vast amount of transactions. Since all the transactions are recorded in great detail, investors can analyze all the generated data and detect repeated patterns of the price movements. Being able to detect them in advance, allows them to take profitable positions or avoid anomalous events in the financial markets. In this work we proposed a deep learning methodology, based on Convolutional Neural Networks (CNNs), that predicts the price movements of stocks, using as input large-scale, high-frequency time-series derived from the order book of financial exchanges. The dataset that we use contains more than 4 million limit order events and our comparison with other methods, like Multilayer Neural Networks and Support Vector Machines, shows that CNNs are better suited for this kind of task.},
	Author = {A. Tsantekidis and N. Passalis and A. Tefas and J. Kanniainen and M. Gabbouj and A. Iosifidis},
	Booktitle = {2017 IEEE 19th Conference on Business Informatics (CBI)},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {10.1109/CBI.2017.23},
	Journal = {2017 IEEE 19th Conference on Business Informatics (CBI)},
	Journal1 = {2017 IEEE 19th Conference on Business Informatics (CBI)},
	Keywords = {economic forecasting; feedforward neural nets; learning (artificial intelligence); pricing; stock markets; time series; CNN; convolutional neural networks; deep learning methodology; financial exchanges; financial markets; input large-scale high-frequency time-series; limit order book; price movements; stock price forecasting; stock price movement prediction; transaction analysis; Convolution; Data models; Machine learning; Market research; Mathematical model; Neural networks; Support vector machines; Convolutional Neural Networks; Large scale financial data; Limit Orderbook},
	Pages = {7--12},
	Title = {Forecasting Stock Prices from the Limit Order Book Using Convolutional Neural Networks},
	Ty = {CONF},
	Vo = {01},
	Volume = {01},
	Year = {2017},
	Year1 = {24-27 July 2017},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/CBI.2017.23}}

@article{Gunduz:2017aa,
	Author = {Gunduz, Hakan and Yaslan, Yusuf and Cataltepe, Zehra},
	Da = {2017/12/01/},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Doi = {https://doi.org/10.1016/j.knosys.2017.09.023},
	Isbn = {0950-7051},
	Journal = {Knowledge-Based Systems},
	Keywords = {Stock market prediction; Deep learning; Borsa Istanbul; Convolutional neural networks; CNN; Feature selection; Feature correlations},
	Number = {Supplement C},
	Pages = {138--148},
	Title = {Intraday prediction of Borsa Istanbul using convolutional neural networks and feature correlations},
	Ty = {JOUR},
	Url = {http://www.sciencedirect.com/science/article/pii/S0950705117304252},
	Volume = {137},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0950705117304252},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.knosys.2017.09.023}}

@article{2016arXiv160306995C,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160306995C},
	Archiveprefix = {arXiv},
	Author = {{Cui}, Z. and {Chen}, W. and {Chen}, Y.},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Eprint = {1603.06995},
	Journal = {ArXiv e-prints},
	Keywords = {Computer Science - Computer Vision and Pattern Recognition},
	Month = mar,
	Primaryclass = {cs.CV},
	Title = {{Multi-Scale Convolutional Neural Networks for Time Series Classification}},
	Year = 2016}

@article{2017arXiv171105860H,
	Adsnote = {International Journal of Computer Science and Information Technologies (IJCSIT{\textregistered}) is published using an open access publishing model, which makes the full-text of all peer-reviewed papers freely available online with no subscription or registration barriers.},
	Adsurl = {http://ijcsit.com/docs/Volume%207/vol7issue5/ijcsit20160705014.pdf},
	Archiveprefix = {pdf},
	Author = {{Bhandare}, Ashwin, {Bhide}, Maithili, {Gokhale}, Pranav, {Chandavarkar}, Rohan,},
	Date-Added = {2018-02-05 09:05:50 +0000},
	Date-Modified = {2018-02-05 09:05:50 +0000},
	Eprint = {1711.05860},
	Journal = {International Journal of Computer Science and Information Technologies},
	Keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	Month = 5,
	Primaryclass = {cs.CV},
	Title = {{Applications of Convolutional Neural Networks}},
	Year = 2016,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QYi4uL1JlZmVyZW5jZXMvQ2l0YXRpb25zL05OLUZpbi9EZWVwIEludmVzdG1lbnQgaW4gRmluYW5jaWFsIE1hcmtldHMgdXNpbmcgRGVlcCBMZWFybmluZyBNb2RlbHMuYmli0hcLGBlXTlMuZGF0YU8RAkoAAAAAAkoAAgAACU1hY2ludG9zaAAAAAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x9EZWVwIEludmVzdG1lbnQgaW4jRkZGRkZGRkYuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEABAAACiBjdQAAAAAAAAAAAAAAAAAGTk4tRmluAAIAeC86VXNlcnM6cmh2dDpEZXY6Q05OLVBoZDpSZWZlcmVuY2VzOkNpdGF0aW9uczpOTi1GaW46RGVlcCBJbnZlc3RtZW50IGluIEZpbmFuY2lhbCBNYXJrZXRzIHVzaW5nIERlZXAgTGVhcm5pbmcgTW9kZWxzLmJpYgAOAIgAQwBEAGUAZQBwACAASQBuAHYAZQBzAHQAbQBlAG4AdAAgAGkAbgAgAEYAaQBuAGEAbgBjAGkAYQBsACAATQBhAHIAawBlAHQAcwAgAHUAcwBpAG4AZwAgAEQAZQBlAHAAIABMAGUAYQByAG4AaQBuAGcAIABNAG8AZABlAGwAcwAuAGIAaQBiAA8AFAAJAE0AYQBjAGkAbgB0AG8AcwBoABIAdlVzZXJzL3JodnQvRGV2L0NOTi1QaGQvUmVmZXJlbmNlcy9DaXRhdGlvbnMvTk4tRmluL0RlZXAgSW52ZXN0bWVudCBpbiBGaW5hbmNpYWwgTWFya2V0cyB1c2luZyBEZWVwIExlYXJuaW5nIE1vZGVscy5iaWIAEwABLwAAFQACAAv//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDzAPgBAANOA1ADVQNgA2kDdwN7A4IDiwOQA50DoAOyA7UDugAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAO8}}
